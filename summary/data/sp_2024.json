{
    "D:\\PaperWorkflowAutomation\\2024(45th)\\A Representative Study on Human Detection of Artificially Generated Media Across Countries.pdf": {
        "title": "A Representative Study on Human Detection of Artificially Generated Media Across Countries",
        "abstract": "——人工智能生成的媒体已对我们现有的数字社会构成威胁。基于公开可用的技术，伪造内容如今可以被自动化地大规模制造。面对这一挑战，学术界和产业界已提出了多种自动检测策略，用于识别此类人工合成媒体。然而，与这些技术进步形成鲜明对比的是，人类对生成媒体的感知能力尚未得到深入研究。\n\n本文旨在填补这一研究空白。我们首次开展了一项全面调查，研究人类识别生成媒体的能力，覆盖美国、德国和中国三个国家，共3,002名参与者，涉及音频、图像和文本三种媒体类型。研究结果表明，当前最先进的伪造内容几乎与“真实”媒体难以区分——大多数参与者在判断内容是由人类还是机器生成时，实际上仅凭猜测。更值得注意的是，在所有媒体类型和国家中，AI生成的媒体反而更常被判断为“人类生成”。\n\n为进一步探究哪些因素影响人们识别AI生成媒体的能力，我们引入了个人变量，这些变量基于深度伪造（deepfake）和虚假新闻研究领域的文献综述进行选取。通过回归分析，我们发现：总体信任度（generalized trust）、认知反思能力（cognitive reflection）以及参与者对深度伪造技术的自我报告熟悉程度，这三个因素在所有媒体类别中均显著影响其判断决策。\n\n（第1节）"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\A Tale of Two Industroyers：It was the Season of Darkness.pdf": {
        "title": "A Tale of Two Industroyers：It was the Season of Darkness",
        "abstract": "在本文中，我们研究了两种试图在乌克兰制造大规模停电的恶意软件。具体而言，我们设计并开发了一种新型沙箱，该沙箱能够模拟不同的网络环境、设备以及其他关键特征，从而可以运行针对变电站设备的恶意软件，并详细分析攻击者可能对变电站设备执行的具体操作序列。同时，我们还研究了未来类似恶意软件可能造成的潜在影响。我们的研究成果包括一些此前未被记录的恶意软件行为（例如，MMS协议载荷的详细算法），并展示了攻击不同目标将产生不同的影响。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape.pdf": {
        "title": "An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape",
        "abstract": "——利用深度生成模型生成的深度伪造（deepfake）或合成图像，对在线平台构成了严重威胁。这已促使多项研究致力于精准检测深度伪造图像，并在公开可用的深度伪造数据集上取得了优异的性能。在本研究中，我们评估了8种当前最先进的检测器，并指出：由于两项最新发展，这些检测器远未达到可部署的水平。\n\n首先，轻量级定制大型生成模型的方法不断涌现，攻击者可借此创建大量个性化的生成器（用于生成深度伪造内容），从而显著扩大攻击面。我们证明，现有的防御手段在面对如今已公开可得的、由用户自定义的生成模型时，泛化能力极差。为此，我们探讨了基于内容与风格无关（content-agnostic）特征的新型机器学习方法，以及集成建模（ensemble modeling）策略，以提升对用户自定义生成模型的泛化检测性能。\n\n其次，视觉基础模型（vision foundation models）——即在大规模广泛数据上训练、可轻松适配多种下游任务的机器学习模型——的出现，可能被攻击者恶意利用，以生成能够绕过现有防御系统的对抗性深度伪造图像。我们提出一种简单的对抗攻击方法：利用现有的基础模型，在不添加任何对抗噪声的前提下，通过对图像内容进行精细的语义操控，生成对抗样本。我们揭示了多种现有防御系统在我们提出的攻击下的脆弱性，并探索了基于更先进的基础模型以及对抗训练（adversarial training）的防御方向，以应对这一新兴威胁。\n\n关键词——深度伪造图像，基础模型，生成模型，深度伪造检测"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\AquaSonic：Acoustic Manipulation of Underwater Data Center Operations and Resource Management.pdf": {
        "title": "AquaSonic：Acoustic Manipulation of Underwater Data Center Operations and Resource Management",
        "abstract": "——水下数据中心（UDC）因其在能效和环保可持续性方面的优势，被视为下一代数据存储的潜在解决方案。虽然水体的自然冷却特性有助于节能，但水下孤立的运行环境以及声波在水中长距离传播的特性，也带来了与陆地数据中心截然不同的独特安全漏洞。本研究首次揭示了水下数据中心中容错存储设备、资源分配软件和分布式文件系统所面临的新型声学注入攻击（acoustic injection attacks）的脆弱性。\n\n我们构建了一个贴近真实水下数据中心服务器运行环境的实验平台，通过实证方法系统分析了水下声学注入攻击的能力。结果表明，攻击者可使容错型RAID 5存储系统的吞吐量降低17%至100%。在封闭水域的实验分析中，我们发现攻击者能够：  \n（i）仅需持续2.4分钟的声学注入，即可导致分布式文件系统出现无响应状态并自动移除节点；  \n（ii）使分布式数据库的延迟最高提升92.7%，显著降低系统可靠性；  \n（iii）操纵负载均衡管理器，将高达74%的资源重定向至目标服务器，从而引发系统过载或强制资源共置，破坏系统稳定性。\n\n此外，我们在湖泊中开展了开放水域实验，结果表明：攻击者仅需使用商用扬声器，即可在最大有效距离6.35米范围内，实现对目标服务器吞吐量的可控性降级。我们还评估并讨论了现有标准防御措施在应对声学注入攻击时的有效性，发现其防护能力有限。\n\n为此，我们提出了一种创新的基于机器学习的检测系统。该系统以我们采集的硬盘在30秒FIO基准测试下的声学特征数据为训练集，实现了**0%的误报率（False Positive Rate）** 和 **98.2%的检出率（True Positive Rate）**，表现出优异的检测性能。\n\n本研究的最终目标是帮助设备制造商提前识别并防范水下数据中心面临的声学注入攻击威胁，为海底计算基础设施的安全提供前瞻性保障，推动水下数据中心在安全前提下的可持续发展。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\AVA：Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection.pdf": {
        "title": "AVA：Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection",
        "abstract": "近年来，深度伪造（DeepFake）应用日益流行，但其滥用行为对个人隐私构成了严重威胁。不幸的是，目前大多数用于缓解此类滥用的检测算法本身极易受到对抗性攻击，因为它们大多基于深度神经网络（DNN）的分类模型。已有研究表明，通过引入像素级的细微扰动，这些检测模型可以被轻易绕过。尽管已有相应的防御措施被提出，但我们发现了一种全新的、基于属性变化的对抗性攻击方法（Attribute-Variation-based Adversarial Attack, 简称AVA）。该方法通过结合高斯先验与语义判别器，在潜在空间中进行扰动，从而有效绕过现有防御机制。\n\nAVA攻击的核心在于对深度伪造图像在“属性空间”中的语义特征进行扰动。这些扰动对人类观察者而言几乎不可察觉（例如，嘴巴是否张开等细微变化），但却能导致深度伪造检测系统产生显著不同的判断结果，从而成功逃避检测。我们在九种当前最先进的深度伪造检测算法和应用上评估了所提出的AVA攻击。实验结果表明，AVA攻击不仅能够有效突破现有最先进的黑盒攻击防御，还在两款商用深度伪造检测器上实现了超过95%的攻击成功率。\n\n此外，我们的人体感知实验进一步表明，由AVA生成的深度伪造图像对人类而言往往难以察觉，几乎与原始伪造图像无异。这一特性使得该攻击极具隐蔽性，也揭示了其在现实场景中可能引发的巨大安全与隐私风险。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\Break the Wall from Bottom：Automated Discovery of Protocol-Level Evasion Vulnerabilities in Web Application Firewalls.pdf": {
        "title": "Break the Wall from Bottom：Automated Discovery of Protocol-Level Evasion Vulnerabilities in Web Application Firewalls",
        "abstract": "——Web应用防火墙（WAF）是抵御网络攻击的关键防线。然而，一种新兴的威胁正来自协议层级的绕过漏洞：攻击者利用WAF的HTTP解析器与Web应用自身的解析器之间的差异，绕过WAF的检测。目前，发现这类漏洞仍依赖于人工的、临时性的方法。在本文中，我们提出了一种名为**WAF Manis**的新型测试方法，用于自动发现WAF中存在的协议层级绕过漏洞。\n\n我们对WAF Manis进行了评估，测试对象包括14款主流WAF（如Cloudflare和ModSecurity）以及20个主流Web框架（如Laravel和Spring）。总共发现了**311个协议层级绕过案例**，影响所有被测的WAF和应用。由于协议层级绕过具有通用性，这些漏洞并不依赖于特定的攻击载荷模式，因此可以传输任意恶意载荷——例如SQL注入、跨站脚本（XSS）或Log4jShell——直达目标网站。\n\n我们进一步分析了这些漏洞，总结出导致WAF绕过的三大主要原因。我们已将发现的漏洞报告给相关厂商，并已收到来自**Cloudflare WAF、Fortinet WAF、阿里云WAF、华为云WAF、ModSecurity、Go安全团队以及PHP安全团队**的确认回复和部分厂商发放的漏洞奖励（bug bounty）。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\C-Frame：Characterizing and measuring in-the-wild CAPTCHA attacks.pdf": {
        "title": "C-Frame：Characterizing and measuring in-the-wild CAPTCHA attacks",
        "abstract": "在本文中，我们设计并实现了 C-FRAME，这是首个用于收集现代验证码（CAPTCHA）攻击实时、真实世界数据的测量系统。为此，我们研究了验证码协议的最新演变，以及推动验证码攻击的人为驱动“打码农场”（human-driven farms）的发展。这项研究直接引导我们发现了一个独特的观察视角，从而得以开展一项全球规模的验证码攻击测量研究。基于此，我们设计并构建了 C-FRAME 系统，使其具备**与具体验证码类型无关**（CAPTCHA-agnostic）的特性，并在设计过程中充分考虑了**伦理合规性**。随后，我们将该系统部署了 92 天，成功捕获了针对 1417 个网站的 425,257 次验证码攻击行为。\n\n为分析这些攻击的特征，我们采用了一种精心设计的三名分析师参与的定性分析方法。研究结果识别出 34 种不同的验证码攻击类型，并提供了多个真实世界中的典型攻击案例。其中，Twitter 遭受的验证码攻击总量最高（约 255,480 次请求），大多数攻击旨在批量创建机器人账户。我们还分类并记录了其他类型的攻击行为，例如：黄牛票抢购（如巴西的泰勒·斯威夫特演唱会）、虚假诉讼索赔、以及恶意预约抢号行为（如中国境内针对西班牙签证网站的攻击）。此外，我们还发现利用验证码绕过手段从政府网站非法下载数据的行为（例如来自美国 20 个州政府的网站）。\n\n这些攻击行为源自全球 5 个大洲的 58 个不同国家。我们对攻击数据进行了详细的测量分析，深入揭示了攻击的分布、模式与动机，并基于我们的系统发现，提出了一些未来可能实施的防御与缓解措施建议。\n\n1."
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\Conning the Crypto Conman：End-to-End Analysis of Cryptocurrency-based Technical Support Scams.pdf": {
        "title": "Conning the Crypto Conman：End-to-End Analysis of Cryptocurrency-based Technical Support Scams",
        "abstract": "——随着加密货币的广泛普及，普通用户在社交媒体平台上报告的与钱包相关的问题急剧增加。与此同时，一种新兴的欺诈趋势——基于加密货币的技术支持诈骗（cryptocurrency-based technical support scam）也日益猖獗。此类诈骗中，不法分子假借提供钱包恢复服务，专门针对那些正遭遇钱包问题的用户实施欺诈。\n\n本文对基于加密货币的技术支持诈骗展开了全面研究。我们提出了一种名为 **HoneyTweet** 的分析工具，用于系统性分析此类诈骗行为。通过 HoneyTweet，我们发布了约 2.5 万条假冒钱包客服支持的推文（即“诱饵推文”或“蜜罐推文”），成功吸引了超过 9000 名诈骗者上钩。随后，我们部署自动化系统与这些诈骗者进行交互，以深入分析其作案手法（modus operandi）。\n\n实验结果表明，诈骗者通常以 Twitter 作为诈骗的起点，随后迅速转向其他通信渠道（如电子邮件、Instagram 或 Telegram）以完成欺诈行为。我们追踪了这些诈骗者在不同通信渠道间的活动轨迹，并成功诱使他们暴露其收款方式。根据支付方式的不同，我们将诈骗者分为两类：一类要求受害者提交助记词（私钥短语），另一类则直接要求向诈骗者控制的数字钱包转账。\n\n此外，我们通过部署“蜜罐钱包地址”（honey wallet addresses）并验证私钥是否被窃取，获得了诈骗行为的确凿证据。我们还与一家主流支付服务提供商合作，向其共享所收集到的诈骗者数据。该支付服务提供商的反馈与我们的研究发现高度一致，从而进一步验证了我们研究方法的可靠性与结果的有效性。\n\n综合从多个角度获得的分析结果，我们首次实现了对此类诈骗行为的端到端生命周期分析，并提出了切实可行的诈骗防范与缓解建议。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\DP-Auditorium：A Large-Scale Library for Auditing Differential Privacy.pdf": {
        "title": "DP-Auditorium：A Large-Scale Library for Auditing Differential Privacy",
        "abstract": "——随着新法规的出台以及对数据隐私意识的不断增强，公共机构和各行各业纷纷部署了新型且更高效、满足差分隐私（differential privacy）的机制。随着差分隐私的广泛应用，在机制的设计推导和实际实现过程中，也带来了引入错误（bug）的风险。因此，确保这些机制的正确性对于有效保护数据至关重要。然而，由于差分隐私并非机制单次输出的属性，而是机制整体分布层面的性质，判断一个机制是否真正满足差分隐私并非易事。尽管在特定假设条件下存在一些临时的测试方法，但研究界尚未系统性地开发出一种灵活且可扩展的工具，用于测试差分隐私机制。本文提出的**DP-AUDITORIUM**正是朝着这一研究方向迈出的重要一步。\n\nDP-AUDITORIUM的核心思想是将差分隐私的测试问题抽象为两个步骤：（1）**衡量输出分布之间的距离**；（2）**寻找使该距离最大化的相邻数据集**（即输入仅相差一条记录的数据集）。从技术角度，我们提出了三种用于评估分布距离的新算法。虽然这些算法在统计学领域已有应用，但我们通过利用一个关键观察——即我们并不需要精确估计两个分布之间的实际距离，而只需判断机制是否满足差分隐私——从而得出了新的估计保证（estimation guarantees）。\n\nDP-AUDITORIUM具有良好的可扩展性，本文通过将一种著名的近似差分隐私测试算法集成到我们的工具库中，展示了其易于扩展的特性。最后，我们进行了迄今为止最全面的实验对比，评估了多种测试方法在不同样本量、不同差分隐私参数下的表现。结果表明，**不存在一种测试方法能在所有场景下都优于其他方法**。为了确保对差分隐私机制进行充分有效的测试，必须结合使用多种不同的测试技术。\n\n---\n\n**总结（补充理解）：**  \n本文强调了差分隐私机制验证的复杂性——它不是简单地检查某个输出是否“安全”，而是要从统计分布的角度验证整个机制的隐私保障。DP-AUDITORIUM通过“距离度量 + 最坏情况数据对搜索”的模块化框架，为自动化、系统化的差分隐私测试提供了新思路。其创新不仅在于算法设计，更在于将“验证目标”（是否满足差分隐私）与“精确估计”解耦，从而提升了测试效率与实用性。同时，工具的可扩展性和多方法融合的思想，为未来构建更强大的差分隐私验证生态系统奠定了基础。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\From Chatbots to Phishbots.：Phishing Scam Generation in Commercial Large Language Models.pdf": {
        "title": "From Chatbots to Phishbots.：Phishing Scam Generation in Commercial Large Language Models",
        "abstract": "大型语言模型（LLM）的先进能力使其在从对话代理、内容创作到数据分析、研究与创新等各个领域都变得不可或缺。然而，其高效性和广泛可及性也使其容易被滥用，用于生成恶意内容，包括网络钓鱼攻击。本研究探讨了四种主流商用大型语言模型——即 ChatGPT（GPT 3.5 Turbo）、GPT-4、Claude 和 Bard——在通过一系列恶意提示词（prompt）的情况下，生成功能性网络钓鱼攻击的潜力。我们发现，这些 LLM 能够生成高度逼真的钓鱼网站和钓鱼邮件，成功模仿知名品牌的风格，并采用多种规避策略，以绕过反钓鱼系统常用的检测机制。这些攻击甚至可以通过这些 LLM 的未修改版本（即“原始”或“普通”版本）直接生成，无需进行越狱（jailbreaking）等先前行之有效的对抗性攻击手段。\n\n我们对这些模型生成钓鱼攻击的能力进行了评估，发现它们还可被用来自动生成恶意提示词，这些提示词又可反馈回模型本身，以进一步生成钓鱼诈骗内容——从而极大减少了攻击者为实现规模化攻击所需的提示工程（prompt engineering）工作量。\n\n作为应对措施，我们开发了一个基于 BERT 的自动化检测工具，可用于在早期识别恶意提示词，防止 LLM 生成钓鱼内容。我们的检测模型可迁移应用于上述全部四种商用 LLM，在钓鱼网站提示词上的平均准确率达到 96%，在钓鱼邮件提示词上达到 94%。我们已向相关模型厂商披露了这些漏洞，其中 Google 已将其确认为一个严重问题。\n\n我们的检测模型已在 Hugging Face 上公开发布，同时也可作为 ChatGPT Actions 插件供用户使用，便于集成到实际应用中。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\Holistic Concolic Execution for Dynamic Web Applications via Symbolic Interpreter Analysis.pdf": {
        "title": "Holistic Concolic Execution for Dynamic Web Applications via Symbolic Interpreter Analysis",
        "abstract": "——由于动态Web应用具有多语言特性，对其进行符号执行极具挑战性。现有方案往往在语法支持范围上受限，且工程实现成本过高。为此，我们提出一种名为“符号解释器分析”（Symbolic Interpreter Analysis, SIA）的新方法，专门用于以解释型语言编写的Web应用。SIA通过利用语言解释器本身对语法的全面支持，并结合现有符号执行引擎中已成熟的工程实践，有效克服上述局限。由于Web应用的业务逻辑由解释器负责执行，SIA采用现成的符号执行引擎，通过分析该解释器的代码，以符号化的方式间接理解Web应用的行为。实际上，SIA解决了Web应用符号执行中的多个关键技术挑战，例如应用路径探索、数据库交互等。\n\n我们将该方法实现为SYMPHP——一个基于具体-符号混合执行（concolic execution）的PHP Web应用分析引擎。广泛的评估结果表明，SYMPHP能够以全面的PHP语法支持，高效地探索Web应用代码，并实现很高的代码覆盖率。在我们的测试数据集中，SYMPHP成功识别出77.23%的已知漏洞，显著优于此前的方法。此外，基于SYMPHP构建的混合模糊测试（hybrid fuzzing）框架显著提升了模糊测试的效率，并发现了10个此前未知的新漏洞。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\Jasmine：Scale up JavaScript Static Security Analysis with Computation-based Semantic Explanation.pdf": {
        "title": "Jasmine：Scale up JavaScript Static Security Analysis with Computation-based Semantic Explanation",
        "abstract": "——静态数据流分析技术已被广泛应用于Web应用程序的安全威胁分析与检测。然而，由于不涉及实际代码执行，这类技术往往面临严重的精度问题，甚至可能遗漏严重的安全漏洞，尤其是在面对具有复杂操作和语义的现代JavaScript应用时。\n\n为应对这些复杂的语义特征，我们提出了一种新颖的语义理解方法，称为**基于计算的语义解释（Computation-based Semantic Explanation, CSE）**。CSE能够有效识别并解决静态数据流分析中因复杂语义所导致的常见误判与漏报问题，从而显著提升潜在漏洞的检测能力。\n\n我们实现了CSE的原型工具，名为**JASMINE**。通过对超过10,000个真实世界JavaScript程序的应用测试，我们发现复杂操作和语义在实际应用中极为普遍，严重阻碍了当前主流静态分析技术（如GitHub的CodeQL和IBM的WALA）进行常规的安全验证。实验结果表明，JASMINE能够有效解析复杂语义，并成功发现了22个现有工具无法检测的隐藏漏洞。其中，有13个漏洞是此前未知的，即**零日漏洞（zero-day vulnerabilities）**。截至目前，已有9个CVE编号被分配，其中5个被评定为“严重”（critical）级别，CVSS严重性评分为9.8分。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\On SMS Phishing Tactics and Infrastructure.pdf": {
        "title": "On SMS Phishing Tactics and Infrastructure",
        "abstract": "2022年，反网络钓鱼工作组（Anti-Phishing Working Group）报告称，短信（SMS）和语音钓鱼攻击的数量激增了70%。然而，关于短信钓鱼的可靠数据却十分稀缺，对其作案手法的深入分析也极为缺乏。由于缺乏可见性，执法机构、监管部门、服务提供商以及研究人员都难以全面理解并有效应对这一日益严重的问题。在本文中，我们报告了从网络上11个公开短信网关中，历时数年收集到的超过2亿条短信中识别并提取钓鱼信息的研究结果。基于该数据集，我们共识别出67,991条钓鱼短信，并根据内容高度相似性将这些信息归并为35,128个钓鱼活动（campaigns）。进一步，我们识别出共享技术基础设施的关联活动，从而发现超过600个独立的短信钓鱼运营组织。\n\n这一广泛的研究视角使我们得以揭示：短信钓鱼者不仅使用自建的短链接服务，还广泛利用现成的云服务和通用网络基础设施；他们的基础设施往往在钓鱼短信发出前数天甚至数周，就已出现在证书透明度日志中，从而提供了提前预警的可能；此外，他们还重复使用其他类型钓鱼（如电子邮件钓鱼）中已有的钓鱼工具包（phishing kits）。我们还首次对现有的网络防御机制进行了分析，并识别出那些公开为恶意行为提供便利的滥用促进者（abuse facilitators）活跃的网络论坛。\n\n这些方法与发现为业界和研究人员提供了全新的研究方向，有助于更有效地应对日益严峻的短信钓鱼威胁。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\Parse Me, Baby, One More Time：Bypassing HTML Sanitizer via Parsing Differentials.pdf": {
        "title": "Parse Me, Baby, One More Time：Bypassing HTML Sanitizer via Parsing Differentials",
        "abstract": "——网站依赖于服务器端的HTML净化（sanitization）机制，以防御始终存在的跨站脚本（XSS）攻击威胁。然而，解析任意的HTML标记片段以判断其是否包含攻击载荷（exploit payload）绝非易事。这种复杂性导致了净化器（sanitizer）与用户浏览器在解析结果上的差异。这类差异被称为“解析差异”（parsing differentials），它们为一种尚未被深入研究的攻击类型——基于变异的攻击（mutation-based attacks）——敞开了大门。在这种攻击中，攻击者可利用净化器中错误的HTML解析器，要么直接绕过净化机制，要么迫使净化器将原本无害的HTML代码错误地转换为具有危害性的攻击载荷。\n\n在本研究中，我们探讨了此类解析差异的普遍性及其对安全的影响。为此，我们构建了一个专门生成难以解析的HTML片段的工具，并评估了五种编程语言中总共11种主流净化器在处理这些输入时的行为。我们发现，解析差异普遍存在：每款被评估的净化器都至少存在若干功能性缺陷，导致其过度清除（overzealous removal）了本应被允许的无害内容。更严重的是，我们能够自动绕过其中11种净化器中的9种，这揭示了当前服务器端HTML净化机制整体上令人堪忧的安全现状。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\SINBAD：Saliency-informed detection of breakage caused by ad blocking.pdf": {
        "title": "SINBAD：Saliency-informed detection of breakage caused by ad blocking",
        "abstract": "——基于过滤列表规则的隐私增强型屏蔽工具往往会破坏正常的网站功能。过滤列表的维护者若能借助自动化的功能破坏检测工具，便可在规则发布给数百万用户之前主动修复有问题的规则。我们推出了SINBAD，这是一种自动化破坏检测系统，其准确率比现有最先进技术高出20%，并且首次能够检测动态功能破坏以及由样式类过滤规则引发的破坏。\n\nSINBAD的成功源于三大创新：(1) 利用用户在论坛中报告的破坏问题，构建高质量的训练数据集，其中仅包含用户实际感知为问题的功能破坏，从而提升训练数据的针对性与真实性；(2) 引入“网页显著性”（web saliency）技术，自动识别网站中用户最关注的关键区域，优先在这些区域执行自动化交互操作，以更有效触发潜在的破坏行为；(3) 通过分析网页的DOM子树结构，实现对过滤规则的细粒度诊断，精确定位导致问题的具体规则。\n\n（第1节）"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\Synq：Public Policy Analytics Over Encrypted Data.pdf": {
        "title": "Synq：Public Policy Analytics Over Encrypted Data",
        "abstract": "数据分析是现代决策制定的核心组成部分，尤其在公共政策领域。然而，当数据源包含个人信息时，数据隐私与社会有益的数据分析之间便存在一种内在张力。为此，我们设计了 **Synq** 系统，该系统支持在加密数据上进行数据分析，同时兼顾研究机构在开展影响公共政策的研究所可能面临的可用性需求。\n\n我们采用以应用为中心的方法，基于在马萨诸塞州开展的一系列大规模阿片类药物危机研究，提炼出 **Synq** 的设计需求。我们将公共政策背景下的设计考量系统化，并通过文献综述证明：**Synq** 所综合应对的这些设计因素组合，在现有研究中尚属新颖。\n\n随后，我们提出了一种新型协议，结合**结构化加密**（structured encryption）、**半同态加密**（somewhat homomorphic encryption）和**不经意伪随机函数**（oblivious pseudorandom functions），以支持一种复杂的查询语言。该语言支持以下操作：  \n- **筛选**（filtering）：根据属性/值对检索数据行；  \n- **链接**（linking）：合并来自不同表格、代表同一实体的数据行；  \n- **聚合函数**（aggregate functions）：包括求和（sum）、计数（count）、平均值（average）、方差（variance）和回归分析（regression）。\n\n我们对协议的安全性进行了形式化表达，并证明 **Synq** 在实际运行中高效可行，同时满足公共政策研究部署所必需的关键可用性要求。\n\n---\n\n**1.**  \n（注：原文中“1.”可能是章节编号，此处保留，表示接下来可能是论文的第一部分或引言的继续。）"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\The Great Request Robbery：An Empirical Study of Client-side Request Hijacking Vulnerabilities on the Web.pdf": {
        "title": "The Great Request Robbery：An Empirical Study of Client-side Request Hijacking Vulnerabilities on the Web",
        "abstract": "——请求伪造攻击是Web应用面临的最早威胁之一，传统上由服务器端的“混淆代理人”（confused deputy）漏洞引发。然而，随着客户端技术的不断发展，出现了一种更为隐蔽的请求伪造变种：攻击者利用客户端程序中的输入验证缺陷，劫持向外发出的网络请求。目前，我们对这类客户端变种知之甚少，包括其普遍性、影响范围以及相应的防御措施。为此，本文首次对Web平台上客户端请求劫持的现状进行了系统性评估。\n\n首先，我们全面梳理了浏览器API的功能特性与Web标准规范，系统性地归纳了请求劫持漏洞及其所导致的攻击类型，识别出10种不同的漏洞变种，其中包括7种此前未被发现或记录的新变种。\n\n基于上述系统化分类，我们设计并实现了一款名为Sheriff的静态-动态混合分析工具，用于检测从攻击者可控制的输入到请求发送指令之间的易受攻击数据流。我们将Sheriff部署于Tranco排名前1万的网站（top 10K sites）之上，据我们所知，这是首次针对真实网络环境中请求劫持漏洞普遍性的实证研究。\n\n研究结果表明，请求劫持漏洞极为普遍，在排名前1万的网站中，有9.6%的网站存在此类漏洞。我们通过构造67个概念验证（PoC）攻击，在49个网站上成功实现了攻击，证明了这些漏洞的实际危害。攻击可导致任意代码执行、信息泄露、开放重定向以及跨站请求伪造（CSRF）等严重后果，甚至影响了包括Microsoft Azure、Starz、Reddit和Indeed在内的多个主流网站。\n\n最后，我们回顾并评估了当前针对客户端请求劫持攻击的各类防御措施的采用情况与实际有效性，涵盖基于浏览器的解决方案（如CSP、COOP、COEP）以及输入验证机制。\n\n**关键词**——CSRF，请求劫持，普遍性，防御措施"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\Time-Aware Projections：Truly Node-Private Graph Statistics under Continual Observation.pdf": {
        "title": "Time-Aware Projections：Truly Node-Private Graph Statistics under Continual Observation",
        "abstract": "——发布社交网络数据的差分隐私统计信息极具挑战性：每个个体的数据不仅包含其自身节点，还包括该节点所有的连接关系；而典型的分析对网络中插入一个异常节点极为敏感。这种挑战在**连续发布（continual release）**场景下进一步加剧：网络随时间不断变化，需要在网络持续增长的多个时间点上不断发布信息。此前的研究通过在图中假设一个未强制执行的**最大度数（degree）承诺**来解决节点差分隐私的连续发布问题；然而，当实际度数超出该界限时，这些算法会明显违反隐私保护要求。\n\n在本工作中，我们首次提出了一系列满足**标准节点差分隐私（node-differential privacy）**的算法，适用于连续发布场景（即**不依赖对输入流中任何性质的预先承诺**）。这些算法在稀疏图上表现良好，适用于若干基础图论问题：边的计数、三角形计数、其他子图计数、连通分量识别，以及度数直方图的发布。我们的无条件隐私算法在这些任务上通常具有**最优误差**，最多相差多项式对数因子和低阶项。\n\n我们提供了一类通用的转换方法：以一个适用于连续发布场景的**基础算法**为输入，该基础算法只需在满足度数承诺的流上具备隐私性，我们的转换可将其提升为一个**无条件满足节点差分隐私**的算法——当输入流确实满足度数承诺时，新算法的行为与原始算法几乎一致，且仅对基础算法的时间和空间复杂度增加线性开销。\n\n为实现这一目标，我们设计了针对图数据流的新型**投影算法（projection algorithms）**，其技术基础源自批处理模型中的方法 [BBDS13; DLL16]，通过修改数据流来限制节点的最大度数。我们的核心技术创新在于证明了：**当输入流满足一个可隐私验证的安全性条件时，这些投影操作是稳定的**——即相似的输入图会产生相似的投影结果。基于这一性质，我们提出了一种新颖的**在线版本 Propose-Test-Release 框架**（源自 [DL09]），在每个发布步骤前，先对安全性条件进行隐私测试，再决定是否输出结果。\n\n---\n\n1 注：本方法的关键在于，通过“先测试、再发布”的在线机制，在不泄露敏感信息的前提下验证输入是否处于可控范围内（如度数有界），从而安全地应用投影操作并保障整体隐私性。这不仅避免了依赖外部承诺，也实现了在真实动态网络中稳健、可证明的隐私保护。"
    },
    "D:\\PaperWorkflowAutomation\\2024(45th)\\Where URLs Become Weapons：Automated Discovery of SSRF Vulnerabilities in Web Applications.pdf": {
        "title": "Where URLs Become Weapons：Automated Discovery of SSRF Vulnerabilities in Web Applications",
        "abstract": "—服务器端请求伪造（SSRF）漏洞对Web应用构成严重的安全威胁，攻击者可利用Web应用作为跳板，非法访问仅限内网的服务，甚至执行任意命令。尽管SSRF在2021年OWASP Top 10中首次被列为独立的安全风险类别，且其在现代Web应用中的出现频率不断上升，但目前仍缺乏系统、有效的方法来检测SSRF漏洞。\n\n我们提出了一种新颖的方法——SSRFuzz，用于有效识别PHP Web应用中的SSRF漏洞。该方法分为三个阶段：\n\n第一阶段，我们设计了一个SSRF“预言机”（oracle），通过分析PHP官方手册中的函数，识别出具备发起服务器端网络请求能力的敏感函数（即“汇点”，sinks）。在总共2101个PHP函数中，我们筛选出了86个可能引发SSRF的敏感汇点。\n\n第二阶段采用动态污点推理技术，结合已识别出的敏感汇点，对目标Web应用的源代码进行分析，精确定位所有可能触发这些汇点的用户输入入口（即输入点）。\n\n第三阶段采用模糊测试（fuzzing）技术：我们构造包含SSRF攻击载荷的测试HTTP请求，将其发送至目标应用中已识别出的输入点，并监控是否成功触发SSRF漏洞。\n\n我们实现了SSRFuzz的原型系统，并在27个真实世界的应用（包括Joomla和WordPress）上进行了评估。总共发现了28个SSRF漏洞，其中25个为此前未被公开报告的新漏洞。我们已将所有漏洞报告给相关厂商，并获得了16个新的CVE编号。\n\n1."
    }
}