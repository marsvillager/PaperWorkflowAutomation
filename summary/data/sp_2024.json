{
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\A Representative Study on Human Detection of Artificially Generated Media Across Countries.pdf": {
        "title": "A Representative Study on Human Detection of Artificially Generated Media Across Countries",
        "abstract": "——人工智能生成的媒体已对我们现有的数字社会构成威胁。基于公开可用的技术，伪造内容如今可以被自动化地大规模制造。面对这一挑战，学术界和产业界已提出了多种自动检测策略，用于识别此类人工合成媒体。然而，与这些技术进步形成鲜明对比的是，人类对生成媒体的感知能力尚未得到深入研究。\n\n本文旨在填补这一研究空白。我们首次开展了一项全面调查，研究人类识别生成媒体的能力，覆盖美国、德国和中国三个国家，共3,002名参与者，涉及音频、图像和文本三种媒体类型。研究结果表明，当前最先进的伪造内容几乎与“真实”媒体难以区分——大多数参与者在判断内容是由人类还是机器生成时，实际上仅凭猜测。更值得注意的是，在所有媒体类型和国家中，AI生成的媒体反而更常被判断为“人类生成”。\n\n为进一步探究哪些因素影响人们识别AI生成媒体的能力，我们引入了个人变量，这些变量基于深度伪造（deepfake）和虚假新闻研究领域的文献综述进行选取。通过回归分析，我们发现：总体信任度（generalized trust）、认知反思能力（cognitive reflection）以及参与者对深度伪造技术的自我报告熟悉程度，这三个因素在所有媒体类别中均显著影响其判断决策。\n\n（第1节）"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\A Tale of Two Industroyers：It was the Season of Darkness.pdf": {
        "title": "A Tale of Two Industroyers：It was the Season of Darkness",
        "abstract": "在本文中，我们研究了两种试图在乌克兰制造大规模停电的恶意软件。具体而言，我们设计并开发了一种新型沙箱，该沙箱能够模拟不同的网络环境、设备以及其他关键特征，从而可以运行针对变电站设备的恶意软件，并详细分析攻击者可能对变电站设备执行的具体操作序列。同时，我们还研究了未来类似恶意软件可能造成的潜在影响。我们的研究成果包括一些此前未被记录的恶意软件行为（例如，MMS协议载荷的详细算法），并展示了攻击不同目标将产生不同的影响。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape.pdf": {
        "title": "An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape",
        "abstract": "——利用深度生成模型生成的深度伪造（deepfake）或合成图像，对在线平台构成了严重威胁。这已促使多项研究致力于精准检测深度伪造图像，并在公开可用的深度伪造数据集上取得了优异的性能。在本研究中，我们评估了8种当前最先进的检测器，并指出：由于两项最新发展，这些检测器远未达到可部署的水平。\n\n首先，轻量级定制大型生成模型的方法不断涌现，攻击者可借此创建大量个性化的生成器（用于生成深度伪造内容），从而显著扩大攻击面。我们证明，现有的防御手段在面对如今已公开可得的、由用户自定义的生成模型时，泛化能力极差。为此，我们探讨了基于内容与风格无关（content-agnostic）特征的新型机器学习方法，以及集成建模（ensemble modeling）策略，以提升对用户自定义生成模型的泛化检测性能。\n\n其次，视觉基础模型（vision foundation models）——即在大规模广泛数据上训练、可轻松适配多种下游任务的机器学习模型——的出现，可能被攻击者恶意利用，以生成能够绕过现有防御系统的对抗性深度伪造图像。我们提出一种简单的对抗攻击方法：利用现有的基础模型，在不添加任何对抗噪声的前提下，通过对图像内容进行精细的语义操控，生成对抗样本。我们揭示了多种现有防御系统在我们提出的攻击下的脆弱性，并探索了基于更先进的基础模型以及对抗训练（adversarial training）的防御方向，以应对这一新兴威胁。\n\n关键词——深度伪造图像，基础模型，生成模型，深度伪造检测"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\AquaSonic：Acoustic Manipulation of Underwater Data Center Operations and Resource Management.pdf": {
        "title": "AquaSonic：Acoustic Manipulation of Underwater Data Center Operations and Resource Management",
        "abstract": "——水下数据中心（UDC）因其在能效和环保可持续性方面的优势，被视为下一代数据存储的潜在解决方案。虽然水体的自然冷却特性有助于节能，但水下孤立的运行环境以及声波在水中长距离传播的特性，也带来了与陆地数据中心截然不同的独特安全漏洞。本研究首次揭示了水下数据中心中容错存储设备、资源分配软件和分布式文件系统所面临的新型声学注入攻击（acoustic injection attacks）的脆弱性。\n\n我们构建了一个贴近真实水下数据中心服务器运行环境的实验平台，通过实证方法系统分析了水下声学注入攻击的能力。结果表明，攻击者可使容错型RAID 5存储系统的吞吐量降低17%至100%。在封闭水域的实验分析中，我们发现攻击者能够：  \n（i）仅需持续2.4分钟的声学注入，即可导致分布式文件系统出现无响应状态并自动移除节点；  \n（ii）使分布式数据库的延迟最高提升92.7%，显著降低系统可靠性；  \n（iii）操纵负载均衡管理器，将高达74%的资源重定向至目标服务器，从而引发系统过载或强制资源共置，破坏系统稳定性。\n\n此外，我们在湖泊中开展了开放水域实验，结果表明：攻击者仅需使用商用扬声器，即可在最大有效距离6.35米范围内，实现对目标服务器吞吐量的可控性降级。我们还评估并讨论了现有标准防御措施在应对声学注入攻击时的有效性，发现其防护能力有限。\n\n为此，我们提出了一种创新的基于机器学习的检测系统。该系统以我们采集的硬盘在30秒FIO基准测试下的声学特征数据为训练集，实现了**0%的误报率（False Positive Rate）** 和 **98.2%的检出率（True Positive Rate）**，表现出优异的检测性能。\n\n本研究的最终目标是帮助设备制造商提前识别并防范水下数据中心面临的声学注入攻击威胁，为海底计算基础设施的安全提供前瞻性保障，推动水下数据中心在安全前提下的可持续发展。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\AVA：Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection.pdf": {
        "title": "AVA：Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection",
        "abstract": "近年来，深度伪造（DeepFake）应用日益流行，但其滥用行为对个人隐私构成了严重威胁。不幸的是，目前大多数用于缓解此类滥用的检测算法本身极易受到对抗性攻击，因为它们大多基于深度神经网络（DNN）的分类模型。已有研究表明，通过引入像素级的细微扰动，这些检测模型可以被轻易绕过。尽管已有相应的防御措施被提出，但我们发现了一种全新的、基于属性变化的对抗性攻击方法（Attribute-Variation-based Adversarial Attack, 简称AVA）。该方法通过结合高斯先验与语义判别器，在潜在空间中进行扰动，从而有效绕过现有防御机制。\n\nAVA攻击的核心在于对深度伪造图像在“属性空间”中的语义特征进行扰动。这些扰动对人类观察者而言几乎不可察觉（例如，嘴巴是否张开等细微变化），但却能导致深度伪造检测系统产生显著不同的判断结果，从而成功逃避检测。我们在九种当前最先进的深度伪造检测算法和应用上评估了所提出的AVA攻击。实验结果表明，AVA攻击不仅能够有效突破现有最先进的黑盒攻击防御，还在两款商用深度伪造检测器上实现了超过95%的攻击成功率。\n\n此外，我们的人体感知实验进一步表明，由AVA生成的深度伪造图像对人类而言往往难以察觉，几乎与原始伪造图像无异。这一特性使得该攻击极具隐蔽性，也揭示了其在现实场景中可能引发的巨大安全与隐私风险。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\Break the Wall from Bottom：Automated Discovery of Protocol-Level Evasion Vulnerabilities in Web Application Firewalls.pdf": {
        "title": "Break the Wall from Bottom：Automated Discovery of Protocol-Level Evasion Vulnerabilities in Web Application Firewalls",
        "abstract": "——Web应用防火墙（WAF）是抵御网络攻击的关键防线。然而，一种新兴的威胁正来自协议层级的绕过漏洞：攻击者利用WAF的HTTP解析器与Web应用自身的解析器之间的差异，绕过WAF的检测。目前，发现这类漏洞仍依赖于人工的、临时性的方法。在本文中，我们提出了一种名为**WAF Manis**的新型测试方法，用于自动发现WAF中存在的协议层级绕过漏洞。\n\n我们对WAF Manis进行了评估，测试对象包括14款主流WAF（如Cloudflare和ModSecurity）以及20个主流Web框架（如Laravel和Spring）。总共发现了**311个协议层级绕过案例**，影响所有被测的WAF和应用。由于协议层级绕过具有通用性，这些漏洞并不依赖于特定的攻击载荷模式，因此可以传输任意恶意载荷——例如SQL注入、跨站脚本（XSS）或Log4jShell——直达目标网站。\n\n我们进一步分析了这些漏洞，总结出导致WAF绕过的三大主要原因。我们已将发现的漏洞报告给相关厂商，并已收到来自**Cloudflare WAF、Fortinet WAF、阿里云WAF、华为云WAF、ModSecurity、Go安全团队以及PHP安全团队**的确认回复和部分厂商发放的漏洞奖励（bug bounty）。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\C-Frame：Characterizing and measuring in-the-wild CAPTCHA attacks.pdf": {
        "title": "C-Frame：Characterizing and measuring in-the-wild CAPTCHA attacks",
        "abstract": "在本文中，我们设计并实现了 C-FRAME，这是首个用于收集现代验证码（CAPTCHA）攻击实时、真实世界数据的测量系统。为此，我们研究了验证码协议的最新演变，以及推动验证码攻击的人为驱动“打码农场”（human-driven farms）的发展。这项研究直接引导我们发现了一个独特的观察视角，从而得以开展一项全球规模的验证码攻击测量研究。基于此，我们设计并构建了 C-FRAME 系统，使其具备**与具体验证码类型无关**（CAPTCHA-agnostic）的特性，并在设计过程中充分考虑了**伦理合规性**。随后，我们将该系统部署了 92 天，成功捕获了针对 1417 个网站的 425,257 次验证码攻击行为。\n\n为分析这些攻击的特征，我们采用了一种精心设计的三名分析师参与的定性分析方法。研究结果识别出 34 种不同的验证码攻击类型，并提供了多个真实世界中的典型攻击案例。其中，Twitter 遭受的验证码攻击总量最高（约 255,480 次请求），大多数攻击旨在批量创建机器人账户。我们还分类并记录了其他类型的攻击行为，例如：黄牛票抢购（如巴西的泰勒·斯威夫特演唱会）、虚假诉讼索赔、以及恶意预约抢号行为（如中国境内针对西班牙签证网站的攻击）。此外，我们还发现利用验证码绕过手段从政府网站非法下载数据的行为（例如来自美国 20 个州政府的网站）。\n\n这些攻击行为源自全球 5 个大洲的 58 个不同国家。我们对攻击数据进行了详细的测量分析，深入揭示了攻击的分布、模式与动机，并基于我们的系统发现，提出了一些未来可能实施的防御与缓解措施建议。\n\n1."
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\Conning the Crypto Conman：End-to-End Analysis of Cryptocurrency-based Technical Support Scams.pdf": {
        "title": "Conning the Crypto Conman：End-to-End Analysis of Cryptocurrency-based Technical Support Scams",
        "abstract": "——随着加密货币的广泛普及，普通用户在社交媒体平台上报告的与钱包相关的问题急剧增加。与此同时，一种新兴的欺诈趋势——基于加密货币的技术支持诈骗（cryptocurrency-based technical support scam）也日益猖獗。此类诈骗中，不法分子假借提供钱包恢复服务，专门针对那些正遭遇钱包问题的用户实施欺诈。\n\n本文对基于加密货币的技术支持诈骗展开了全面研究。我们提出了一种名为 **HoneyTweet** 的分析工具，用于系统性分析此类诈骗行为。通过 HoneyTweet，我们发布了约 2.5 万条假冒钱包客服支持的推文（即“诱饵推文”或“蜜罐推文”），成功吸引了超过 9000 名诈骗者上钩。随后，我们部署自动化系统与这些诈骗者进行交互，以深入分析其作案手法（modus operandi）。\n\n实验结果表明，诈骗者通常以 Twitter 作为诈骗的起点，随后迅速转向其他通信渠道（如电子邮件、Instagram 或 Telegram）以完成欺诈行为。我们追踪了这些诈骗者在不同通信渠道间的活动轨迹，并成功诱使他们暴露其收款方式。根据支付方式的不同，我们将诈骗者分为两类：一类要求受害者提交助记词（私钥短语），另一类则直接要求向诈骗者控制的数字钱包转账。\n\n此外，我们通过部署“蜜罐钱包地址”（honey wallet addresses）并验证私钥是否被窃取，获得了诈骗行为的确凿证据。我们还与一家主流支付服务提供商合作，向其共享所收集到的诈骗者数据。该支付服务提供商的反馈与我们的研究发现高度一致，从而进一步验证了我们研究方法的可靠性与结果的有效性。\n\n综合从多个角度获得的分析结果，我们首次实现了对此类诈骗行为的端到端生命周期分析，并提出了切实可行的诈骗防范与缓解建议。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\DP-Auditorium：A Large-Scale Library for Auditing Differential Privacy.pdf": {
        "title": "DP-Auditorium：A Large-Scale Library for Auditing Differential Privacy",
        "abstract": "——随着新法规的出台以及对数据隐私意识的不断增强，公共机构和各行各业纷纷部署了新型且更高效、满足差分隐私（differential privacy）的机制。随着差分隐私的广泛应用，在机制的设计推导和实际实现过程中，也带来了引入错误（bug）的风险。因此，确保这些机制的正确性对于有效保护数据至关重要。然而，由于差分隐私并非机制单次输出的属性，而是机制整体分布层面的性质，判断一个机制是否真正满足差分隐私并非易事。尽管在特定假设条件下存在一些临时的测试方法，但研究界尚未系统性地开发出一种灵活且可扩展的工具，用于测试差分隐私机制。本文提出的**DP-AUDITORIUM**正是朝着这一研究方向迈出的重要一步。\n\nDP-AUDITORIUM的核心思想是将差分隐私的测试问题抽象为两个步骤：（1）**衡量输出分布之间的距离**；（2）**寻找使该距离最大化的相邻数据集**（即输入仅相差一条记录的数据集）。从技术角度，我们提出了三种用于评估分布距离的新算法。虽然这些算法在统计学领域已有应用，但我们通过利用一个关键观察——即我们并不需要精确估计两个分布之间的实际距离，而只需判断机制是否满足差分隐私——从而得出了新的估计保证（estimation guarantees）。\n\nDP-AUDITORIUM具有良好的可扩展性，本文通过将一种著名的近似差分隐私测试算法集成到我们的工具库中，展示了其易于扩展的特性。最后，我们进行了迄今为止最全面的实验对比，评估了多种测试方法在不同样本量、不同差分隐私参数下的表现。结果表明，**不存在一种测试方法能在所有场景下都优于其他方法**。为了确保对差分隐私机制进行充分有效的测试，必须结合使用多种不同的测试技术。\n\n---\n\n**总结（补充理解）：**  \n本文强调了差分隐私机制验证的复杂性——它不是简单地检查某个输出是否“安全”，而是要从统计分布的角度验证整个机制的隐私保障。DP-AUDITORIUM通过“距离度量 + 最坏情况数据对搜索”的模块化框架，为自动化、系统化的差分隐私测试提供了新思路。其创新不仅在于算法设计，更在于将“验证目标”（是否满足差分隐私）与“精确估计”解耦，从而提升了测试效率与实用性。同时，工具的可扩展性和多方法融合的思想，为未来构建更强大的差分隐私验证生态系统奠定了基础。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\From Chatbots to Phishbots.：Phishing Scam Generation in Commercial Large Language Models.pdf": {
        "title": "From Chatbots to Phishbots.：Phishing Scam Generation in Commercial Large Language Models",
        "abstract": "大型语言模型（LLM）的先进能力使其在从对话代理、内容创作到数据分析、研究与创新等各个领域都变得不可或缺。然而，其高效性和广泛可及性也使其容易被滥用，用于生成恶意内容，包括网络钓鱼攻击。本研究探讨了四种主流商用大型语言模型——即 ChatGPT（GPT 3.5 Turbo）、GPT-4、Claude 和 Bard——在通过一系列恶意提示词（prompt）的情况下，生成功能性网络钓鱼攻击的潜力。我们发现，这些 LLM 能够生成高度逼真的钓鱼网站和钓鱼邮件，成功模仿知名品牌的风格，并采用多种规避策略，以绕过反钓鱼系统常用的检测机制。这些攻击甚至可以通过这些 LLM 的未修改版本（即“原始”或“普通”版本）直接生成，无需进行越狱（jailbreaking）等先前行之有效的对抗性攻击手段。\n\n我们对这些模型生成钓鱼攻击的能力进行了评估，发现它们还可被用来自动生成恶意提示词，这些提示词又可反馈回模型本身，以进一步生成钓鱼诈骗内容——从而极大减少了攻击者为实现规模化攻击所需的提示工程（prompt engineering）工作量。\n\n作为应对措施，我们开发了一个基于 BERT 的自动化检测工具，可用于在早期识别恶意提示词，防止 LLM 生成钓鱼内容。我们的检测模型可迁移应用于上述全部四种商用 LLM，在钓鱼网站提示词上的平均准确率达到 96%，在钓鱼邮件提示词上达到 94%。我们已向相关模型厂商披露了这些漏洞，其中 Google 已将其确认为一个严重问题。\n\n我们的检测模型已在 Hugging Face 上公开发布，同时也可作为 ChatGPT Actions 插件供用户使用，便于集成到实际应用中。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\Holistic Concolic Execution for Dynamic Web Applications via Symbolic Interpreter Analysis.pdf": {
        "title": "Holistic Concolic Execution for Dynamic Web Applications via Symbolic Interpreter Analysis",
        "abstract": "——由于动态Web应用具有多语言特性，对其进行符号执行极具挑战性。现有方案往往在语法支持范围上受限，且工程实现成本过高。为此，我们提出一种名为“符号解释器分析”（Symbolic Interpreter Analysis, SIA）的新方法，专门用于以解释型语言编写的Web应用。SIA通过利用语言解释器本身对语法的全面支持，并结合现有符号执行引擎中已成熟的工程实践，有效克服上述局限。由于Web应用的业务逻辑由解释器负责执行，SIA采用现成的符号执行引擎，通过分析该解释器的代码，以符号化的方式间接理解Web应用的行为。实际上，SIA解决了Web应用符号执行中的多个关键技术挑战，例如应用路径探索、数据库交互等。\n\n我们将该方法实现为SYMPHP——一个基于具体-符号混合执行（concolic execution）的PHP Web应用分析引擎。广泛的评估结果表明，SYMPHP能够以全面的PHP语法支持，高效地探索Web应用代码，并实现很高的代码覆盖率。在我们的测试数据集中，SYMPHP成功识别出77.23%的已知漏洞，显著优于此前的方法。此外，基于SYMPHP构建的混合模糊测试（hybrid fuzzing）框架显著提升了模糊测试的效率，并发现了10个此前未知的新漏洞。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\Jasmine：Scale up JavaScript Static Security Analysis with Computation-based Semantic Explanation.pdf": {
        "title": "Jasmine：Scale up JavaScript Static Security Analysis with Computation-based Semantic Explanation",
        "abstract": "——静态数据流分析技术已被广泛应用于Web应用程序的安全威胁分析与检测。然而，由于不涉及实际代码执行，这类技术往往面临严重的精度问题，甚至可能遗漏严重的安全漏洞，尤其是在面对具有复杂操作和语义的现代JavaScript应用时。\n\n为应对这些复杂的语义特征，我们提出了一种新颖的语义理解方法，称为**基于计算的语义解释（Computation-based Semantic Explanation, CSE）**。CSE能够有效识别并解决静态数据流分析中因复杂语义所导致的常见误判与漏报问题，从而显著提升潜在漏洞的检测能力。\n\n我们实现了CSE的原型工具，名为**JASMINE**。通过对超过10,000个真实世界JavaScript程序的应用测试，我们发现复杂操作和语义在实际应用中极为普遍，严重阻碍了当前主流静态分析技术（如GitHub的CodeQL和IBM的WALA）进行常规的安全验证。实验结果表明，JASMINE能够有效解析复杂语义，并成功发现了22个现有工具无法检测的隐藏漏洞。其中，有13个漏洞是此前未知的，即**零日漏洞（zero-day vulnerabilities）**。截至目前，已有9个CVE编号被分配，其中5个被评定为“严重”（critical）级别，CVSS严重性评分为9.8分。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\On SMS Phishing Tactics and Infrastructure.pdf": {
        "title": "On SMS Phishing Tactics and Infrastructure",
        "abstract": "2022年，反网络钓鱼工作组（Anti-Phishing Working Group）报告称，短信（SMS）和语音钓鱼攻击的数量激增了70%。然而，关于短信钓鱼的可靠数据却十分稀缺，对其作案手法的深入分析也极为缺乏。由于缺乏可见性，执法机构、监管部门、服务提供商以及研究人员都难以全面理解并有效应对这一日益严重的问题。在本文中，我们报告了从网络上11个公开短信网关中，历时数年收集到的超过2亿条短信中识别并提取钓鱼信息的研究结果。基于该数据集，我们共识别出67,991条钓鱼短信，并根据内容高度相似性将这些信息归并为35,128个钓鱼活动（campaigns）。进一步，我们识别出共享技术基础设施的关联活动，从而发现超过600个独立的短信钓鱼运营组织。\n\n这一广泛的研究视角使我们得以揭示：短信钓鱼者不仅使用自建的短链接服务，还广泛利用现成的云服务和通用网络基础设施；他们的基础设施往往在钓鱼短信发出前数天甚至数周，就已出现在证书透明度日志中，从而提供了提前预警的可能；此外，他们还重复使用其他类型钓鱼（如电子邮件钓鱼）中已有的钓鱼工具包（phishing kits）。我们还首次对现有的网络防御机制进行了分析，并识别出那些公开为恶意行为提供便利的滥用促进者（abuse facilitators）活跃的网络论坛。\n\n这些方法与发现为业界和研究人员提供了全新的研究方向，有助于更有效地应对日益严峻的短信钓鱼威胁。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\Parse Me, Baby, One More Time：Bypassing HTML Sanitizer via Parsing Differentials.pdf": {
        "title": "Parse Me, Baby, One More Time：Bypassing HTML Sanitizer via Parsing Differentials",
        "abstract": "——网站依赖于服务器端的HTML净化（sanitization）机制，以防御始终存在的跨站脚本（XSS）攻击威胁。然而，解析任意的HTML标记片段以判断其是否包含攻击载荷（exploit payload）绝非易事。这种复杂性导致了净化器（sanitizer）与用户浏览器在解析结果上的差异。这类差异被称为“解析差异”（parsing differentials），它们为一种尚未被深入研究的攻击类型——基于变异的攻击（mutation-based attacks）——敞开了大门。在这种攻击中，攻击者可利用净化器中错误的HTML解析器，要么直接绕过净化机制，要么迫使净化器将原本无害的HTML代码错误地转换为具有危害性的攻击载荷。\n\n在本研究中，我们探讨了此类解析差异的普遍性及其对安全的影响。为此，我们构建了一个专门生成难以解析的HTML片段的工具，并评估了五种编程语言中总共11种主流净化器在处理这些输入时的行为。我们发现，解析差异普遍存在：每款被评估的净化器都至少存在若干功能性缺陷，导致其过度清除（overzealous removal）了本应被允许的无害内容。更严重的是，我们能够自动绕过其中11种净化器中的9种，这揭示了当前服务器端HTML净化机制整体上令人堪忧的安全现状。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\SINBAD：Saliency-informed detection of breakage caused by ad blocking.pdf": {
        "title": "SINBAD：Saliency-informed detection of breakage caused by ad blocking",
        "abstract": "——基于过滤列表规则的隐私增强型屏蔽工具往往会破坏正常的网站功能。过滤列表的维护者若能借助自动化的功能破坏检测工具，便可在规则发布给数百万用户之前主动修复有问题的规则。我们推出了SINBAD，这是一种自动化破坏检测系统，其准确率比现有最先进技术高出20%，并且首次能够检测动态功能破坏以及由样式类过滤规则引发的破坏。\n\nSINBAD的成功源于三大创新：(1) 利用用户在论坛中报告的破坏问题，构建高质量的训练数据集，其中仅包含用户实际感知为问题的功能破坏，从而提升训练数据的针对性与真实性；(2) 引入“网页显著性”（web saliency）技术，自动识别网站中用户最关注的关键区域，优先在这些区域执行自动化交互操作，以更有效触发潜在的破坏行为；(3) 通过分析网页的DOM子树结构，实现对过滤规则的细粒度诊断，精确定位导致问题的具体规则。\n\n（第1节）"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\Synq：Public Policy Analytics Over Encrypted Data.pdf": {
        "title": "Synq：Public Policy Analytics Over Encrypted Data",
        "abstract": "数据分析是现代决策制定的核心组成部分，尤其在公共政策领域。然而，当数据源包含个人信息时，数据隐私与社会有益的数据分析之间便存在一种内在张力。为此，我们设计了 **Synq** 系统，该系统支持在加密数据上进行数据分析，同时兼顾研究机构在开展影响公共政策的研究所可能面临的可用性需求。\n\n我们采用以应用为中心的方法，基于在马萨诸塞州开展的一系列大规模阿片类药物危机研究，提炼出 **Synq** 的设计需求。我们将公共政策背景下的设计考量系统化，并通过文献综述证明：**Synq** 所综合应对的这些设计因素组合，在现有研究中尚属新颖。\n\n随后，我们提出了一种新型协议，结合**结构化加密**（structured encryption）、**半同态加密**（somewhat homomorphic encryption）和**不经意伪随机函数**（oblivious pseudorandom functions），以支持一种复杂的查询语言。该语言支持以下操作：  \n- **筛选**（filtering）：根据属性/值对检索数据行；  \n- **链接**（linking）：合并来自不同表格、代表同一实体的数据行；  \n- **聚合函数**（aggregate functions）：包括求和（sum）、计数（count）、平均值（average）、方差（variance）和回归分析（regression）。\n\n我们对协议的安全性进行了形式化表达，并证明 **Synq** 在实际运行中高效可行，同时满足公共政策研究部署所必需的关键可用性要求。\n\n---\n\n**1.**  \n（注：原文中“1.”可能是章节编号，此处保留，表示接下来可能是论文的第一部分或引言的继续。）"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\The Great Request Robbery：An Empirical Study of Client-side Request Hijacking Vulnerabilities on the Web.pdf": {
        "title": "The Great Request Robbery：An Empirical Study of Client-side Request Hijacking Vulnerabilities on the Web",
        "abstract": "——请求伪造攻击是Web应用面临的最早威胁之一，传统上由服务器端的“混淆代理人”（confused deputy）漏洞引发。然而，随着客户端技术的不断发展，出现了一种更为隐蔽的请求伪造变种：攻击者利用客户端程序中的输入验证缺陷，劫持向外发出的网络请求。目前，我们对这类客户端变种知之甚少，包括其普遍性、影响范围以及相应的防御措施。为此，本文首次对Web平台上客户端请求劫持的现状进行了系统性评估。\n\n首先，我们全面梳理了浏览器API的功能特性与Web标准规范，系统性地归纳了请求劫持漏洞及其所导致的攻击类型，识别出10种不同的漏洞变种，其中包括7种此前未被发现或记录的新变种。\n\n基于上述系统化分类，我们设计并实现了一款名为Sheriff的静态-动态混合分析工具，用于检测从攻击者可控制的输入到请求发送指令之间的易受攻击数据流。我们将Sheriff部署于Tranco排名前1万的网站（top 10K sites）之上，据我们所知，这是首次针对真实网络环境中请求劫持漏洞普遍性的实证研究。\n\n研究结果表明，请求劫持漏洞极为普遍，在排名前1万的网站中，有9.6%的网站存在此类漏洞。我们通过构造67个概念验证（PoC）攻击，在49个网站上成功实现了攻击，证明了这些漏洞的实际危害。攻击可导致任意代码执行、信息泄露、开放重定向以及跨站请求伪造（CSRF）等严重后果，甚至影响了包括Microsoft Azure、Starz、Reddit和Indeed在内的多个主流网站。\n\n最后，我们回顾并评估了当前针对客户端请求劫持攻击的各类防御措施的采用情况与实际有效性，涵盖基于浏览器的解决方案（如CSP、COOP、COEP）以及输入验证机制。\n\n**关键词**——CSRF，请求劫持，普遍性，防御措施"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\Time-Aware Projections：Truly Node-Private Graph Statistics under Continual Observation.pdf": {
        "title": "Time-Aware Projections：Truly Node-Private Graph Statistics under Continual Observation",
        "abstract": "——发布社交网络数据的差分隐私统计信息极具挑战性：每个个体的数据不仅包含其自身节点，还包括该节点所有的连接关系；而典型的分析对网络中插入一个异常节点极为敏感。这种挑战在**连续发布（continual release）**场景下进一步加剧：网络随时间不断变化，需要在网络持续增长的多个时间点上不断发布信息。此前的研究通过在图中假设一个未强制执行的**最大度数（degree）承诺**来解决节点差分隐私的连续发布问题；然而，当实际度数超出该界限时，这些算法会明显违反隐私保护要求。\n\n在本工作中，我们首次提出了一系列满足**标准节点差分隐私（node-differential privacy）**的算法，适用于连续发布场景（即**不依赖对输入流中任何性质的预先承诺**）。这些算法在稀疏图上表现良好，适用于若干基础图论问题：边的计数、三角形计数、其他子图计数、连通分量识别，以及度数直方图的发布。我们的无条件隐私算法在这些任务上通常具有**最优误差**，最多相差多项式对数因子和低阶项。\n\n我们提供了一类通用的转换方法：以一个适用于连续发布场景的**基础算法**为输入，该基础算法只需在满足度数承诺的流上具备隐私性，我们的转换可将其提升为一个**无条件满足节点差分隐私**的算法——当输入流确实满足度数承诺时，新算法的行为与原始算法几乎一致，且仅对基础算法的时间和空间复杂度增加线性开销。\n\n为实现这一目标，我们设计了针对图数据流的新型**投影算法（projection algorithms）**，其技术基础源自批处理模型中的方法 [BBDS13; DLL16]，通过修改数据流来限制节点的最大度数。我们的核心技术创新在于证明了：**当输入流满足一个可隐私验证的安全性条件时，这些投影操作是稳定的**——即相似的输入图会产生相似的投影结果。基于这一性质，我们提出了一种新颖的**在线版本 Propose-Test-Release 框架**（源自 [DL09]），在每个发布步骤前，先对安全性条件进行隐私测试，再决定是否输出结果。\n\n---\n\n1 注：本方法的关键在于，通过“先测试、再发布”的在线机制，在不泄露敏感信息的前提下验证输入是否处于可控范围内（如度数有界），从而安全地应用投影操作并保障整体隐私性。这不仅避免了依赖外部承诺，也实现了在真实动态网络中稳健、可证明的隐私保护。"
    },
    "\\\\NAS\\Library\\Papers\\IEEE S&P\\2024(45th)\\Where URLs Become Weapons：Automated Discovery of SSRF Vulnerabilities in Web Applications.pdf": {
        "title": "Where URLs Become Weapons：Automated Discovery of SSRF Vulnerabilities in Web Applications",
        "abstract": "—服务器端请求伪造（SSRF）漏洞对Web应用构成严重的安全威胁，攻击者可利用Web应用作为跳板，非法访问仅限内网的服务，甚至执行任意命令。尽管SSRF在2021年OWASP Top 10中首次被列为独立的安全风险类别，且其在现代Web应用中的出现频率不断上升，但目前仍缺乏系统、有效的方法来检测SSRF漏洞。\n\n我们提出了一种新颖的方法——SSRFuzz，用于有效识别PHP Web应用中的SSRF漏洞。该方法分为三个阶段：\n\n第一阶段，我们设计了一个SSRF“预言机”（oracle），通过分析PHP官方手册中的函数，识别出具备发起服务器端网络请求能力的敏感函数（即“汇点”，sinks）。在总共2101个PHP函数中，我们筛选出了86个可能引发SSRF的敏感汇点。\n\n第二阶段采用动态污点推理技术，结合已识别出的敏感汇点，对目标Web应用的源代码进行分析，精确定位所有可能触发这些汇点的用户输入入口（即输入点）。\n\n第三阶段采用模糊测试（fuzzing）技术：我们构造包含SSRF攻击载荷的测试HTTP请求，将其发送至目标应用中已识别出的输入点，并监控是否成功触发SSRF漏洞。\n\n我们实现了SSRFuzz的原型系统，并在27个真实世界的应用（包括Joomla和WordPress）上进行了评估。总共发现了28个SSRF漏洞，其中25个为此前未被公开报告的新漏洞。我们已将所有漏洞报告给相关厂商，并获得了16个新的CVE编号。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/BOLT：Privacy-Preserving, Accurate and Efficient Inference for Transformers.pdf": {
        "title": "BOLT：Privacy-Preserving, Accurate and Efficient Inference for Transformers",
        "abstract": "——Transformer 的出现为传统机器学习任务带来了显著的进步。然而，其广泛应用也引发了在推理过程中敏感信息可能泄露的担忧。现有基于安全多方计算（MPC）的方法在应用于 Transformer 模型时面临诸多限制，主要源于模型规模庞大以及密集的资源消耗，尤其是矩阵-矩阵乘法运算的高开销。在本文中，我们提出了 BOLT，一种面向 Transformer 模型的隐私保护推理框架，该框架支持高效的矩阵乘法和非线性计算。结合我们提出的新型机器学习优化技术，BOLT 将通信开销降低了 10.91 倍。在多个不同数据集上的实验评估表明，BOLT 在保持与浮点模型相当准确率的同时，相比当前最先进的系统，在各种网络环境下实现了 4.8 至 9.5 倍的推理加速。\n\n**关键词**——安全多方计算，同态加密，安全机器学习推理，Transformer"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Predecessor-aware Directed Greybox Fuzzing.pdf": {
        "title": "Predecessor-aware Directed Greybox Fuzzing",
        "abstract": "定向灰盒模糊测试（Directed Greybox Fuzzing, DGF）是一种以目标为导向的模糊测试技术，可用于复现或发现软件漏洞。该技术通常通过两个阶段实现其目标：第一阶段是静态分析，预先获取程序的结构信息；第二阶段是动态执行，引导模糊测试向目标位置（如漏洞点）逼近。然而，现有的DGF方法仍面临两个主要问题：一是**重量级开销**，二是**覆盖不完整**。前者源于在识别和逼近目标位置过程中所付出的额外计算成本，后者则指由于间接调用或现有DGF方法无法覆盖的路径不足，导致对目标位置的测试覆盖不全面。\n\n在本文中，我们提出了一种**前驱感知的定向灰盒模糊测试（Predecessor-aware Directed Greybox Fuzzing, PDGF）**方法，将DGF建模为一个**路径搜索问题**。PDGF首先通过轻量级程序分析，将给定程序划分为**前驱区域**（即通往目标路径上的关键节点集合）和**非前驱区域**，并在初始阶段维护一组前驱节点，随后在动态执行过程中不断补充和完善该集合。与此同时，PDGF引入了一种新的**适应度度量标准——区域成熟度（regional maturity）**，用于评估前驱区域的路径覆盖程度。此外，PDGF结合基于模拟退火（simulated annealing）的能量调度机制，配合种子选择与变异策略，高效且全面地覆盖前驱区域。\n\n我们在包含30个真实世界程序目标位置的基准测试集上对PDGF进行了评估，并与当前最先进的DGF工具进行了广泛对比。实验结果表明，PDGF在**漏洞暴露时间（Time-To-Exposure）**、**路径多样性**以及**漏洞发现能力**方面均优于现有方法。此外，PDGF成功发现了9个此前未知的漏洞，其中6个已获得CVE编号，被官方收录。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Revisiting Black-box Ownership Verification for Graph Neural Networks.pdf": {
        "title": "Revisiting Black-box Ownership Verification for Graph Neural Networks",
        "abstract": "图神经网络（GNN）已成为处理图结构数据的强大工具，广泛应用于多个领域。然而，GNN容易受到模型提取攻击，从而对知识产权构成威胁。为缓解此类攻击，模型所有权验证被视为一种有效手段。然而，通过一系列实证研究，我们发现现有的GNN所有权验证方法要么要求不切实际的条件，要么在最具实用性的场景——即黑盒设置下（验证者仅能访问目标模型和嫌疑模型的最终输出，例如后验概率）——表现出不尽人意的准确率。\n\n受上述研究启发，我们提出了一种新的黑盒GNN所有权验证方法，该方法结合局部独立模型和影子代理模型，训练一个分类器来完成所有权验证。我们的方法通过以下两个关键洞察显著提升了验证准确率：（1）我们综合考虑目标模型的整体决策行为，更充分地利用其整体“指纹”信息；（2）我们通过在目标模型训练数据中屏蔽部分特征，人为注入额外信息，从而丰富目标模型的指纹特征，增强所有权验证的可区分性。\n\n为评估所提方法的有效性，我们在5个常用数据集、5种主流GNN架构以及16种不同设置下进行了系统且深入的实验评估。结果表明，在所有情况下，我们的方法均能以对目标模型几乎无影响的代价实现接近完美的验证准确率，显著优于现有方法，并大大提升了其实际可用性。此外，我们还证明，该方法在面对试图逃避验证的对抗性攻击时，依然保持较强的鲁棒性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Nightshade：Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models.pdf": {
        "title": "Nightshade：Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models",
        "abstract": "——基于数十亿图像训练的扩散式文本到图像模型，似乎对传统的数据投毒攻击具有极强的抵抗力，因为这类攻击通常需要污染样本占训练集总量的近20%。然而，在本文中，我们证明当前最先进的文本到图像生成模型实际上极易受到投毒攻击。我们的研究基于两个关键洞察。首先，尽管扩散模型在数十亿样本上进行训练，但与某个特定概念或提示（prompt）相关联的训练样本数量通常仅为数千量级。这表明，这些模型在面对**针对特定提示的投毒攻击**时将非常脆弱——即攻击者通过污染模型对某些特定提示的响应能力，使其生成错误或恶意内容。其次，通过精心设计，投毒样本可以被优化以最大化其“毒性效力”，从而确保仅需极少数量的样本即可成功实施攻击。\n\n我们提出了 **Nightshade**，一种以高效力为目标优化的**针对特定提示的投毒攻击方法**。该方法仅需不到100个被污染的训练样本，即可完全控制 Stable Diffusion 最新模型（SDXL）在特定提示下的输出结果。Nightshade 还能生成**隐蔽性极强的投毒图像**：这些图像在视觉上与正常图像几乎完全一致，难以被察觉；同时，其投毒效果还能“渗透”到相关概念中，影响模型对其他语义相近提示的生成结果。\n\n更重要的是，当对多个独立的提示分别实施中等数量的 Nightshade 攻击时，可以导致模型整体失稳，最终使其**彻底丧失生成图像的能力**，即对所有提示均无法正常响应。\n\n最后，我们提出将 Nightshade 及类似工具作为一种**防御手段**，供内容创作者用来对抗那些无视“退出采集”（opt-out）或“禁止爬取”（do-not-crawl）指令的网络爬虫。我们还探讨了此类技术对模型训练方和内容所有者的潜在影响：一方面，它暴露了大规模生成模型在数据安全方面的严重隐患；另一方面，也为原创内容保护提供了新的技术思路。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/To Boldly Go Where No Fuzzer Has Gone Before：Finding Bugs in Linux' Wireless Stacks through VirtIO Devices.pdf": {
        "title": "To Boldly Go Where No Fuzzer Has Gone Before：Finding Bugs in Linux' Wireless Stacks through VirtIO Devices",
        "abstract": "——Linux 内核接口的安全性对于防范空中（over-the-air）、近距离（proximity）或其他网络攻击至关重要。  \n为了发现新引入的漏洞，Linux 内核持续接受模糊测试（fuzzing）。然而，尽管现有的模糊测试工具运行时间很长，它们仍难以发现关键性漏洞，主要原因在于它们不了解物理设备的语义，并且难以适配新型设备。  \n本文提出了一种名为 **VIRTUFF** 的新型模糊测试工具，该工具基于虚拟 I/O（VirtIO）设备驱动。通过一种代理机制，VIRTUFF 能够从物理设备的交互中收集数据；这些收集到的输入随后被用于通过虚拟设备进行模糊测试。  \n借助我们设计的通用 VirtIO 设备，VIRTUFF 具有良好的通用性，可以轻松适配多种 Linux VirtIO 内核驱动及其相关子系统。我们利用该方法对 Linux 的蓝牙（Bluetooth）和无线局域网（WLAN）协议栈进行了模糊测试。为展示该方法的适应性，我们还额外提供了针对网络协议栈和输入子系统（input stack）的模糊测试实现。  \n实验中，我们发现了 **31 个**新漏洞，均已通过人工验证，其中 **6 个**被分配了通用漏洞披露编号（CVE）。\n\n**关键词**：模糊测试，系统安全，Linux，VirtIO，蓝牙，无线局域网（WLAN）  \n\n---\n\n### 说明与理解补充：\n- **模糊测试（Fuzzing）**：一种自动化软件测试技术，通过向程序输入大量随机或半随机的异常数据，以触发崩溃或未定义行为，从而发现潜在漏洞。\n- **VirtIO**：一种为虚拟化环境设计的通用 I/O 设备接口标准，使虚拟机（VM）能够高效地与宿主机通信。本文创新点在于将 VirtIO 用于安全测试，构建“虚拟设备”来模拟真实设备行为，从而实现更灵活、可移植的模糊测试。\n- **物理设备语义（Physical device semantics）**：指设备在真实世界中如何响应特定输入（如蓝牙广播、Wi-Fi 帧结构等）。传统 fuzzer 缺乏对这类上下文的理解，导致测试效率低。\n- **代理机制**：在真实设备与系统交互时“监听”并记录输入数据（如蓝牙数据包、Wi-Fi 帧），作为后续虚拟 fuzzing 的种子输入，提升测试的相关性和有效性。\n- **通用性与可移植性**：VIRTUFF 不依赖具体硬件，通过 VirtIO 抽象层，可快速扩展到其他支持 VirtIO 的驱动（如网络、输入设备等），显著提升安全测试的覆盖范围。\n\n该研究为操作系统内核安全测试提供了一种更智能、更高效的框架，尤其适用于难以直接测试的硬件相关子系统。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/PromptCARE：Prompt Copyright Protection by Watermark Injection and Verification.pdf": {
        "title": "PromptCARE：Prompt Copyright Protection by Watermark Injection and Verification",
        "abstract": "——过去几个月中，大型语言模型（LLMs）在普通用户中迅速走红，能够以接近人类的准确度和熟练度完成多种下游任务。在这一成功中，提示（prompt）起到了关键作用：只需在查询文本前添加一串特定的词符（tokens），即可高效地将预训练的大型语言模型适配到特定任务中。然而，设计和选择一个最优提示往往成本高昂且技术门槛较高，这催生了“提示即服务”（Prompt-as-a-Service）提供商的出现——他们通过向授权用户提供精心设计的提示来盈利。随着提示的广泛使用及其在基于LLM的服务中不可或缺的地位，亟需对提示的版权进行保护，防止其被未经授权地使用。\n\n在本文中，我们提出了 PromptCARE，首个通过水印嵌入与验证实现提示版权保护的系统框架。提示水印面临诸多独特挑战，使得现有为模型和数据集版权验证而开发的水印技术难以直接适用。PromptCARE 针对提示本身的特性以及自然语言领域的特点，提出了专门定制的水印嵌入与验证方案，成功克服了这些难题。我们在六个知名基准数据集上，结合三种广泛使用的预训练大型语言模型（BERT、RoBERTa 和 Facebook OPT-1.3b），进行了大量实验，结果表明 PromptCARE 在水印的有效性、无干扰性（即不影响提示原有功能）、鲁棒性以及隐蔽性方面均表现优异。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Benzene：A Practical Root Cause Analysis System with an Under-Constrained State Mutation.pdf": {
        "title": "Benzene：A Practical Root Cause Analysis System with an Under-Constrained State Mutation",
        "abstract": "——模糊测试（fuzzing）在发现软件漏洞方面已展现出巨大成功，如今在软件测试中发挥着至关重要的作用。尽管模糊测试日益普及，但自动化的根因分析（RCA, Root Cause Analysis）却未获得同等关注。近年来，基于崩溃的统计调试（crash-based statistical debugging）成为RCA领域的一项新进展，该方法利用导致崩溃的输入与非崩溃输入在程序执行行为上的差异进行分析。因此，获取与原始崩溃行为相近的非崩溃执行行为至关重要，但传统方法（如模糊测试）在这方面面临挑战。\n\n在本文中，我们提出了 BENZENE，一个实用化的端到端根因分析系统，旨在实现自动化的崩溃诊断。为此，我们引入了一种名为“欠约束状态变异”（under-constrained state mutation）的新技术，该技术能够同时生成导致崩溃和非崩溃的执行行为，从而实现高效且有效的根因分析。我们设计并实现了 BENZENE 的原型系统，并在现实世界中的60个漏洞上进行了评估。实证结果表明，BENZENE 不仅在性能（即根因排序准确性）上显著优于现有方法，而且在平均运行速度上快4.6倍，内存占用减少至原来的1/31.4，展现出更优的资源效率。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Thwarting Last-Minute Voter Coercion.pdf": {
        "title": "Thwarting Last-Minute Voter Coercion",
        "abstract": "——反制策略是抗胁迫投票方案的关键组成部分——  \n在由胁迫者控制的环境中，反制策略使选民能够提交真实表达自身意愿的选票。通过采用反制策略，选民可以阻止胁迫者判断自己是否遵从了其指令。文献中已提出两种有效的反制策略：一种基于伪造凭证（fake credentials），另一种基于重新投票（revoting）。其中，伪造凭证方案假设选民能够将加密密钥对胁迫者隐藏；而重新投票方案则假设选民在受到胁迫后可以进行再次投票。\n\n在本工作中，我们提出一种新的反制策略技术，支持**灵活的选票更新**（flexible vote updating），即一种即使在投票阶段最后一刻仍受到胁迫的情况下，也能有效抵御胁迫的重新投票机制。我们通过将该技术实现于Loki——一个支持重新投票的、基于互联网的抗胁迫投票方案——来验证其有效性。我们证明了Loki满足一种基于博弈论的抗胁迫定义，该定义充分考虑了灵活选票更新的能力。据我们所知，这是首个能够实现**可否认的抗胁迫投票**（deniable coercion-resistant voting）并能够规避最后一刻选民胁迫的技术。\n\n---\n\n**说明与理解补充：**  \n- **反制策略（counter-strategy）**：指选民在被胁迫时采取的技术手段，使其既能表面“服从”胁迫者，又能秘密保留真实投票自由。  \n- **可否认性（deniability）**：选民可以向胁迫者“证明”自己投了某票（例如出示伪造凭证或临时投票记录），但实际上投的是另一票，且这种欺骗无法被验证，从而实现“可否认”。  \n- **最后一刻胁迫**：指攻击者在投票截止前最后时刻强迫选民按特定方式投票。传统重新投票机制若要求选民在胁迫前或胁迫后立即行动，则难以应对此类攻击。本文的“灵活选票更新”允许选民在任意时间、甚至最后一刻更新选票，从而有效对抗此类胁迫。  \n- **Loki系统**：作为实现平台，体现了该反制策略在实际系统中的可行性与安全性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/MM-BD：Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic.pdf": {
        "title": "MM-BD：Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic",
        "abstract": "——后门攻击是深度神经网络分类器所面临的一类重要对抗性威胁，其特点是在测试样本中嵌入特定的后门模式后，来自一个或多个源类别的样本会被（错误）分类到攻击者预设的目标类别。在本文中，我们聚焦于文献中广泛研究的“训练后后门防御”场景：防御者旨在判断一个已训练好的分类器是否遭受过后门攻击，但无法访问原始训练数据集。\n\n许多现有的训练后检测器仅能识别使用特定后门嵌入函数（例如补丁替换或加性扰动攻击）的攻击。当攻击者实际使用的后门嵌入函数（防御者未知）与防御者所假设的嵌入函数不同时，这些检测器可能会失效。\n\n相比之下，我们提出了一种不依赖于任何后门嵌入类型假设的训练后防御方法，能够检测任意类型的后门嵌入攻击。我们的检测器利用后门攻击对分类器在softmax层之前输出分布的影响——这种影响独立于具体后门嵌入机制。对于每个类别，我们估计一个“最大间隔统计量”（maximum margin statistic），然后使用无监督异常检测算法对这些统计量进行分析，从而完成检测推断。\n\n因此，我们的检测器无需任何干净的正常样本，即可高效地检测出包含任意数量源类别的后门攻击。我们在四个数据集上、针对三种不同类型的后门模式、以及多种攻击配置，验证了该方法相较于几种先进方法的优越性。最后，我们还提出了一种新颖且通用的后门缓解方法，用于在检测到攻击后减轻其影响。该方法在第一届IEEE木马清除竞赛（Trojan Removal Competition）中获得亚军。相关代码已开源。\n\n**关键词**：后门攻击；木马；后门防御"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/No Easy Way Out：the Effectiveness of Deplatforming an Extremist Forum to Suppress Hate and Harassment.pdf": {
        "title": "No Easy Way Out：the Effectiveness of Deplatforming an Extremist Forum to Suppress Hate and Harassment",
        "abstract": "全球各地的立法者和政策制定者正在就如何遏制网络上的非法、有害及不良内容展开激烈辩论。基于多项量化数据，我们发现，即便多家科技公司联合采取大规模行动，试图通过“驱逐平台”（deplatforming）手段来压制网络仇恨与骚扰行为，其成效依然十分有限。本文以2022年底对规模最大、历史最悠久的网络骚扰论坛“KIWI FARMS”的整治行动为案例展开研究，这可能是迄今为止科技行业最广泛的一次联合干预行动。\n\n尽管多家科技公司连续数月积极参与，此次行动仍未能彻底关闭该论坛，也未能清除其令人反感的内容。虽然短暂提升了公众关注，但结果却导致平台迅速迁移、用户流量分散。部分活动转移至Telegram平台，而主要域名的访问量则转向此前已被弃用的替代域名。在接下来几周里，论坛虽经历间歇性断网，但随着主导整治行动的社区逐渐失去兴趣，流量重新回归主域名，用户迅速回流，论坛不仅恢复上线，其网络连接性甚至进一步增强。\n\n事件发生后不久，论坛成员自身也停止讨论此次封禁行动。总体来看，论坛的活动量、活跃用户数、主题帖数量、发帖量及总流量均下降了约一半。此次干扰主要影响的是普通用户——其中约87%选择离开；而核心成员中则有一半仍保持活跃。值得注意的是，此次事件还吸引了大量新用户，这些新成员在刚加入的几周内表现出日益加剧的攻击性和毒性言论。\n\n在没有法院命令的情况下对一个社区实施平台驱逐，引发了关于“审查制度”与“言论自由”之间的哲学争议；也带来了科技企业应如何参与网络内容治理的伦理与法律问题；更提出了私营部门行动与政府干预在实际效果上的对比难题。若仅通过一系列针对个别服务提供商的法院命令来驱逐一个已高度分散的社区，其效果很可能极为有限——除非执法方能有效遏制关键维护者的行为，例如通过逮捕、下达禁制令或以其他方式威慑他们，否则很难实现真正的治理目标。\n\n简言之：**技术平台可以短暂干扰极端社区，却难以根除其存在；而缺乏对核心人物的有效控制，任何平台驱逐行动都可能只是治标不治本，甚至可能适得其反。**"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Group Oblivious Message Retrieval.pdf": {
        "title": "Group Oblivious Message Retrieval",
        "abstract": "——在诸如私密通信和注重隐私保护的区块链应用中，匿名消息传递必须保护接收方的元数据：一条消息不应被无意中关联到其目标接收者。然而，如果每个接收者都不去扫描所有消息，又该如何将消息准确送达每位接收者呢？最近的研究提出了“遗忘式消息检索”（Oblivious Message Retrieval, OMR）协议，将这些任务以保护隐私的方式外包给不可信的服务器。\n\n我们考虑的是群组消息场景，即每条消息可能拥有多个接收者（例如群聊或区块链交易）。若直接将现有的OMR协议应用于群组场景，服务器的计算开销会随着群组规模的增大而线性增长，导致在大群组下成本过高，难以实用。\n\n为此，我们设计了新的协议，使服务器的开销仅随群组规模缓慢增长，同时接收方的开销保持较低水平，且与群组规模无关。我们的方法基于全同态加密（Fully Homomorphic Encryption, FHE）以及其他基于格的密码学技术，在已有工作的基础上进行了构建与优化。我们实现高效群组处理的关键在于：将多个接收者专属的“线索”编码进一个单一的多项式或多线性函数中，该函数可在FHE环境下高效计算；同时结合预处理和摊销（amortization）技术，进一步降低开销。\n\n我们正式提出了“群组遗忘式消息检索”（Group Oblivious Message Retrieval, GOMR）的概念，并描述了相应的GOMR协议。我们的实现与基准测试表明，在具有实际意义的参数设置下，相比此前方案，性能提升可达数个数量级。例如，在每条消息最多发送给15名接收者的情况下，服务器扫描每百万条消息的成本仅为约3.36美元。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Threshold ECDSA in Three Rounds.pdf": {
        "title": "Threshold ECDSA in Three Rounds",
        "abstract": "我们提出了一种三轮协议，用于实现具有恶意安全性的阈值ECDSA签名，能够抵御不诚实多数攻击，并在信息论意义上通用可组合地（UC）实现一个标准的阈值签名功能，仅需假设存在理想的承诺机制和两方乘法原语。我们的协议结合了Abram等人[2]最近提出的一种ECDSA签名中间表示方法，以及一种高效的统计一致性检查机制，该机制类似于Doerner等人[3]、[4]协议中采用的技术。我们证明，本协议所需的共享密钥可以通过一个简单的“承诺-揭示-申诉”流程生成，无需任何知识证明；为计算每个签名的中间表示，我们提出了一种基于不经意传输（oblivious transfer）的两轮向量化乘法协议，其性能优于所有现有同类构造。实验结果表明，在高延迟环境下，我们的协议性能可达Doerner等人协议最高六倍，且相比基于Paillier加密的方案，其速度提升达多个数量级。\n\n（说明：翻译中做了以下技术处理：\n1. \"information-theoretically UC-realizes\"译为\"在信息论意义上通用可组合地（UC）实现\"，保留UC安全性的核心概念\n2. \"vectorized multiplication protocol\"译为\"向量化乘法协议\"，突出并行计算特性\n3. \"commit-release-and-complain\"采用意译\"承诺-揭示-申诉\"，符合密码学协议描述惯例\n4. 长难句拆分为符合中文表达习惯的短句，如将\"assuming only...\"处理为独立分句\n5. 保留文献引用标记[2][3][4]及专业术语如\"oblivious transfer\"（不经意传输）\n6. \"multiple orders of magnitude\"译为\"多个数量级\"，准确传达指数级差异）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/No Privacy Left Outside：On the (In-)Security of TEE-Shielded DNN Partition for On-Device ML.pdf": {
        "title": "No Privacy Left Outside：On the (In-)Security of TEE-Shielded DNN Partition for On-Device ML",
        "abstract": "——设备端机器学习引入了新的安全挑战：\n\n深度神经网络（DNN）模型对设备用户而言变为“白盒”可访问。  \n基于这种白盒信息，攻击者可以对模型权重实施高效的**模型窃取攻击**（Model Stealing, MS），并对训练数据隐私发起**成员推断攻击**（Membership Inference Attack, MIA）。  \n使用可信执行环境（Trusted Execution Environments, TEEs）来保护设备端DNN模型，旨在将（较容易的）白盒攻击降级为（更难实施的）黑盒攻击。然而，TEE的一个主要缺陷是显著增加的计算延迟（最高可达50倍）。为了利用GPU加速受TEE保护的DNN计算，研究人员提出了多种模型分割技术。这些方案统称为**TEE保护下的DNN分割**（TEE-Shielded DNN Partition, TSDP），其核心思想是将DNN模型划分为两部分：将隐私不敏感的部分**卸载**到GPU上执行，而将隐私敏感的部分保留在TEE内部进行保护。\n\n然而，当前社区对现有TSDP方案在DNN推理过程中所提供的隐私保护能力仍缺乏深入理解——这些看似具有前景的隐私保障是否真正可靠？本文通过针对多种DNN模型、数据集和评估指标，系统地对现有TSDP方案在模型窃取（MS）和成员推断（MIA）攻击下的表现进行了基准测试。我们揭示了关键发现：**现有TSDP方案实际上容易受到隐私窃取攻击，并不像普遍认为的那样安全**。我们还揭示了另一个根本性难题：**最优的DNN分割配置难以确定，且因数据集和模型的不同而存在显著差异**。\n\n基于实验中总结的经验教训，我们提出了**TEES LICE**——一种全新的TSDP方法，可在DNN推理过程中有效抵御模型窃取和成员推断攻击。与传统方法不同，**TEES LICE采用“先分割、后训练”的策略**，能够在训练前就准确地将与隐私相关的权重与公开权重分离开来。TEES LICE提供了与“将整个DNN模型完全置于TEE内运行”相当的安全保护（即“安全上限”保障），但其开销比现有TSDP方案降低超过10倍（在实验环境和真实环境中均成立），且**不造成任何模型精度损失**。\n\n我们已将本研究的代码和相关实验材料公开发布于互联网上。\n\n> 注1：在本文中，“卸载”（offload）指的是将计算密集的DNN操作部署到计算能力强但不安全的设备（如GPU）上执行，而非部署到安全但计算能力较弱的设备（如TEE）上。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Orca：FSS-based Secure Training and Inference with GPUs.pdf": {
        "title": "Orca：FSS-based Secure Training and Inference with GPUs",
        "abstract": "安全两方计算（2PC）允许两方在不向对方泄露各自私有输入的前提下，共同计算任意函数。在2PC的离线/在线模型中，与计算输入无关的关联随机数会在预处理的离线阶段生成，并在各方输入可用后的在线阶段被实际使用。目前大多数2PC研究工作都聚焦于优化在线阶段的执行时间，因为这部分开销处于关键路径上，直接影响整体性能。近年来，一种基于函数秘密共享（Function Secret Sharing, FSS）这一密码学技术的新范式，为构建在线开销低的高效2PC协议提供了有效途径。\n\n我们构建了一个端到端的系统 **O RCA**，旨在利用GPU加速基于FSS的2PC协议计算。进一步地，我们观察到，此类加速协议的主要性能瓶颈在于存储（由于需要存储大量关联随机数）。为此，我们针对机器学习中的若干关键功能，设计了一系列新的基于FSS的2PC协议，将存储开销降低至原来的1/5（即减少约5倍）。\n\n与同一计算模型下先前最先进的基于GPU加速的安全训练系统 **P IRANHA**（发表于Usenix Security 2022）相比，**O RCA** 在CIFAR-10数据集上实现了高出4%的准确率、通信量减少98倍，并且运行速度快22倍。在安全推理任务中，针对ImageNet数据集，**O RCA** 实现了VGG-16和ResNet-50模型的亚秒级延迟，性能优于现有最先进系统达8至103倍。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/NetShuffle：Circumventing Censorship with Shuffle Proxies at the Edge.pdf": {
        "title": "NetShuffle：Circumventing Censorship with Shuffle Proxies at the Edge",
        "abstract": "NetShuffle 是一种抗审查系统，提供“动态混洗代理”（shuffle proxies）服务。其核心思想是：将常规代理服务（如 HTTPS 代理、Tor 网桥）与其网络地址解耦，通过持续不断的网络内部地址变更实现“混洗”。这使得混洗代理相比传统代理更难被封锁，因为它们的网络位置始终处于动态变化之中。NetShuffle 还旨在引入一类此前被现有研究忽视的新型支持基础——边缘网络（edge networks）。该系统利用新兴的可编程交换机实现地址混洗，同时对上层服务和客户端保持透明，因此可作为即插即用的网络设备安装部署，助力推动互联网自由。我们在实验测试环境中搭建了 NetShuffle 原型，并在真实校园网络的一个子网中持续无缝运行超过一个月，结果表明：NetShuffle 能够以透明的方式实现网络地址混洗，且几乎不引入额外性能开销。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/ALIF：Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features.pdf": {
        "title": "ALIF：Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features",
        "abstract": "大量研究表明，对抗样本（Adversarial Examples, AE）对语音控制的智能设备构成了严重威胁。近期研究提出了仅需自动语音识别（ASR）系统最终转录文本的黑盒对抗攻击方法。然而，这些攻击通常需要向ASR系统发起大量查询，导致成本高昂。此外，基于AE的对抗音频样本还容易受到ASR系统更新的影响，鲁棒性较差。在本文中，我们揭示了这些局限性的根本原因：即目前难以直接在深度学习（DL）模型的决策边界附近构造对抗攻击样本。\n\n基于这一发现，我们提出了ALIF——首个基于对抗性语言特征的黑盒攻击框架。该方法利用文本到语音（TTS）与语音到文本（ASR）模型之间的互逆过程，在语言嵌入空间中（即决策边界所在的空间）生成扰动。基于ALIF框架，我们进一步提出了ALIF-OTL和ALIF-OTA两种攻击方案，分别适用于数字域和真实物理播放环境下的攻击，并在四个主流商用ASR系统和语音助手上进行了验证。\n\n大量实验结果表明，与现有方法相比，ALIF-OTL和ALIF-OTA在查询效率上分别提升了97.7%和73.3%，同时保持了相当的攻击性能。尤其值得注意的是，ALIF-OTL仅需一次ASR查询即可生成成功的攻击样本。此外，我们开展的“时间推移”（test-of-time）实验进一步验证了该方法在面对ASR系统更新时的强鲁棒性。\n\n（第1节完）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/DeepShuffle：A Lightweight Defense Framework against Adversarial Fault Injection Attacks on Deep Neural Networks in Multi-Tenant Cloud-FPGA.pdf": {
        "title": "DeepShuffle：A Lightweight Defense Framework against Adversarial Fault Injection Attacks on Deep Neural Networks in Multi-Tenant Cloud-FPGA",
        "abstract": "——随着FPGA虚拟化旨在实现多租户云系统，使多个用户电路能够共存于单个FPGA上，这一技术已引发了产业界与学术界的广泛关注。尽管该方式显著提升了硬件资源的利用效率，但也带来了新的安全挑战。作为代表性研究之一，一种最先进的（SOTA）对抗性故障注入攻击——**Deep-Dup [1]**，揭示了多租户云FPGA系统中片外数据通信的脆弱性。Deep-Dup攻击通过在黑盒设置下，仅对极少量敏感权重数据的传输过程注入故障，便成功导致多种深度神经网络（DNN）完全失效；其关键在于利用一种强大的差分进化搜索算法，精准识别出关键权重传输。这类新兴的对抗性故障注入攻击，凸显出在多租户云FPGA系统中构建有效防御机制的紧迫性。\n\n本文首次提出了一种面向**移动目标防御**（Moving-Target Defense, MTD）的新型防御框架——**DeepShuffle**，通过一种创新的轻量级模型参数**动态重排**（shuffling）方法，有效保护多租户云FPGA上的DNN免受SOTA级Deep-Dup攻击。DeepShuffle通过动态改变权重数据的传输顺序，破坏了攻击者依赖的“每轮推理中权重传输可重复”这一特性，从而使其无法识别出安全关键模型参数，成功抵御攻击。\n\n值得注意的是，**DeepShuffle是一种无需训练的DNN防御方法**，巧妙地利用了DNN架构的固有拓扑结构，实现轻量化设计。此外，其部署**无需任何硬件修改**，也**不会带来任何性能下降**。我们在SOTA开源FPGA-DNN加速器平台——**Vertical Tensor Accelerator (VTA)** 上对DeepShuffle进行了评估，该平台代表了实际FPGA-DNN系统开发者的主流实践。实验结果表明，与未受保护的基线系统相比，DeepShuffle仅带来约**3%的额外推理时间开销**。\n\nDeepShuffle显著提升了多种SOTA DNN架构（如VGG、ResNet等）对Deep-Dup攻击的鲁棒性，防御效果提升达数个数量级。它将基于进化搜索的对抗性故障注入攻击的有效性降低至接近随机故障注入的水平。例如，在VGG-11模型上，即使攻击者的努力增加2.3倍，我们的防御方法仍相比未受保护系统实现了**约93%的准确率提升**。\n\n**关键词**——深度神经网络，安全，防御，多租户云FPGA"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：The Long Journey of Exploiting and Defending the Legacy of King Harald Bluetooth.pdf": {
        "title": "SoK：The Long Journey of Exploiting and Defending the Legacy of King Harald Bluetooth",
        "abstract": "——以北欧维京国王哈拉尔·蓝牙（Harald Bluetooth）的名字命名，  \n蓝牙已成为短距离无线通信的事实标准。随着蓝牙低功耗（BLE）和蓝牙Mesh协议的推出，蓝牙在物联网（IoT）与5G时代进一步奠定了其主导地位。然而，近年来针对蓝牙的攻击，如BlueBorne、BleedingBit、KNOB、BIAS和BLESA等，呈现爆发式增长，影响了数十亿台设备。尽管蓝牙安全性已引起安全研究社区的广泛关注，但目前仍缺乏对该领域的系统性理解，这严重阻碍了该领域的进一步发展。\n\n在本文中，我们首先回顾了过去24年中蓝牙安全在技术规范层面的演进历程。随后，通过对该领域已有研究中提出的76种攻击和33种防御措施进行深入分析，我们对蓝牙安全进行了系统化的梳理。我们首先根据攻击和防御所影响的蓝牙协议栈层级、相关协议以及其所对应的威胁模型，对它们进行了分类。然后，我们对攻击与防御措施进行交叉比对，从而构建出蓝牙安全的整体图景。\n\n基于这一系统化分析，我们发现：当前对蓝牙的**形式化分析**（formal analyses）未能覆盖蓝牙Mesh的大部分安全机制。为此，我们迈出了关键一步——设计并实现了一个全面的蓝牙Mesh形式化模型，涵盖其所有与安全相关的协议。该模型旨在提升蓝牙Mesh的安全性。\n\n我们的系统化研究揭示了一些重要问题，例如：蓝牙配对的安全性仍面临因用户操作失误所带来的挑战；蓝牙模糊测试（fuzzing）虽然有效，但尚不全面。基于上述分析，我们提出了若干具有前景的未来研究方向，旨在为未来的蓝牙安全研究提供指引与启发。\n\n---\n\n**第1节**（引言）  \n（注：原文中“1.”应为章节编号，此处保留并解释其位置）  \n本节作为论文的引言部分，旨在引出蓝牙技术的重要地位、当前面临的安全挑战以及现有研究的不足。通过回顾技术发展、安全事件和学术进展，本文确立了研究动机：构建一个系统化的蓝牙安全知识体系，填补当前理论空白，并推动该领域向更深入、更全面的方向发展。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Rethinking IC Layout Vulnerability：Simulation-Based Hardware Trojan Threat Assessment with High Fidelity.pdf": {
        "title": "Rethinking IC Layout Vulnerability：Simulation-Based Hardware Trojan Threat Assessment with High Fidelity",
        "abstract": "——由于芯片设计日益复杂，以及建设先进制造工厂的成本高昂，现代半导体产业中普遍采用将集成电路（IC）制造外包的方式。然而，这种模式也带来了显著的安全风险：不可信的代工厂可能在缺乏严密监管的情况下实施隐蔽的攻击。已有研究表明，在代工厂层面实施可规避制造后检测的“木马攻击”（Trojan attack）是可行的，因此IC设计人员在将版图（layout）提交给第三方代工厂之前，必须对设计加以保护，这类防护措施被称为“设计阶段防御”（design-time defenses）。\n\n为此，评估版图脆弱性的安全度量标准对于检验所提出防御机制的有效性至关重要。然而，现有的度量方法仅关注几何特征，且对木马攻击“视而不见”（Trojan-oblivious），无法真正反映代工厂层面木马植入的本质特征及其带来的副作用。\n\n为了弥合真实攻击与威胁预测之间的鸿沟，我们提出了**SiliconCritic**——一个基于仿真的、可扩展的框架。该框架利用设计阶段的技术手段，模拟“黑盒”式的代工厂木马攻击，并进行制造后分析。SiliconCritic通过量化木马植入后侧信道参数（如时序、功耗）的变化，来衡量将特定木马植入最终物理版图的难度：参数变化越大，木马越容易被检测，因此系统的安全性越高。\n\nSiliconCritic使IC设计人员能够基于侧信道分析反馈，交互式地优化针对特定目标木马的防御策略。通过对真实ASIC设计案例和已报道的硬件木马进行评估，SiliconCritic揭示了现有版图级防御机制的局限性，并突出了木马自身属性（如位置、大小、触发机制等）对防御效果的重要影响。\n\n我们的工作重新审视了硬件木马防御的认知框架，为应对不可信代工厂威胁提供了新的思路，并指出了未来防御技术的研究方向。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Signing in Four Public Software Package Registries：Quantity, Quality, and Influencing Factors.pdf": {
        "title": "Signing in Four Public Software Package Registries：Quantity, Quality, and Influencing Factors",
        "abstract": "许多软件应用都集成了由公共软件包注册中心（public package registries）分发的开源第三方软件包。然而，确保整个供应链中软件包的作者身份真实性是一项挑战。软件包维护者可以通过软件签名（software signing）来保证其包的身份归属，但这种做法的普及程度如何，以及所生成的签名是否规范有效，目前尚不明确。此前的研究虽然提供了关于注册中心签名实践的原始数据，但仅针对单一平台进行测量，未考虑签名质量，未分析时间维度上的演变，也未评估可能影响签名行为的各种因素。因此，我们缺乏对当前签名实践的最新统计，也不了解现有签名的质量状况，更缺乏对影响签名采纳因素的系统性理解。\n\n本研究旨在填补这一空白。我们对三类软件包注册中心进行了测量分析：传统软件（Maven、PyPI）、容器镜像（Docker Hub）以及机器学习模型（Hugging Face）。针对每个注册中心，我们描述了签名构件（signed artifacts）的本质，并分析了当前签名的数量与质量。随后，我们考察了签名实践在时间维度上的纵向演变趋势。最后，我们采用准实验方法（quasi-experiment），评估了多种因素对软件签名实践的影响。\n\n总结本研究的主要发现如下：\n\n（1）强制要求签名能显著提高签名的数量；  \n（2）提供专用的签名工具有助于提升签名的质量；  \n（3）起步阶段最为困难——一旦维护者开始为软件包签名，他们往往会持续这一行为；  \n（4）尽管许多软件供应链攻击可通过签名机制加以缓解，但签名的采纳程度主要受注册中心政策的影响，而非公众对攻击事件的认知、新兴工程标准等其他外部因素。\n\n这些发现凸显了软件包注册中心管理者以及签名基础设施在保障软件供应链安全中的关键作用。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/LLMIF：Augmented Large Language Model for Fuzzing IoT Devices.pdf": {
        "title": "LLMIF：Augmented Large Language Model for Fuzzing IoT Devices",
        "abstract": "尽管模糊测试（fuzzing）在验证网络协议实现的正确性方面具有显著成效，但现有的物联网（IoT）协议模糊测试方法仍面临若干关键限制，包括：消息格式被混淆、消息间依赖关系难以解析，以及缺乏对测试用例的有效评估。这些限制严重制约了IoT模糊测试工具在漏洞识别方面的能力。在本工作中，我们指出，协议规范中包含了丰富的协议消息描述信息，这些信息可被有效利用，以克服上述限制并指导IoT协议的模糊测试。为实现对协议规范的自动化分析，我们将大型语言模型（LLM）与协议规范内容相结合，驱动其完成两项关键任务：（1）协议信息提取；（2）设备响应推理。在此基础上，我们进一步设计并实现了一种新的模糊测试算法LLMIF，将大型语言模型深度集成到IoT模糊测试流程中。最后，我们选取Zigbee协议作为目标协议，开展了全面的评估实验。评估结果表明，LLMIF成功解决了前述各项限制。与现有的Zigbee模糊测试工具相比，LLMIF将协议消息覆盖率和代码覆盖率分别提升了55.2%和53.9%。除了覆盖率的显著提升外，LLMIF还在真实Zigbee设备上发现了11个安全漏洞，其中包括8个此前未知的漏洞，而有7个漏洞未被现有的Zigbee模糊测试工具所覆盖。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Pryde：A Modular Generalizable Workflow for Uncovering Evasion Attacks Against Stateful Firewall Deployments.pdf": {
        "title": "Pryde：A Modular Generalizable Workflow for Uncovering Evasion Attacks Against Stateful Firewall Deployments",
        "abstract": "——有状态防火墙（Stateful Firewall, SFW）在保障我们网络基础设施安全方面发挥着关键作用。然而，即使防火墙规则配置正确，若其有状态语义的实现存在偏差，仍可能导致攻击者有机可乘，实施规避行为。发现这些规避机会极具挑战性，原因主要有三点：（1）防火墙本身具有“黑盒”特性且多为专有系统；（2）实际部署环境多种多样；（3）有状态语义本身高度复杂。为应对这些挑战，我们提出了 Pryde 系统。\n\nPryde 采用一种模块化、模型驱动的自动化工作流，能够跨越不同厂商的黑盒防火墙实现以及特定部署配置，生成有效的规避攻击。Pryde 能够推断出在可能违反 TCP 规范的报文序列下，有状态防火墙的行为模型。该模型结合了攻击者的能力与受害端的行为，进而合成定制化的规避攻击。利用 Pryde，我们针对 4 种主流防火墙和 4 种主机网络协议栈，发现了超过 6,000 种独特的攻击方式。其中许多攻击是此前在审查绕过（censorship circumvention）和黑盒模糊测试（black-box fuzzing）研究中未能揭示的。\n\n关键词：网络安全，有状态防火墙，规避攻击，黑盒建模，TCP"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Prune+PlumTree - Finding Eviction Sets at Scale.pdf": {
        "title": "Prune+PlumTree - Finding Eviction Sets at Scale",
        "abstract": "——为缓存中大部分缓存组（cache set）构造驱逐集（eviction set），是基于“Prime+Probe”的缓存侧信道攻击中一项关键的预处理步骤。此前针对该问题的研究，通常将其简化为对每个缓存组**独立**地寻找一个驱逐集。在一个具有 s 个缓存组、每组为 w 路相联（way-associative）的缓存中，这种逐组独立处理的方法所需时间复杂度为 Ω(s²w)。\n\n本文提出了 **Prune+PlumTree 算法**，该算法在假设使用 LRU（最近最少使用）缓存替换策略的前提下，能够在 **O(sw log s)** 的时间内，为缓存中任意一个固定比例的缓存组构造出驱逐集。我们通过实验验证了这一渐近结果：在现代 Intel 处理器上，其末级缓存（LLC）包含 16k 个缓存组，内存页大小为 4KB，该算法仅需 40–63 毫秒即可为超过 98% 的 LLC 构造出驱逐集，相比此前的工作性能提升达**两个数量级**。此外，在标准（即未偏斜）的随机化缓存模型上模拟 Prune+PlumTree 算法——即地址被随机映射到缓存组——结果表明，对于拥有 2¹⁴ 个缓存组、12 路相联的缓存，该算法可在 7.4 秒内为超过 98% 的缓存组找到驱逐集。\n\n进一步地，我们基于一种新方法，将 Prune+PlumTree 算法适配到采用**随机替换策略**的缓存中。该方法能够将大量随机内存行（memory lines）集合，剪枝（prune）为多个最小驱逐集的并集。在这种设定下，改进后的 Prune+PlumTree 算法运行时间为 **O(sw² log s)**。\n\n作为最后一项贡献，我们证明了针对 LRU 替换策略的 Prune+PlumTree 算法具有**渐近紧确的运行时间**：我们证明，任何能够为缓存中一个固定比例缓存组构造驱逐集的算法，其时间复杂度下界均为 Ω(sw log s)，从而说明 Prune+PlumTree 在渐近意义下是最优的。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/FCert：Certifiably Robust Few-Shot Classification in the Era of Foundation Models.pdf": {
        "title": "FCert：Certifiably Robust Few-Shot Classification in the Era of Foundation Models",
        "abstract": "——基于基础模型（如 CLIP、DINOv2、PaLM-2）的小样本分类（few-shot classification）使用户能够仅用少量带标签的训练样本（称为支持样本）为分类任务构建一个高精度的分类器。然而，攻击者可以通过操纵部分支持样本实施数据投毒攻击，使得分类器对测试输入做出攻击者所期望的、任意的预测。现有的经验性防御方法无法提供形式化的鲁棒性保证，导致攻击者与防御者之间陷入“猫鼠博弈”的困境。当前已有的可验证防御（certified defenses）主要设计用于传统监督学习，在扩展到小样本分类任务时性能表现不佳。\n\n在本研究中，我们提出了 FCert——首个针对小样本分类中数据投毒攻击的可验证防御方法。我们证明，当被投毒的支持样本总数受到限制时，FCert 能够保证对任意测试输入在遭受任意数据投毒攻击的情况下，始终预测出相同的标签。我们在视觉和文本领域，基于 OpenAI、Meta 和 Google 发布的基础模型，在多个标准的小样本分类数据集上进行了广泛的实验。实验结果表明，我们的 FCert 具有以下优势：  \n1）在无攻击情况下仍能保持原有的分类准确率；  \n2）在应对数据投毒攻击方面，性能优于现有最先进的可验证防御方法；  \n3）具备高效性和良好的泛化能力，适用于多种任务和模型。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Wear's my Data. Understanding the Cross-Device Runtime Permission Model in Wearables.pdf": {
        "title": "Wear's my Data. Understanding the Cross-Device Runtime Permission Model in Wearables",
        "abstract": "可穿戴设备正变得日益重要，不仅帮助我们保持健康，也让我们与他人保持联系。目前存在多种基于应用的可穿戴设备平台，可用于管理这些设备。可穿戴设备上的应用通常需要与用户智能手机上的配套应用协同工作。这类设备与手机通常采用两种独立的权限管理机制，二者同步运行以保护敏感数据。然而，这种设计导致权限保护数据的管理过程对用户而言缺乏透明性，从而造成数据访问权限的过度授予，且未经用户明确同意。\n\n在本文中，我们首次对Android与Wear OS权限模型之间的交互机制进行了系统性分析。我们的分析分为两个层面。首先，通过污点分析（taint analysis），我们证明了在实际应用中，权限保护的敏感数据确实存在跨设备流动。研究发现，在Google Play商店中我们分析的150款应用中，有28款应用存在可穿戴设备应用与其配套手机应用之间的敏感数据流动。这些数据传输过程并未获得用户的明确授权，从而可能违背用户的隐私预期，带来隐私泄露风险。\n\n其次，我们开展了一项实验室环境下的用户研究（n = 63），旨在评估用户在面临跨设备通信时对权限机制的理解程度。结果显示，66.7%的用户并未意识到敏感数据可能在设备间流动，这严重削弱了他们对可穿戴设备权限模型的理解，并使其敏感数据暴露于风险之中。我们还发现，用户容易受到一类新型攻击——我们称之为“跨设备权限钓鱼攻击”（cross-device permission phishing attacks）——这类攻击专门针对可穿戴设备，利用用户对权限机制的认知盲区诱导其授权恶意数据共享。\n\n此外，我们对其他主流智能手表平台（如苹果的watchOS、Fitbit和Garmin OS）进行了初步研究，发现这些平台同样存在类似的隐私问题。\n\n为应对跨设备应用可能引发的隐私泄露风险，我们提出以下改进建议：在系统层面优化权限提示机制，改进权限模型，使用户能够做出更知情、更合理的授权决策；同时，建议应用市场加强审查机制，识别并阻止恶意跨设备数据流动。这些措施有助于提升用户对自身数据的控制力，增强可穿戴生态系统的整体隐私安全性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SyzGen++：Dependency Inference for Augmenting Kernel Driver Fuzzing.pdf": {
        "title": "SyzGen++：Dependency Inference for Augmenting Kernel Driver Fuzzing",
        "abstract": "近年来，内核模糊测试（kernel fuzzing）研究呈现出显著的增长趋势。在众多内核模糊测试工具中，Syzkaller 脱颖而出，成为当前最先进的工具，已在 Linux 内核中发现了超过 5,000 个漏洞。Syzkaller 的成功主要归功于其使用了由内核专家手动精心编写的**系统调用规范**（syscall specifications）。然而，这一过程耗时耗力，且难以扩展，原因在于系统调用的输入结构复杂，且系统调用之间存在大量未知的依赖关系。因此，内核代码库中仍有大量部分——特别是**内核驱动程序**——缺乏相应的规范描述，这带来了严重的安全风险。\n\n在本文中，我们提出了 SyzGen++，一种无需依赖现有测试套件即可自动推断系统调用之间的依赖关系并生成规范的创新方法。具体而言，我们定义了两个基本操作单元：**插入操作**（insertion）和**查找操作**（lookup），并通过它们的配对来精准识别系统调用间的依赖关系。我们在 Linux 和 macOS 的驱动程序上，对 SyzGen++ 与当前最先进的现有技术进行了评估。实验结果表明，SyzGen++ 额外发现了 245 个依赖关系，显著优于其他方法。此外，在代码覆盖率方面，SyzGen++ 也全面超越了 DIFUZE、KSG 和 SyzDescribe，分别实现了平均 71%、67% 和 39% 的性能提升。尤其值得注意的是，我们在 Linux 内核 6.2 版本中，利用 SyzGen++ 自动生成的规范，发现了 10 个此前未知的漏洞，并由此成功申请了 6 个 CVE（通用漏洞披露）编号，充分验证了该方法在漏洞挖掘中的有效性。\n\n**关键词**：模糊测试，操作系统安全，漏洞分析"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/MIMOCrypt：Multi-User Privacy-Preserving Wi-Fi Sensing via MIMO Encryption.pdf": {
        "title": "MIMOCrypt：Multi-User Privacy-Preserving Wi-Fi Sensing via MIMO Encryption",
        "abstract": "——Wi-Fi信号有望实现低成本、非侵入式的人体感知，但同时也可能被窃听者利用以获取私人信息。截至目前，针对这一隐私问题的研究仍非常有限：现有方案要么干扰所有感知行为，要么依赖复杂技术仅支持单一感知用户，因而难以适用于多用户场景。此外，这些方案均未能充分利用Wi-Fi的多输入多输出（MIMO）能力。为此，我们提出了**MIMO Crypt**——一种支持真实多用户场景的隐私保护型Wi-Fi感知框架。\n\nMIMO Crypt的创新之处在于：通过利用MIMO技术对Wi-Fi信道进行物理层加密，将感知到的人体活动视为物理明文，从而在保障合法用户正常感知与通信功能的同时，有效阻止未经授权的窃听行为。该加密机制进一步通过一个优化框架进行增强，旨在安全地向合法用户传递解密密钥的前提下，在以下三者之间取得平衡：i）窃听风险；ii）感知精度；iii）通信质量。\n\n我们在软件定义无线电（SDR）平台上实现了MIMO Crypt的原型系统，并针对常见应用场景（尤其是对隐私高度敏感的人体手势识别）开展了大量实验，全面评估其有效性。\n\n**关键词**——Wi-Fi感知，隐私保护，信号混淆，MIMO加密\n\n---\n\n### 1. 引言\n\n随着Wi-Fi基础设施的日益广泛部署，在带来无处不在的无线接入便利的同时，也催生了一项显著的安全威胁。事实上，过去二十年中，这种威胁本身已被转化为一种“无传感器”“非接触式”感知环境的机会[1]–[8]。其原理是：Wi-Fi信号（特别是信道状态信息，即CSI [9]）在传播过程中受到周围环境的扰动，这些扰动可被用于推断扰动源的状态和行为。\n\n然而，尽管这一技术使普通Wi-Fi用户（在满足某些宽松条件时）能够感知到他人（不一定是Wi-Fi用户）的位置[3]、[4]、[7]、行为/手势[1]、[2]、[6]、[10]，甚至生命体征[5]、[8]、[11]，但这也意味着恶意窃听者可能借此获取敏感信息。例如，用户输入密码的动作可通过Wi-Fi感知被“窃听”[6]、[12]–[14]，重要人物的健康状况也可能因其生命体征泄露而被窥探[8]、[11]。\n\n> **图1说明**：MIMO Crypt利用接入点（AP，即Alice）的MIMO多样性对信道进行加密，从而阻止恶意窃听者（Eve）；同时，通过安全地向合法用户（Bobs）传递解密密钥，保留其正常的通信与感知能力。\n\n尽管这一威胁已被认识多年[15]、[16]，但现有解决方案的应用范围仍十分有限。例如，**PhyCloak** [15] 提出了一种“自私”的防御机制：它通过吸收原始信号并干扰后续信号，仅允许一个用户进行感知，导致多用户场景无法使用。类似地，文献[17]再次采用信号混淆技术，但将其从接入点（AP）端实施，通过注入“虚假”数据流量来阻止所有基于接收信号强度（RSS）的感知尝试。作为信号混淆的最新进展，**IRShield** [18] 利用智能反射面（IRS, Intelligent Reflecting Surfaces）实现了与[17]相似的目标，但其依赖昂贵的IRS设备，且仅针对特定类型的CSI子集（如CS）进行保护，未能全面应对多用户、多场景下的隐私挑战。\n\n更重要的是，上述所有方案均未挖掘Wi-Fi系统固有的**MIMO能力**——即通过多天线协同，在空间上对信号进行编码与操控。MIMO不仅可用于提升通信速率，更具备天然的物理层安全潜力：通过对不同空间流进行差异化处理，可以在不破坏合法接收端信号的前提下，使窃听者接收到的信号变得不可解读。\n\n为此，**MIMO Crypt** 应运而生。其核心思想是：将人体活动视为“物理明文”，利用MIMO技术对Wi-Fi信道进行**物理层加密**。合法用户通过安全信道获取解密密钥后，可恢复出真实CSI以支持高精度感知与通信；而窃听者由于缺乏密钥且无法解析加密后的空间流，其感知能力被显著削弱甚至完全失效。\n\nMIMO Crypt的设计不仅解决了多用户共存问题，还通过一个联合优化框架动态调节加密参数，在**隐私保护强度、感知准确率与通信性能**之间实现最佳权衡。实验结果表明，该系统在典型室内环境中，尤其在手势识别等隐私敏感任务中，能够有效抵御多种窃听攻击，同时保障合法用户的服务质量。\n\n综上，MIMO"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Bounded and Unbiased Composite Differential Privacy.pdf": {
        "title": "Bounded and Unbiased Composite Differential Privacy",
        "abstract": "——差分隐私（Differential Privacy, DP）的目标是通过生成在任意两个相邻数据库之间不可区分的输出分布来保护隐私。然而，传统的差分隐私机制为了实现最大的扰动范围，通常会产生无界的输出，这并不总是符合实际应用场景的需求。现有解决方案试图通过后处理或截断技术来限制输出结果，以解决这一问题，但这样做会引入偏差（bias），从而影响结果的准确性。\n\n在本文中，我们提出了一种新颖的差分隐私机制，该机制使用一个复合概率密度函数（composite probability density function）为任意数值型输入数据生成有界且无偏的输出。该复合函数由激活函数（activation function）和基础函数（base function）组成，用户可根据差分隐私的约束条件灵活地自定义这两个函数。我们还开发了一种优化算法，能够在无需重复实验的情况下，通过迭代搜索找到最优的超参数配置，从而避免因多次实验带来的额外隐私开销。\n\n此外，我们通过评估复合概率密度函数的方差来衡量所提机制的效用，并提出了两种比方差估计更易计算的替代性评估指标。在三个基准数据集上的广泛实验表明，我们所提出的机制在性能上显著且一致地优于传统的拉普拉斯（Laplace）和高斯（Gaussian）机制。\n\n本文提出的**有界且无偏的复合差分隐私机制**，不仅拓展了差分隐私的技术工具箱，也为未来隐私保护研究的发展提供了坚实的基础和新的方向。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Chronos：Finding Timeout Bugs in Practical Distributed Systems by Deep-Priority Fuzzing with Transient Delay.pdf": {
        "title": "Chronos：Finding Timeout Bugs in Practical Distributed Systems by Deep-Priority Fuzzing with Transient Delay",
        "abstract": "在复杂的分布式环境中，延迟是不可避免的。超时机制被广泛用于处理分布式系统中的意外故障。然而，超时处理不当或超时机制实现中的错误，可能导致系统挂起或崩溃。这类超时缺陷可能十分关键，对分布式系统的可用性与安全性构成严重威胁。\n\n在本文中，我们提出了 Chronos——一个用于自动检测分布式系统中超时缺陷的通用测试框架，该框架通过深度优先的瞬时延迟（deep-priority transient delays）来实现。首先，我们设计了一组通用的运行时延迟库，能够动态地向被测分布式系统（DSUT）中注入细粒度的延迟。为了有效触发延迟并持续探索深层执行路径中的超时缺陷，Chronos 采用了一种深度优先引导的模糊测试（deep-priority guided fuzzing）技术，在运行时动态生成高质量的延迟序列。随后，Chronos 利用瞬时延迟（transient delays）来消除真实延迟带来的时间开销，从而显著加速测试过程。\n\n我们实现了 Chronos，并在四个广泛使用的分布式系统上进行了评估，包括 ZooKeeper、MySQL-Cluster、HDFS 和 Go-Ethereum。与当前最先进的故障注入技术（随机注入 Random、暴力注入 Brute-Force 和覆盖引导注入 Coverage-Guided）相比，Chronos 分别多覆盖了 26.40%、21.69% 和 15.14% 的超时机制逻辑。此外，Chronos 已成功在这些真实应用中检测出 27 个超时缺陷，且这些缺陷均已被相应系统的维护者修复。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Investigating Voter Perceptions of Printed Physical Audit Trails for Online Voting.pdf": {
        "title": "Investigating Voter Perceptions of Printed Physical Audit Trails for Online Voting",
        "abstract": "在线选举面临安全挑战，因为数字选票无法生成易于验证的物理审计轨迹。我们提出并研究了一种混合式在线投票系统，该系统结合了居家网络投票的便利性与实体纸质选票的优势，例如可进行风险限定审计（risk-limiting audits）和选票可验证性。选民在网上投票后，系统会生成一个追踪码，以及一份加密选票的实体打印件——可以是纸质或3D打印形式，选民可通过实时视频直播对选票内容进行视觉核验。\n\n我们通过一项在线实验（样本量N=150），将该混合投票系统（分别采用纸质和3D打印选票）与仅存储数字选票的基准系统进行对比，重点考察了用户对系统可信度、用户体验（UX）、可用性以及安全准备程度的感知。研究结果表明，纸质打印件在不损害用户体验的前提下显著提升了用户信任度；而3D打印件虽然增强了用户对隐私保护的感知，却对可用性和整体用户体验产生了一定负面影响。\n\n最后，我们提出了相关建议与实践考量，旨在为混合式在线投票系统的实施提供指导。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/CaFA：Cost-aware, Feasible Attacks With Database Constraints Against Neural Tabular Classifiers.pdf": {
        "title": "CaFA：Cost-aware, Feasible Attacks With Database Constraints Against Neural Tabular Classifiers",
        "abstract": "本文提出了CaFA（Cost-aware Feasible Attacks，成本感知可行攻击）系统，用于评估神经表格分类器在面对问题空间中可实现对抗样本时的鲁棒性，同时最小化攻击者的实施成本。为实现这一目标，CaFA采用了我们提出的TabPGD算法——一种专为表格数据生成对抗性扰动的方法，并结合了由当前最先进的数据库技术自动挖掘出的完整性约束。CaFA首先利用TabPGD在特征空间中生成对抗样本，随后将这些样本投影到已挖掘的约束上，从而显著提升攻击在现实场景中的可实现性。\n\n我们在三个数据集和两种模型架构上对CaFA进行了测试，结果表明：与先前工作所使用的约束相比，我们采用的约束在质量上更优（通过准确性和完备性衡量）。此外，CaFA实现了更高的可行攻击成功率——即所生成的对抗样本在满足约束条件的同时，更频繁地导致模型误分类；同时，它在扰动时仅改变较少数量的特征，且扰动幅度更小，从而降低了攻击成本并提升了隐蔽性。\n\n我们已将CaFA开源，1 希望它能作为一个通用系统，帮助机器学习工程师评估其模型在面对现实可实现攻击时的鲁棒性，进而提升实际部署模型的可信度。\n\n1. https://github.com/CaFA-release （注：原文中“1”为脚注编号，此处保留原意，具体链接可根据实际情况补充）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：A Comprehensive Analysis and Evaluation of Docker Container Attack and Defense Mechanisms.pdf": {
        "title": "SoK：A Comprehensive Analysis and Evaluation of Docker Container Attack and Defense Mechanisms",
        "abstract": "基于容器的应用因其在跨平台软件开发、部署和运维中的高效性而日益受到青睐。然而，随着安全与隐私攻击事件的不断增多，人们对此产生了严重担忧。由于容器与宿主机共享同一个操作系统，容器内部的漏洞一旦被利用，可能危及整个宿主系统。不幸的是，现有的容器防御机制在面对不断演进且高度动态化的攻击手段时，显得力不从心。\n\n本文系统性地梳理了容器攻击及其防御机制。我们系统地分析了以下两类方法的有效性：（i）用于漏洞检测的静态容器扫描工具，揭示其在实际应用中存在的局限性；（ii）现有的基于运行时异常的检测方法。随后，我们构建了一个评估框架，并利用包含51个真实漏洞的广泛数据集，对专为容器设计的先进异常检测技术进行了全面再评估。我们强调，现有防御手段在抵御当前最先进的攻击方式时效果甚微。\n\n尽管基于异常检测的方法在应对动态攻击场景方面展现出一定潜力，但其较高的误报率以及有限的训练数据，严重制约了其在实际环境中的应用。因此，我们的研究凸显了进一步加强容器应用安全研究的紧迫性，亟需开发更有效的防御机制，以应对日益复杂的威胁环境。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Labrador：Response Guided Directed Fuzzing for Black-box IoT Devices.pdf": {
        "title": "Labrador：Response Guided Directed Fuzzing for Black-box IoT Devices",
        "abstract": "——模糊测试（Fuzzing）是发现软件（包括物联网固件）漏洞的一种流行方法。然而，由于固件模拟或移植（rehosting）存在诸多挑战，某些物联网设备（如企业级设备）只能以黑盒方式进行模糊测试。这种黑盒模式使得模糊测试工具缺乏反馈信息（例如代码覆盖率或距离敏感代码的“距离”），因而变得盲目且效率低下。\n\n在本文中，我们提出了一种新颖的、由响应引导的定向模糊测试解决方案 L ABRADOR，能够高效地测试黑盒物联网设备。具体来说，我们利用设备的网络响应来推断固件的执行轨迹，并据此推导出测试过程中的代码覆盖率。其次，我们结合测试用例（即请求）及其响应，估算当前执行路径到目标敏感代码（即“汇点”sink）的距离。最后，我们进一步利用这一距离信息来指导测试用例的变异过程，从而高效地引导定向模糊测试向可能存在漏洞的代码区域推进。\n\n我们实现了 L ABRADOR 的原型系统，并在14种不同的企业级物联网设备上进行了评估。实验结果表明，L ABRADOR 显著优于当前最先进的（SOTA）解决方案：其发现的漏洞数量是 SNIPUZZ、BOOFUZZ 和 FIRM-AFL 的44倍，是 SaTC 的8.57倍。总共发现了79个未知漏洞，其中61个已被分配CVE编号。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/TrojanPuzzle：Covertly Poisoning Code-Suggestion Models.pdf": {
        "title": "TrojanPuzzle：Covertly Poisoning Code-Suggestion Models",
        "abstract": "——借助 GitHub Copilot 等工具，自动代码补全在软件工程中已不再是一种幻想。这些基于大型语言模型的工具，通常是在从公开、未经审查的来源中挖掘出的海量代码数据上进行训练的。因此，这类模型容易受到“数据投毒攻击”（data poisoning attacks）的威胁：攻击者通过在训练数据中注入恶意代码，从而操控模型的行为。此类攻击可被精心设计，以在运行时针对特定上下文影响模型的代码建议，例如诱导模型生成包含安全漏洞的代码片段。为了实现这一目的，以往的攻击方法通常直接将不安全的代码片段（即恶意载荷）显式地注入训练数据中，这使得这些“有毒”数据容易被静态分析工具检测到，并从训练集中清除。\n\n在本研究中，我们提出了两种新型攻击方法：**COVERT** 和 **TROJAN PUZZLE**，它们能够通过将恶意投毒数据隐藏在“上下文之外”的区域（例如代码的文档字符串 docstrings）中，从而绕过静态分析。其中，我们最创新的方法 **TROJAN PUZZLE** 更进一步：它**不会在投毒数据中显式包含载荷中某些（易被怀疑的）部分**，从而生成更不易引起怀疑的投毒样本；然而，当模型在代码补全任务中（即在 docstrings 之外的正常代码区域）进行建议时，仍能完整地生成整个恶意载荷。这种机制使得 **TROJAN PUZZLE** 能够有效抵御基于签名的训练数据清洗方法——这些方法通常依赖识别并过滤掉可疑的代码序列，但面对这种“隐式拼接”的载荷却无能为力。\n\n我们针对两种不同规模的模型进行了实验评估，结果表明：**COVERT** 和 **TROJAN PUZZLE** 对开发者在选择用于训练或微调代码补全模型的数据时具有重大警示意义。这提醒我们，必须高度重视训练数据的来源与安全性，否则看似无害的公开代码库可能潜藏精心构造的“逻辑后门”，最终导致模型在实际使用中生成危险的代码建议。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Protecting Label Distribution in Cross-Silo Federated Learning.pdf": {
        "title": "Protecting Label Distribution in Cross-Silo Federated Learning",
        "abstract": "—联邦学习（Federated Learning, FL）是一种流行的分布式机器学习（ML）框架，在该框架中，多个参与方通过共享模型参数而非原始训练数据，以保护隐私的方式共同构建一个全局模型。然而，现有的联邦学习方案主要侧重于通过引入差分隐私（Differential Privacy, DP）来保护单个训练样本的隐私，却忽视了训练数据集分布信息的保护。事实上，在涉及高风险的敏感应用中，数据分布本身也被视为高度敏感的信息。\n\n在本文中，我们首次提出了一种用于保护联邦学习中标注分布（label distribution）的隐私保护随机梯度下降（SGD）算法。为了建立形式化的隐私保障，我们提出了一种新的隐私定义，称为（m, γ, ξ）-标注分布隐私（label distributional privacy），用以量化标注分布信息的隐私泄露程度。随后，我们设计了标注分布扰动机制（Label Distribution Perturbation Mechanism, LDPM），该机制通过在SGD算法中精心引入随机性，确保所有“一对多”（one-vs-all）分类模型均满足（m, γ, ξ）-标注分布隐私。LDPM实现简单，且能提供非平凡的隐私保障，因此可作为一种即插即用的替代方案，直接替换现有的联邦学习本地模型训练算法。值得注意的是，我们进一步证明LDPM同样满足差分隐私（DP），这表明LDPM不仅提供了对标注分布的保护，也保障了个体数据的隐私，实现了个体隐私与分布隐私的双重保障。在六个基准数据集上的大量实验验证了LDPM的有效性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/From Principle to Practice：Vertical Data Minimization for Machine Learning.pdf": {
        "title": "From Principle to Practice：Vertical Data Minimization for Machine Learning",
        "abstract": "——为了训练和部署预测模型，各类组织会收集大量详细的客户数据，一旦发生数据泄露，将面临私人信息暴露的风险。为应对这一问题，政策制定者日益要求遵守“数据最小化”（Data Minimization, DM）原则，即仅收集与任务相关且必要的数据，限制数据收集的范围。尽管监管压力不断加大，但如何在机器学习模型的部署中切实遵循数据最小化原则，这一问题至今仍未得到足够重视。在本文中，我们全面应对这一挑战。\n\n我们提出了一种基于数据泛化的全新垂直数据最小化（vertical DM, vDM）工作流程。该流程在设计上确保在模型的训练和部署过程中，不会收集任何完整分辨率的客户数据，从而在发生数据泄露时缩小攻击面，有效保护客户隐私。我们形式化并研究了这一核心问题：寻找既能最大化数据效用、又能最小化实际隐私风险的泛化策略。为此，我们引入了一系列符合政策导向的对抗性场景，以量化隐私风险。\n\n此外，我们提出了一系列vDM基线算法，并设计了“隐私感知树”（Privacy-aware Tree, PAT）算法——这是一种特别高效的vDM算法，在多种实验设置下均优于所有基线方法。我们计划将代码开源，发布为一个公开可用的库，以推动机器学习中数据最小化技术的标准化进程。\n\n总体而言，我们相信本研究为在现实应用中进一步探索和实践数据最小化原则奠定了重要基础，有助于推动该原则在工业界和学术界的广泛采纳。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Large-Scale Study of Vulnerability Scanners for Ethereum Smart Contracts.pdf": {
        "title": "Large-Scale Study of Vulnerability Scanners for Ethereum Smart Contracts",
        "abstract": "以太坊智能合约是部署在区块链上的自主型去中心化应用，通常管理着价值数百万美元甚至更高的资产，因此已成为网络攻击的主要目标。仅在2023年，因智能合约漏洞导致的直接经济损失就超过10亿美元。为应对这些威胁，学术界和商业机构已开发出多种工具，用于检测并缓解智能合约中的安全漏洞。本研究旨在探讨现有安全扫描工具的实际有效性与其未能覆盖的现实漏洞之间的差距。为此，我们构建了四个不同的数据集进行分析：第一个数据集包含从区块链直接提取的77,219份智能合约源代码；第二个数据集涵盖从以太坊主网和测试网获取的超过400万份字节码；其余两个数据集分别为近14,000个经过人工标注的智能合约，以及373个经过专业审计验证的智能合约，为在字节码和源代码层面开展严格的“真实基准”（ground truth）分析提供了坚实基础。\n\n基于未标注数据集，我们对18种漏洞扫描工具进行了全面的定量评估，结果显示这些工具的检测结果存在显著差异。通过对“真实基准”数据集的分析，我们发现所有被测工具的性能均表现不佳。本研究进一步揭示了性能低下的根本原因，并强调当前智能合约安全领域的先进技术仍未能有效解决诸多公开挑战，表明**如何高效、准确地检测智能合约漏洞，依然是一个重大且尚未解决的难题**。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SneakyPrompt：Jailbreaking Text-to-image Generative Models.pdf": {
        "title": "SneakyPrompt：Jailbreaking Text-to-image Generative Models",
        "abstract": "——像Stable Diffusion和DALL·E这样的文本生成图像模型，由于可能生成有害内容（例如不适合在工作场合展示的NSFW图像），引发了诸多伦理问题。为应对这些伦理担忧，通常会采用安全过滤器来阻止NSFW图像的生成。在本文中，我们提出了SneakyPrompt——首个自动化攻击框架，旨在“越狱”文本生成图像模型，即使模型已部署安全过滤器，仍使其生成NSFW图像。当某个提示词（prompt）被安全过滤器拦截时，SneakyPrompt会反复向文本生成图像模型发起查询，并根据查询结果策略性地对提示词中的标记（tokens）进行扰动，从而绕过安全过滤机制。具体而言，SneakyPrompt利用强化学习来指导标记的扰动过程。我们的实验评估表明，SneakyPrompt能够成功绕过DALL·E 2中闭源的安全过滤器，生成NSFW图像。此外，我们还在Stable Diffusion模型上部署了多个最先进的开源安全过滤器。评估结果显示，SneakyPrompt不仅能够成功生成NSFW图像，而且在扩展用于攻击文本生成图像模型时，相较于现有的文本对抗攻击方法，在查询次数和生成NSFW图像的质量方面均表现更优。SneakyPrompt已开源，并可在以下仓库获取：https://github.com/Yuchen413/text2image_safety。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Efficient Actively Secure DPF and RAM-based 2PC with One-Bit Leakage.pdf": {
        "title": "Efficient Actively Secure DPF and RAM-based 2PC with One-Bit Leakage",
        "abstract": "近年来，基于随机存取机（RAM）模型的安全两方计算（2PC）引起了广泛关注。现有的大多数成果仅支持半诚实安全（semi-honest security），仅有Keller和Yanai在2018年欧密会（Eurocrypt）上提出的方案支持主动安全（active security），但其开销极高。在本文中，我们提出了一种高效、支持主动安全且仅泄露一比特信息的基于RAM的2PC协议。\n\n1) 我们提出了一种针对分布式点函数（Distributed Point Function, DPF）的、支持主动安全且仅泄露一比特信息的协议，其效率与当前最先进的半诚实安全协议基本相当。与此前工作相比，在域大小为2²⁰个条目的情况下，我们的协议通信量减少了约50倍，并且不再需要依赖通用型的主动安全2PC协议。\n\n2) 我们扩展了双执行协议（dual-execution protocol），使其支持反应式计算（reactive computation），并在此基础上，利用新的构建模块，构建了一个具有主动安全性的基于RAM的2PC协议。该协议遵循Doerner和Shelat在2017年CCS会议中提出的范式。我们能够证明，该协议在整个计算过程中仅存在端到端的一比特信息泄露。\n\n3) 我们的实验实现表明，该协议在实际运行效率上几乎与当前最先进的半诚实安全RAM-based 2PC协议相当，且比此前不支持信息泄露但具备主动安全性的RAM-based 2PC方案快至少两个数量级，从而在实践中提供了一个切实可行的安全与效率的权衡。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Combing for Credentials：Active Pattern Extraction from Smart Reply.pdf": {
        "title": "Combing for Credentials：Active Pattern Extraction from Smart Reply",
        "abstract": "——像GPT-2和BERT这样的预训练大型语言模型，通常通过微调（fine-tuning）来实现下游任务的当前最优性能。一个典型的例子是“智能回复”（Smart Reply）应用，其中预训练模型被调整，以便针对给定的查询消息提供建议回复。由于用于微调的数据通常包含敏感信息，例如电子邮件或聊天记录，因此理解并缓解模型泄露其微调数据的风险至关重要。我们研究了典型的智能回复流程中潜在的信息泄露漏洞。我们考虑一种现实场景：攻击者只能通过前端接口与底层模型交互，而该接口限制了可发送给模型的查询类型。以往的攻击在这种设置下无法奏效，因为它们通常要求能够直接向模型发送不受限制的查询。即使查询本身没有限制，以往攻击也通常需要成千上万，甚至数百万次查询才能提取出有用的信息；而我们的攻击仅需少数几次查询即可提取敏感数据。\n\n我们提出了一种新型的主动信息提取攻击，该攻击利用了包含敏感数据的文本中常见的典型模式（canonical patterns）。通过实验，我们证明：即使在现实场景中——所有与模型的交互都必须经过一个限制查询类型的前端接口——攻击者仍有可能从训练数据中提取出敏感的用户信息。我们进一步探讨了可能的缓解策略，并通过实验验证，差分隐私（differential privacy）似乎是一种能够有效抵御此类模式提取攻击的合理防御机制。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Withdrawing is believing. Detecting Inconsistencies between Withdrawal Choices and Third-party Data Collections in Mobile Apps.pdf": {
        "title": "Withdrawing is believing. Detecting Inconsistencies between Withdrawal Choices and Third-party Data Collections in Mobile Apps",
        "abstract": "诸如《通用数据保护条例》（GDPR）等主流隐私法规，通常允许用户撤回数据授权，例如著名的“选择退出权”（right to opt-out）。现代计算机软件（如移动应用程序，简称“应用”）通常会提供撤回界面，用于停止数据收集行为——例如来自第三方广告和分析库的数据收集——以尊重用户的撤回决定。然而，尽管这些界面被标记为“撤回”，其对应的撤回决策却常常与应用实际的数据收集行为不一致，尤其是在涉及第三方数据收集时。这种不一致在本文中被称为“撤回不一致性”（withdrawal inconsistency）。\n\n以往的研究要么聚焦于网站端的撤回不一致性，要么关注移动应用中的隐私泄露问题。然而，移动端的撤回不一致问题不同于网站，且更为复杂，原因在于：移动应用中的撤回界面形式多样，且所涉及的私人信息类型更加丰富。与此同时，现有检测移动应用隐私泄露的工具均未真正理解用户的撤回决策，更不用说将这些决策与应用的撤回行为关联起来。\n\n在本文中，我们设计并实现了一种新颖的方法，称为 **MOWCHECKER**，用于检测移动应用在第三方数据收集方面存在的不一致性。其核心思想是：用户的撤回选择应当满足以下两个条件之一——（1）在控制流上依赖于个人信息的流动路径，或（2）在数据流上依赖于第三方数据收集库所提供的撤回API。\n\n我们对 **MOWCHECKER** 在真实世界中的Android应用上进行了评估，结果发现了157个经人工确认的、此前未知的（即零日）撤回不一致性问题。我们已负责任地向相关应用开发者报告了这些问题，共收到23份回复，其中已有2个问题被修复。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/On Large Language Models' Resilience to Coercive Interrogation.pdf": {
        "title": "On Large Language Models' Resilience to Coercive Interrogation",
        "abstract": "——大型语言模型（LLM）正被广泛应用于众多场景，因此确保其伦理标准与人类一致变得至关重要。然而，现有的“越狱”（jail-breaking）攻击表明，这种对齐性可能被精心设计的提示（prompt）所破坏。在本文中，我们揭示了一种新的针对LLM对齐性的威胁：当恶意行为者能够访问模型在每个输出位置上的top-k（前k个）候选词预测时（这在所有开源LLM以及部分提供相关API的商业LLM中普遍存在，例如某些版本的GPT），即使不构造任何特殊提示，也可能破坏模型的对齐机制。\n\n该攻击方法的核心观察是：即使LLM拒绝回答有害请求，其潜在的有害回应仍隐藏在输出层的logits（未归一化的预测分数）深处。我们可以通过在自回归生成过程中，强制模型使用那些排名较低的输出词元（token），从而迫使模型“吐露”这些被隐藏的有害内容。值得注意的是，这种强制操作仅需在极少数精心选择的输出位置上实施即可。我们将这一技术称为“模型审问”（model interrogation）。\n\n与传统越狱方法不同，我们的方法在效果上显著优于当前最先进的越狱技术（成功率92%对比62%），并且速度快10至20倍。此外，通过该方法诱导出的有害内容质量更高。更重要的是，模型审问与越狱攻击是互补的：将两者协同结合使用时，整体性能优于单独使用任一方法。\n\n我们还发现，即使在专为编程任务定制（如代码生成）的模型中，通过模型审问依然能够提取出有害内容。这表明，该威胁不仅存在于通用对话模型中，也广泛适用于各类专用LLM，凸显出其严重性和普适性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SmartInv：Multimodal Learning for Smart Contract Invariant Inference.pdf": {
        "title": "SmartInv：Multimodal Learning for Smart Contract Invariant Inference",
        "abstract": "——智能合约是运行在区块链上的软件程序，支持多种多样的商业活动。近期研究发现了一类新型的“机器不可审计”漏洞，这类漏洞源于源代码未能满足底层交易上下文的要求。现有的漏洞检测方法依赖于人工理解底层交易逻辑，并需要跨多种信息源（即模态）进行手动推理，例如代码和描述预期交易行为的自然语言。\n\n为实现对“机器不可审计”漏洞的自动化检测，我们提出了 **S MART INV**，一个准确且高效的智能合约不变量（invariant）推断框架。我们的核心洞察是：智能合约的预期行为由不变量定义，而理解并推理这些行为需要融合多模态信息，包括源代码和自然语言描述。为此，我们提出了一种针对基础模型的新型微调与提示策略——**思维层级（Tier of Thought, ToT）**，使其能够跨智能合约的多种模态进行推理，并生成相应的运行时不变量。随后，S MART INV 通过检查这些生成的不变量是否被违反，来定位潜在的安全漏洞。\n\n我们在过去2.5年（2021年1月1日至2023年5月31日）内导致实际经济损失的真实智能合约漏洞上对 S MART INV 进行了评估。广泛的实验结果表明，S MART INV 能够生成高质量的不变量，有效定位“机器不可审计”漏洞，并从中发现了 **119个零日漏洞**。我们从中抽取了8个漏洞向相关开发团队进行了报告，其中 **6个漏洞被开发团队迅速修复**，并有 **5个被确认属于“高严重性”漏洞**。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models.pdf": {
        "title": "Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models",
        "abstract": "——网络仇恨是一个日益严重的问题，对互联网用户的生活造成了负面影响，并且由于不断演变的社会事件而迅速变化，导致一波又一波新型网络仇恨的涌现，构成严峻威胁。检测并缓解这些新型仇恨浪潮面临两大关键挑战：一方面，需要基于推理的复杂决策能力来判断内容是否具有仇恨性质；另一方面，可用于训练的数据样本有限，严重阻碍了检测模型的更新。\n\n为应对这一紧迫问题，我们提出了一种名为 **HATEGUARD** 的新型框架，旨在有效管控新型网络仇恨浪潮。HATEGUARD 采用基于推理的方法，利用近期提出的“思维链”（Chain-of-Thought, CoT）提示技术，充分挖掘大型语言模型（LLMs）的潜力。该框架进一步实现了基于提示的“零样本”检测（zero-shot detection），通过自动从新出现的仇恨浪潮样本中提取贬损性术语和攻击目标，并动态生成和更新检测提示，从而有效应对新型网络仇恨。\n\n为验证所提方法的有效性，我们构建了一个新的数据集，包含与三起近期发生的重大事件相关的推文：2022年俄罗斯入侵乌克兰、2021年美国国会山骚乱，以及新冠疫情（COVID-19）大流行。我们的研究发现，这些新型仇恨浪潮在事件演进过程中呈现出重要的纵向演变规律，凸显出亟需能够快速更新现有内容审核工具的技术，以及时应对新出现的仇恨模式。\n\n与当前最先进的检测方法进行对比评估的结果表明，我们的框架表现显著更优，在检测上述三种新型网络仇恨浪潮方面，性能提升了 **10.59% 至 88%**。本研究揭示了新型网络仇恨浪潮所带来的严重威胁，并标志着在应对这一威胁方面实现了实践意义上的范式转变。\n\n**免责声明**：本稿件包含有害内容，包括仇恨言论，可能具有冒犯性，并可能引起读者不适。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Sabre：Cutting through Adversarial Noise with Adaptive Spectral Filtering and Input Reconstruction.pdf": {
        "title": "Sabre：Cutting through Adversarial Noise with Adaptive Spectral Filtering and Input Reconstruction",
        "abstract": "神经网络（NNs）在交通、医疗、通信基础设施等关键领域的应用已势不可挡。然而，神经网络仍极易受到对抗性扰动的影响——即使输入发生看似微小甚至难以察觉的变化，也可能导致严重的误分类，这对其实际应用构成了严峻挑战。尽管已有大量研究致力于防御此类攻击，但对抗鲁棒性仍是一个悬而未决的难题，尤其是我们发现：现有防御方案在面对日益复杂的输入操纵时，其有效性往往以牺牲对正常样本的识别能力为代价。\n\n在本研究中，我们提出了SABRE——一种对抗防御框架，能够在不损害对正常样本识别性能的前提下，显著缩小正常准确率与鲁棒准确率之间的差距。具体而言，SABRE通过对输入进行谱分解，并结合基于能量的选择性滤波，提取出鲁棒的特征，用于在输入现有神经网络架构之前进行输入重建。\n\n我们通过图像分类、网络入侵检测以及语音指令识别等多个任务，验证了该方法在多种应用场景下的性能。实验结果表明，SABRE不仅在性能上优于现有防御机制，而且在不同神经网络架构、多种数据类型、已知或未知攻击类型，以及不同强度的对抗扰动下，均能保持稳定一致的表现。\n\n基于上述大量实验，我们有力地论证了SABRE在部署鲁棒且可靠的神经网络分类器方面的应用价值，主张其应被广泛采纳。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Janus：Safe Biometric Deduplication for Humanitarian Aid Distribution.pdf": {
        "title": "Janus：Safe Biometric Deduplication for Humanitarian Aid Distribution",
        "abstract": "人道主义组织为有需要的人群提供援助。为了高效利用其有限的预算，援助物资的分配流程必须确保合法受助者不会获得超过其应得份额的援助。因此，每个受助者在同一援助项目中最多只能注册一次，这一点至关重要。\n\n以红十字国际委员会的援助分发注册流程为实际案例，我们明确了在避免为受助者带来新风险的前提下，检测重复注册所需满足的技术要求。基于这些要求，我们设计了Janus系统——该系统结合了隐私增强技术与生物识别技术，以安全的方式防止重复注册。Janus不会创建明文的生物特征数据库，且在注册时仅揭示一位信息（即当前注册用户是否已存在于数据库中）。\n\n我们实现了Janus的三种具体技术方案，并进行了评估：第一种仅基于安全多方计算（SMC）；第二种采用半同态加密（SHE）与安全多方计算的混合方案；第三种基于可信执行环境（TEE）。实验表明，这三种方案均能满足人道主义组织对隐私保护、识别准确性和系统性能的实际需求。\n\n我们将Janus与现有的替代方案进行了对比，结果表明，Janus是首个在满足本场景所要求的识别准确率的同时，还能提供强有力隐私保护的系统。\n\n**关键词**：隐私保护型生物特征去重、隐私增强技术、生物特征去重、安全多方计算、半同态加密、可信执行环境、人道主义援助分发"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Larger-scale Nakamoto-style Blockchains Don't Necessarily Offer Better Security.pdf": {
        "title": "Larger-scale Nakamoto-style Blockchains Don't Necessarily Offer Better Security",
        "abstract": "关于中本聪式共识协议的广泛研究表明，网络延迟会削弱这些协议的安全性。已有研究结果表明，或许令人惊讶的是，当网络规模最小（仅有两个节点）时，安全性达到最高水平，因为随着网络规模扩大，延迟增加，导致安全性能下降。这与区块链的基本理念——即去中心化能够提升安全性——形成了矛盾。\n\n在本文中，我们深入探讨了网络规模如何影响中本聪式区块链的安全性。我们认为，现有安全模型忽略了一个关键因素：网络规模越大，攻击者就越难控制大量资源。为此，我们引入了一种**概率性腐败模型**（probabilistic corruption model），用以刻画攻击者在更大规模网络中获取并控制资源的难度递增现象。基于该模型，我们分析了节点数量对（最大）网络延迟以及攻击者所占算力（或权益）比例的影响。特别地，我们指出：\n\n（1）节点数量的增加最终会破坏安全性；  \n（2）但仅依赖少量节点也无法提供足够的安全保障。\n\n随后，我们通过一项实证研究验证了上述分析，模拟了比特币（Bitcoin）、门罗币（Monero）、卡尔达诺（Cardano）和以太坊经典（Ethereum Classic）等系统中数十万节点的部署场景。基于该实证分析，我们具体评估了各种现实世界参数和配置对现有系统中**一致性边界**（consistency bounds）的影响，以及在保证安全的前提下所能容忍的攻击者算力比例。\n\n据我们所知，这是首篇**结合解析分析与实证研究**，系统探讨当前主流中本聪式区块链部署在现实环境中所实现安全权衡的论文。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Holepunch：Fast, Secure File Deletion with Crash Consistency.pdf": {
        "title": "Holepunch：Fast, Secure File Deletion with Crash Consistency",
        "abstract": "如果一个文件系统在文件被删除后，能够确保即使攻击者物理获取了存储设备，也无法从已删除文件中恢复任何数据，那么该系统就提供了**安全删除**功能。然而，当前主流的商用文件系统普遍不提供安全删除功能。即便是那些明确希望实现安全删除的文件系统，也面临着现代存储设备中硬件控制器带来的复杂挑战：这些控制器隐藏了逻辑块与物理块之间的映射关系，会在后台静默地复制物理块，并且使得主机层面的软件难以对文件数据在设备上的实际存储方式做出可靠假设。此外，目前最先进的安全删除框架还缺乏**崩溃一致性**（crash consistency），这意味着一旦发生意外的断电或软件故障，加密密钥与其对应的加密文件数据之间就会失去同步，从而导致文件系统损坏。\n\n在本文中，我们提出了 **HOLEPUNCH**，一种新的、基于软件层面的安全删除实现方法。HOLEPUNCH 将存储设备视为一个“黑盒”，通过**密码学擦除**（cryptographic erasure）技术来实现安全删除。HOLEPUNCH 采用**每文件密钥**（per-file keys）机制，对用户写入的文件数据自动透明加密，并在读取时自动解密，从而确保存储设备上所有物理数据始终处于加密状态。\n\nHOLEPUNCH 使用**可穿孔伪随机函数**（puncturable pseudorandom functions, PPRFs）来快速访问文件密钥。当文件 f 被删除时，HOLEPUNCH 会更新该 PPRF，使得即使攻击者获取了 PPRF 的副本，也无法再利用它生成文件 f 的密钥。与之前工作中采用密钥树（key trees）的方法不同，HOLEPUNCH 使用 PPRFs 显著降低了两方面的开销：一是密钥管理带来的内存压力，二是访问文件所需的磁盘 I/O 次数。\n\n此外，HOLEPUNCH 将主密钥（master key）安全地存储在可信平台模块（TPM）中，并采用一种新颖的日志（journaling）机制，确保 TPM 内部状态与磁盘上的持久状态之间具有崩溃一致性。这样，即使系统发生意外崩溃，密钥与加密数据之间仍能保持正确同步，避免文件系统损坏。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Tabbed Out：Subverting the Android Custom Tab Security Model.pdf": {
        "title": "Tabbed Out：Subverting the Android Custom Tab Security Model",
        "abstract": "移动操作系统为开发者提供了多种“移动端到Web”的桥梁，使原生应用能够嵌入并显示网页内容。最近引入的一个名为“自定义标签页”（Custom Tab，简称CT）的组件，提供了一项突破性的功能，克服了传统WebView在可用性方面的诸多局限：它能够与底层浏览器共享状态。与传统WebView类似，CT也能让宿主应用实时获知当前的网页浏览行为。在本文中，我们首次对CT组件进行了系统性的安全评估，揭示了其在安全模型设计之初并未充分考虑“跨上下文状态推断攻击”（cross-context state inference attacks）这一关键问题。\n\n我们发现，CT可被利用实现多种攻击：  \n- 精细化的用户浏览数据泄露（fine-grained exfiltration of sensitive browsing data）；  \n- 绕过SameSite Cookie机制，破坏Web会话的完整性；  \n- 通过定制CT的用户界面（UI），诱导用户陷入钓鱼攻击，造成信息泄露。\n\n为评估CT在实际应用中的普及程度，以及我们提出缓解措施的可行性，我们对超过5万个Android应用进行了首次大规模分析。结果表明，CT的使用极为广泛：**83%的应用**直接嵌入或作为第三方库的一部分集成了CT组件。\n\n我们已将所有发现负责任地披露给Google。Google已迅速采取针对性缓解措施，为发现的漏洞分配了三个CVE编号，并向我们颁发了10,000美元的漏洞奖励。在与Google的协作过程中，我们推动了CT安全模型的澄清，相关内容已被纳入新版《Chrome 自定义标签页安全常见问题》（Chrome Custom Tabs Security FAQ）文档中。\n\n这项工作不仅揭示了现代移动Web集成架构中的深层安全风险，也展示了学术界与工业界合作提升平台安全性的有效路径。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/MPC-in-the-Head Framework without Repetition and its Applications to the Lattice-based Cryptography.pdf": {
        "title": "MPC-in-the-Head Framework without Repetition and its Applications to the Lattice-based Cryptography",
        "abstract": "—“MPC-in-the-Head”（头脑中的多方计算）框架因其高效的证明生成能力，已被提出作为非交互式零知识知识论证（NIZKAoK）的一种解决方案。然而，目前大多数基于该方法的NIZKAoK构造都需要进行多次多方计算（MPC）评估，才能实现可忽略的可靠性误差（soundness error），从而导致证明的大小和生成时间在渐进意义下至少是NP关系对应电路大小的λ倍（λ为安全参数）。在本文中，我们提出了一种新方法，能够消除对重复MPC评估的需求，从而构建出一种适用于任意NP关系的NIZKAoK协议，我们称之为**Diet**。Diet的证明大小和生成时间在渐进意义上仅与NP关系对应电路C的大小呈**多对数关系**（polylogarithmic），而与安全参数λ无关。因此，证明的大小和生成时间均可显著降低。\n\n此外，Diet在证明“学习有误差”（Learning With Errors, LWE）问题及其变体时，展现出卓越的实际效率。综合考虑证明大小和证明时间两个因素，我们的方案在性能上显著优于其他现有方案。具体而言，Diet为基于格的密钥封装机制（KEM）——如Frodo和Kyber——提供了证明私钥知识的高效方法，为未来后量子时代的证书管理提供了实用的解决方案。针对Kyber 512，我们的实现达到了仅**83.65千字节（KB）的在线证明大小**，并附带**152.02KB的预处理开销**。在运行效率方面，其在线证明时间仅为**0.68秒**，预处理时间为**0.81秒**，整体实现效率极高。值得注意的是，我们的工作是**首个基于后量子原语实现Kyber 512私钥知识证明的可报告实现**，填补了后量子零知识证明在实际应用中的关键空白。\n\n白伟豪（Weihao Bai）与陈龙（Long Chen）为论文作出同等贡献，应被视为共同第一作者。陈龙（Long Chen）和张振峰（Zhenfeng Zhang）为论文的通讯作者。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Everyone for Themselves. A Qualitative Study about Individual Security Setups of Open Source Software Contributors.pdf": {
        "title": "Everyone for Themselves. A Qualitative Study about Individual Security Setups of Open Source Software Contributors",
        "abstract": "为了提升开源软件供应链的安全性，保护贡献者的开发环境免受攻击至关重要。例如，贡献者必须妥善保护其用于软件仓库的身份验证凭证、代码签名密钥，以及防范其系统遭受恶意软件感染。\n\n以往的安全事件表明，开源贡献者在保护自身开发环境方面面临诸多挑战。与企业不同，开源软件项目难以对开发环境的安全规范进行统一强制要求。相反，贡献者的安全配置在所选技术和策略上往往呈现出高度异质性。\n\n据我们所知，本研究首次对开源软件贡献者个人安全配置的安全性进行了深入的定性研究，涵盖其安全动机、决策过程、主观态度，以及对开源软件供应链安全的潜在影响。为此，我们对来自关键开源软件项目的20位经验丰富的贡献者进行了半结构化访谈，受访者背景多样。\n\n总体而言，我们发现贡献者普遍对安全问题具有较高的敏感度和重视程度。然而，安全实践在开源社区中很少被讨论，也很少被项目方强制执行。此外，信任、尊重、礼貌等社会性机制对贡献者行为产生了显著影响，反而进一步阻碍了安全知识和最佳实践的传播与共享。\n\n最后，我们在文中讨论了本研究结果对开源软件及供应链安全的影响，并针对开源软件社区提出了若干建议。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/GrOVe：Ownership Verification of Graph Neural Networks using Embeddings.pdf": {
        "title": "GrOVe：Ownership Verification of Graph Neural Networks using Embeddings",
        "abstract": "图神经网络（Graph Neural Networks, GNNs）已成为建模并从大规模图结构数据中进行推断的一种前沿方法，广泛应用于社交网络等场景。GNN的核心目标是学习数据集中每个图节点的嵌入表示（embedding），该表示不仅编码节点自身的特征，还融合了节点周围局部图结构的信息。\n\n已有研究表明，GNN容易受到模型提取攻击（model extraction attacks）的威胁。尽管模型提取攻击及其防御机制在其他非图结构场景中已被广泛研究，但检测和预防此类攻击仍极具挑战。相较之下，通过有效的所有权验证（ownership verification）技术来威慑攻击，是一种更具前景的防御手段。在非图场景中，对模型或训练数据进行“指纹”（fingerprinting）标记，已被证明是实现所有权验证的一种有效方式。\n\n我们提出了GROVE，一种先进的GNN模型指纹方案。给定一个目标模型和一个待检测的嫌疑模型，GROVE能够可靠地判断该嫌疑模型是独立训练所得，还是通过模型提取攻击从目标模型中窃取得到的代理模型（surrogate model）。实验表明，即使独立模型与原始目标模型使用了相同的训练数据集和模型架构，GROVE仍能准确区分二者。\n\n通过在六个基准数据集和三种模型架构上的测试，我们验证了GROVE在误报率（false-positive rate）和漏报率（false-negative rate）方面均表现稳定且较低。此外，GROVE对已知的指纹规避技术具有鲁棒性，同时保持了较高的计算效率。\n\n关键词：图神经网络；模型提取；所有权验证。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Real-Time Website Fingerprinting Defense via Traffic Cluster Anonymization.pdf": {
        "title": "Real-Time Website Fingerprinting Defense via Traffic Cluster Anonymization",
        "abstract": "——网站指纹（Website Fingerprinting, WF）攻击对Tor等匿名网络中的用户隐私构成了严重威胁。尽管已有多种防御方案被提出，但它们难以有效抵御近年来基于深度学习的WF攻击。在本文中，我们提出了Palette，一种新颖且实用的WF防御机制，通过流量聚类匿名化技术来保护实时的Tor流量。Palette将流量模式高度相似的网站进行聚类，并将每个聚类（即一组相似网站）中的流量统一调整为一个精心设计的标准化流量模式。通过这种方式，Palette使得攻击者无法区分同一聚类内的相似网站，从而提供了更强的匿名性保障。\n\n基于公开的真实世界数据集进行的全面评估表明，Palette在性能上显著优于现有防御方案，能够以可接受的开销大幅降低当前最先进（State-of-the-Art, SOTA）WF攻击的识别准确率。此外，我们将Palette实现为Tor网络中的可插拔传输（Pluggable Transport）模块。实验结果表明，Palette平均可将SOTA WF攻击的准确率降低73.60%，相较于现有防御方案，性能提升了33.50%至43.47%。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Scalable Verification of Zero-Knowledge Protocols.pdf": {
        "title": "Scalable Verification of Zero-Knowledge Protocols",
        "abstract": "零知识（ZK）证明的应用在工业界正迅速增长，已成为实现公共分布式账本中隐私保护与可扩展性提升的关键技术。在实际的大多数ZK系统中，待证明的命题通常通过一组定义在素数域上的多项式方程来表达，这些方程描述了算术电路。使用此类约束来描述一般性命题是一项复杂且容易出错的任务。虽然可以通过高级编程语言部分缓解这一问题，但代价是失去对新增约束的控制，从而导致针对复杂命题所构建的系统规模过大。在此背景下，拥有能够自动验证约束系统性质的工具，对于保障协议的安全性至关重要。然而，由于验证复杂性质需要对有限域上的非线性多项式进行推理，现有的自动化工具要么无法扩展，要么无法检测出非平凡的漏洞。\n\n本文提出了一种新的可扩展、模块化的技术，该技术基于一系列经过验证的转换和演绎规则，能够高效地验证以素数域上一组多项式方程形式表示的电路信号的性质。我们已将这一技术实现为一个名为CIVER的工具，并将其应用于验证用circom语言编写的电路的安全性质——circom是目前定义ZK协议最流行的语言之一。我们成功分析了多个大型工业级电路，并检测出由资深程序员设计的电路中存在的细微漏洞。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Test-Time Poisoning Attacks Against Test-Time Adaptation Models.pdf": {
        "title": "Test-Time Poisoning Attacks Against Test-Time Adaptation Models",
        "abstract": "——将机器学习（ML）模型部署到现实场景中极具挑战性，因为模型面临**分布偏移**（distribution shift）问题：即在原始领域上训练的模型，难以泛化到未见过的、多样化的迁移领域。为解决这一问题，研究者提出了多种**测试时自适应**（Test-Time Adaptation, TTA）方法，旨在提升预训练模型在测试数据上的泛化能力，以应对分布偏移。TTA 的成功之处在于：在测试阶段，模型能够根据测试样本提供的分布线索，持续进行微调。\n\n然而，尽管 TTA 方法性能强大，它也引入了一个新的攻击面——**测试时投毒攻击**（test-time poisoning attacks）。这种攻击与传统的训练时投毒攻击有本质区别：在训练时投毒中，攻击者可以干预模型的训练过程；而在测试时投毒中，攻击者无法参与训练，只能在测试阶段向模型输入恶意构造的样本。\n\n在本文中，我们首次对四种主流 TTA 方法（TTT、DUA、TENT 和 RPL）实施了测试时投毒攻击。具体而言，我们基于替代模型（surrogate models）生成投毒样本，并将其输入目标 TTA 模型。实验结果表明，这些 TTA 方法普遍容易受到测试时投毒攻击的影响。例如，攻击者仅需输入**10个**投毒样本，即可将目标模型的性能从 76.20% 降至 41.83%。\n\n我们的研究结果揭示：**未经严格安全评估的 TTA 算法不适合在真实场景中部署**。因此，我们呼吁：在 TTA 方法的设计中，应**内嵌针对测试时投毒攻击的防御机制**，以增强其鲁棒性和安全性。\n\n1. 引言部分（注：原文末尾的“1”可能为脚注或章节编号，此处按学术论文章节结构理解为第1节的结尾，故译为“1.”）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：SGX.Fail：How Stuff Gets eXposed.pdf": {
        "title": "SoK：SGX.Fail：How Stuff Gets eXposed",
        "abstract": "——英特尔软件防护扩展（Software Guard Extensions, SGX）承诺提供一个隔离的执行环境，该环境受到保护，不受机器上运行的所有软件的影响。正因如此，大量研究工作致力于利用SGX，在对抗性环境中为代码运行提供机密性和完整性保障。然而，在过去的几年中，SGX受到了猛烈抨击，面临诸多硬件层面的攻击威胁。英特尔不断通过补丁修复SGX的安全漏洞，同时持续推出新的（微）架构，这使得人们越来越难以判断各种攻击技术在SGX不同设计版本中的适用性。\n\n因此，在本文中，我们旨在对各类SGX攻击进行系统性梳理与分类，分析这些攻击在不同SGX架构上的适用性，以及它们所泄露的信息类型。随后，我们进一步探讨SGX的更新机制在防止真实世界部署中遭受攻击时的有效性。为此，我们研究了两个商用SGX应用实例。首先，我们调查了SECRET网络——一个基于SGX的区块链平台，旨在提供保护隐私的智能合约功能。其次，我们还考察了PowerDVD，这是一款用于在个人电脑上播放超高清（UHD）蓝光光盘的数字版权管理（DRM）软件。\n\n我们发现，在这两个案例中，厂商均未能实现其产品设计之初所设定的安全目标。这很可能是由于SGX更新周期过长，以及手动更新流程的复杂性所致。这种现实迫使厂商不得不在安全性与可用性之间做出艰难的权衡，最终导致安全性的妥协。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/P4Control：Line-Rate Cross-Host Attack Prevention via In-Network Information Flow Control Enabled by Programmable Switches and eBPF.pdf": {
        "title": "P4Control：Line-Rate Cross-Host Attack Prevention via In-Network Information Flow Control Enabled by Programmable Switches and eBPF",
        "abstract": "——现代定向攻击（如高级持续性威胁，Advanced Persistent Threats）利用多台主机作为跳板，在主机之间横向移动，以获取对网络更深层的访问权限。然而，现有的防御机制缺乏跨主机的端到端信息流可见性，无法实时阻断跨主机的攻击流量。在本文中，我们提出了 P4CONTROL，一种新型网络防御系统，能够精确限制网络中的端到端信息流，并以线速（line rate）实时阻止跨主机攻击。\n\nP4CONTROL 引入了一种新颖的、基于网络的去中心化信息流控制（Decentralized Information Flow Control, DIFC）机制，是首个能够在网络层以网络线速强制执行 DIFC 的技术方案。该系统的实现依赖于以下两个核心组件：（1）基于可编程交换机的网络内原语（in-network primitive），用于追踪主机间的信息流，并以线速执行 DIFC 策略；（2）部署在主机上的轻量级 eBPF 原语，用于追踪主机内部的信息流。此外，P4CONTROL 还提供了一种表达性强的策略框架，支持针对多种攻击场景定义细粒度的 DIFC 策略。\n\n我们进行了广泛的实验评估，结果表明：P4CONTROL 能够实时、有效地阻止跨主机攻击，同时保持线速网络性能，并对网络和主机设备施加极小的性能开销。特别值得注意的是，P4CONTROL 通过其细粒度的最小权限网络访问控制机制，能够有效促进零信任（Zero Trust）架构的实现。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Obelix：Mitigating Side-Channels Through Dynamic Obfuscation.pdf": {
        "title": "Obelix：Mitigating Side-Channels Through Dynamic Obfuscation",
        "abstract": "可信执行环境（Trusted Execution Environments, TEEs）提供了由硬件辅助的机制，用于保护代码和数据的安全。然而，多年来的大量研究表明，攻击者可以利用侧信道（side-channels）泄露数据的访问模式，甚至能够单步跟踪程序的执行过程。尽管厂商正在逐步引入针对某些攻击的硬件级防御措施，但仍有很多攻击方式尚未得到解决。因此，软件层面的防护机制变得十分必要，但目前现有的解决方案要么仅针对非常特定的攻击方式，要么仅适用于有限的泄露模型。\n\n在本研究中，我们对TEE的漏洞进行了全面的分析，并设计了一款名为**OBELIX**的工具。该工具是首个能够同时保护代码和数据、抵御多种TEE攻击的解决方案，其防护范围涵盖从缓存攻击、单步执行攻击到密文侧信道攻击等多种威胁。我们首先分析了当前最先进的单步执行攻击工具在实际应用中能达到的精度，并基于这一分析提出了一种算法：该算法利用对攻击能力的认知，将程序划分为多个“统一代码块”，使得即使对于能力强大的攻击者，这些代码块也无法被区分。\n\n通过将这些代码块以及程序数据存储在“无意识随机存储器”（Oblivious RAM, ORAM）中，攻击者将无法追踪程序的执行流程，从而有效地保护了机密代码和敏感数据。我们还详细描述了如何自动化整个流程，使得即使是不熟悉侧信道攻击的开发者也能轻松使用OBELIX。\n\n作为一款代码混淆与防护工具，OBELIX确实会带来显著的性能开销，但作为补偿，它提供了强大的安全保障，并且无需用户具备专家级知识即可轻松集成和应用。其易用性与高安全性相结合，使其成为当前TEE环境下极具实用价值的防护方案。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Securing Graph Neural Networks in MLaaS：A Comprehensive Realization of Query-based Integrity Verification.pdf": {
        "title": "Securing Graph Neural Networks in MLaaS：A Comprehensive Realization of Query-based Integrity Verification",
        "abstract": "——图神经网络（GNN）在“机器学习即服务”（MLaaS）中的部署，开辟了新的攻击面，并加剧了以模型为中心的攻击所带来的安全担忧。这类攻击可在模型服务阶段直接操纵GNN的模型参数，导致预测错误，对关键的GNN应用构成严重威胁。然而，传统的完整性验证方法在此场景下效果不佳，原因在于MLaaS的架构限制以及GNN模型自身独特的结构特性。\n\n在本研究中，我们提出了一种突破性的方法，旨在保护MLaaS环境中的GNN模型免受以模型为中心的攻击。我们的方法构建了一个全面的GNN完整性验证框架，不仅同时支持传导式（transductive）和归纳式（inductive）GNN模型，还能适应模型部署前已知信息各异的实际情况。我们提出了一种基于查询的验证技术，并辅以创新的节点“指纹”生成算法，以增强验证能力。为应对那些事先已了解我们防御机制的高级攻击者，我们在设计中引入了随机化的指纹节点，以提升系统的抗攻击鲁棒性。\n\n实验评估表明，我们的方法能够有效检测五种具有代表性的对抗性模型中心攻击，其效率相比现有基线方法提升了2到4倍。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/ARMOR：A Formally Verified Implementation of X.509 Certificate Chain Validation.pdf": {
        "title": "ARMOR：A Formally Verified Implementation of X.509 Certificate Chain Validation",
        "abstract": "我们提出了 ARMOR，这是首个在 X.509 证书链验证逻辑（CCVL）实现方面做出的实质性努力，为 RFC 5280 的绝大部分内容提供了形式化、经机器验证的正确性保证。ARMOR 的设计具有双重目标：1）提供一份形式化、经机器验证的 RFC 规范替代方案；2）构建一个参考实现和测试预言机（test oracle）。ARMOR 采用模块化架构，将 X.509 证书链验证逻辑分解为多个模块，每个模块均可独立进行形式化规约、实现和验证。目前，ARMOR 中已形式化验证的模块包括：（子集）PEM 和 ASN.1 X.690 DER 语言的规约与解析、证书链构建，以及关于单个证书内部字段和证书链中跨证书字段所需满足的众多语义属性。为了实证评估其是否达成上述目标，我们针对规范准确性和运行时开销，将 ARMOR 与 11 个开源 X.509 实现以及一个开源证书检查工具（certificate linter）进行了对比。在评估中，尽管 ARMOR 带来了较高的运行时开销，但其使用使我们成功检测出若干不符合 RFC 规范的行为。最后，我们通过将 ARMOR 集成到 BoringSSL 的 TLS 1.3 实现中，并使用 Curl 进行测试，展示了其在端到端场景中的实际应用。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/E-Vote Your Conscience：Perceptions of Coercion and Vote Buying, and the Usability of Fake Credentials in Online Voting.pdf": {
        "title": "E-Vote Your Conscience：Perceptions of Coercion and Vote Buying, and the Usability of Fake Credentials in Online Voting",
        "abstract": "——在线投票因其便捷性和可及性而具有吸引力，但相较于现场投票，它更容易受到选民胁迫和选票买卖的影响。一种缓解策略是向选民提供“虚假投票凭证”，他们可以将这些凭证交给胁迫者。虚假凭证在外观上与真实凭证完全相同，但其所投的选票将被系统静默排除在最终计票结果之外。一个尚未解决的重要问题是：普通选民如何看待这种缓解措施？他们是否能够理解并使用虚假凭证？这种缓解措施所带来的成本，是否值得为降低胁迫风险而付出？\n\n我们首次对这些问题进行了系统性研究，研究对象为马萨诸塞州波士顿市的150名背景多样的个体。所有参与者都在一次模拟选举中完成了“注册”和“投票”：其中120人体验了通过虚假凭证实现的防胁迫机制，其余人作为对照组。在接触过虚假凭证的120名参与者中，96%的人理解其用途；53%的人表示，如果现实投票中提供这种机会，他们愿意创建虚假凭证；然而，有10%的人错误地使用了虚假凭证进行投票（即本应使用真实凭证时却用了假的）。此外，22%的参与者报告称，他们本人曾经历过或亲眼目睹过胁迫或选票买卖事件。这些有过相关经历的参与者认为，这种具备防胁迫功能的系统，其可信度几乎与传统的现场手写纸质投票相当。\n\n在全部150名使用该系统的人中，87%能够独立完成凭证创建；83%的人不仅成功创建了凭证，还正确使用了它们。参与者为该系统的可用性打出了70.4分（系统可用性量表，SUS），略高于行业平均分68分。\n\n我们的研究结果总体上支持了“胁迫问题确实重要”这一观点，也表明“虚假凭证”作为一种潜在的缓解手段具有良好的前景。然而，用户操作错误率仍然是一个亟待解决的重要可用性挑战，需要在未来的研究和设计中加以改进。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/CryptoVampire：Automated Reasoning for the Complete Symbolic Attacker Cryptographic Model.pdf": {
        "title": "CryptoVampire：Automated Reasoning for the Complete Symbolic Attacker Cryptographic Model",
        "abstract": "— 密码协议的设计和正确性验证非常困难，这一点从不断增多的针对协议标准的攻击案例中可见一斑。密码学的符号模型能够对协议在理想化密码模型下进行自动化的形式化安全证明，这种模型忽略了密码方案本身的代数性质，因此可能会遗漏某些实际攻击。而计算模型虽然提供了严格的安全保证，但目前仅支持交互式证明，以及/或仅适用于受限类型的协议（如无状态协议）。一种有前景的方法是由BC逻辑形式化定义的计算完备符号攻击者（Computationally Complete Symbolic Attacker, CCSA）模型，其目标在于弥合上述两种范式的鸿沟，取二者之长，通过符号化协议分析来获得密码学意义上的安全保证。BC逻辑最近由一个名为SQUIRREL的交互式定理证明器支持，该工具支持机器可验证的交互式安全证明（而非自动化证明），因此要求使用者既具备密码学知识，又掌握形式化推理技能。\n\n在本文中，我们提出了CRYPTO VAMPIRE密码协议验证器，这是首个在BC逻辑中完全自动化证明**迹属性**（trace properties）的工具。其关键技术贡献在于：对协议属性进行一阶逻辑形式化，并针对子项（subterm）关系设计了专门的处理机制。通过这种方式，我们克服了在高阶逻辑中进行交互式证明的负担，仅使用一阶推理即可自动建立密码协议的**可靠性**（soundness）。我们对密码协议的一阶编码面临诸多挑战。从理论角度看，我们在完整一阶逻辑中引入密码学公理，并加以限制，以确保：尽管牺牲了高阶BC逻辑的表达能力，但在一阶编码中仍能保持协议的安全性不被破坏。从实践角度看，CRYPTO VAMPIRE集成了专门设计的证明技术，采用一阶饱和算法与启发式策略，共同使其能够利用当前最先进的VAMPIRE一阶自动定理证明器作为底层证明引擎。\n\n我们的实验结果展示了CRYPTO VAMPIRE作为独立验证器的有效性，同时也体现了其在SQUIRREL工具中作为自动化辅助支持方面的价值。\n\n**关键词**——安全协议，形式化方法，计算安全性，自动定理证明"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Titan ：Efficient Multi-target Directed Greybox Fuzzing.pdf": {
        "title": "Titan ：Efficient Multi-target Directed Greybox Fuzzing",
        "abstract": "——现代定向模糊测试（directed fuzzing）在同时分析程序中的多个目标时，常常面临可扩展性（scalability）问题。我们发现，其根本原因在于定向模糊测试工具并不了解各个目标之间的相关性，因此可能退化为一种“无目标导向”的模糊测试方法。结果是，当需要复现多个目标时，定向模糊测试的效率会严重下降。\n\n本文提出了Titan，该方法使模糊测试工具能够识别程序中不同目标之间的相关性，从而优化输入生成过程，以更高效地复现多个目标。Titan利用这些相关性，在种子调度阶段区分每个种子到达不同目标的潜力，并在变异阶段识别出可以同时修改的字节。我们将Titan与八种最先进的（定向）模糊测试工具进行了对比。评估结果表明，Titan在高效检测多个目标方面显著优于现有方法，实现了高达21.4倍的加速，并且所需执行次数减少了95.0%。此外，在最新版本的基准测试程序中，Titan还发现了九处其他定向模糊测试工具无法检测到的“修复不完整”（incomplete fixes）问题，其中两个问题已被分配CVE编号。\n\n关键词 —— 定向模糊测试，多目标，路径相关性"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Springproofs：Efficient Inner Product Arguments for Vectors of Arbitrary Length.pdf": {
        "title": "Springproofs：Efficient Inner Product Arguments for Vectors of Arbitrary Length",
        "abstract": "内积论证（Inner Product Argument, IPA）是一种知识论证，用于证明两个已承诺的向量满足内积关系。借助 Bootle 等人 2016 年提出的递归证明技术，IPA 的证明大小仅随向量长度呈对数增长，且无需可信设置。这种简洁的证明特性使 IPA 非常适合区块链应用。然而，目前的 IPA 方案仅能处理长度为 2 的幂的向量，这限制了其实际应用。一种直接的解决方案是通过补零（zero-padding）来扩展向量长度，但这会带来额外的计算和存储开销。\n\n我们提出了 **Springproofs**，一种从多种现有 IPA 方案中推导出的新型框架。Springproofs **天然支持任意长度的向量**。通过一种新颖的递归压缩结构，Springproofs 在保持与原始 IPA 相同证明大小的同时，实现了更高的计算效率。特别地，我们以 Bulletproofs 为基础实例化 Springproofs，并找到了该场景下最优的递归结构。\n\n首先，实验表明，当向量长度略大于 2 的幂时，Springproofs 在范围证明（range proof）上的性能几乎比 Bulletproofs 快一倍。随后，我们将 Springproofs 集成到 Monero 中——一种支持交易隐私的主流加密货币，结果表明：基于 Springproofs 的 Monero 在交易生成和验证两方面均优于基于 Bulletproofs 的版本。\n\n此外，我们将 Springproofs 应用于通用算术电路，包括 SHA256、Merkle 树以及典型统计计算等场景，实验结果显示其性能均优于使用 Bulletproofs 的情况。值得注意的是，Springproofs 扩展了 Bulletproofs 性能优于 Groth16 的参数范围，同时自然地继承了 Bulletproofs 的诸多优势，例如：**无需初始可信设置、支持证明聚合以及批量验证**。\n\n因此，Springproofs 在诸多领域具有广阔的应用前景，包括加密货币中的机密交易（confidential transactions），以及智能合约中针对特定算术电路的隐私计算（privacy computing）。\n\n**关键词**：零知识证明，内积论证，范围证明，隐私计算，区块链"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Routing Attacks on Cryptocurrency Mining Pools.pdf": {
        "title": "Routing Attacks on Cryptocurrency Mining Pools",
        "abstract": "——矿池一直是保障多种工作量证明（PoW）加密货币安全性的核心驱动力。在事实上的标准协议Stratum下，矿池使矿工能够协同工作，共同发现新区块并分享收益。最近，区块链社区正积极推动采用一种更安全的新版协议——Stratum V2。在本文中，我们提出了一种名为**EROSION**的新型网络层攻击，该攻击适用于Stratum和Stratum V2两种协议。EROSION攻击的核心在于其能够破坏矿工与目标矿池之间的连接，严重削弱矿工所贡献的工作量证明（PoW），从而降低受害矿池的挖矿算力。我们还发现，Stratum V2协议中存在一个漏洞：攻击者仅需篡改单个数据包，即可实现对连接的持续性干扰，这显著增强了攻击的隐蔽性。我们的调查显示，EROSION攻击者可以轻松对前十大加密货币中绝大多数（例如91%）的矿池发起攻击。我们还观察到严重的挖矿中心化现象，使得攻击者能够同时针对多个矿池和多种加密货币实施协同打击。此外，我们对比特币矿池挖矿的深入分析表明，成千上万个不同的攻击者实体可能掌控比特币全网过半的挖矿算力；其中，一个潜在的恶意自治系统（AS）甚至可能瘫痪全网高达96%的总挖矿算力。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Children, Parents, and Misinformation on Social Media.pdf": {
        "title": "Children, Parents, and Misinformation on Social Media",
        "abstract": "——儿童在社交媒体上接触虚假信息的情况，与其父母类似。但与父母不同的是，儿童是一个尤为脆弱的群体，因为他们的认知能力和情绪调节能力仍在发展，使他们更容易受到网络虚假信息的误导和欺骗。然而，目前人们对儿童如何经历虚假信息，以及父母如何看待虚假信息对儿童成长的影响，仍知之甚少。为回答这些问题，我们结合了针对父母的质性问卷调查（n=87）以及对父母和儿童的半结构化访谈（n=12）。\n\n研究发现，儿童将虚假信息识别为社交媒体上用于“欺骗他人”的内容，例如深度伪造（deep fakes）、带有政治背景的梗图（memes），或关于名人/网红的谣言。儿童表示，在通过谷歌搜索或向父母求证内容真实性之前，他们会先询问Siri：“这个社交媒体上的视频或帖子是不是为了骗我？”\n\n父母们普遍表达了对子女易受虚假信息影响的担忧，认为帮助孩子在社交媒体上辨别虚假信息、培养批判性思维的重担落在了自己肩上。大多数父母认为，学校也应承担起教育责任，向儿童传授这些技能，以及媒体素养教育。\n\n父母和儿童一致认为，虚假信息会影响家庭关系，尤其是当他们与持有不同政治观点的祖辈互动时，这种影响尤为明显。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Side-Channel-Assisted Reverse-Engineering of Encrypted DNN Hardware Accelerator IP and Attack Surface Exploration.pdf": {
        "title": "Side-Channel-Assisted Reverse-Engineering of Encrypted DNN Hardware Accelerator IP and Attack Surface Exploration",
        "abstract": "深度神经网络（DNN）凭借其卓越的性能，已在众多应用领域引发革命性变革。随着模型规模不断增大、结构日益复杂，硬件DNN加速器正变得越来越普及。基于现场可编程门阵列（FPGA）的DNN加速器在效率上接近专用集成电路（ASIC），同时具备极强的灵活性，使其成为快速发展的深度学习实现方案（尤其在边缘设备中）的主要硬件平台之一。这种重要性使得FPGA DNN加速器成为攻击者极具吸引力的目标。\n\n目前针对FPGA DNN加速器上部署的DNN模型机密性所发起的攻击，通常假设攻击者完全了解加速器的内部结构和实现细节。然而，这一假设在现实世界中并不成立——尤其在专有、高性能的商业化FPGA DNN加速器中，其设计细节往往是保密的。为此，在本研究中，我们提出了一套全面且高效的逆向工程方法，用于解析FPGA DNN加速器的软核知识产权（IP）模块。我们以先进的AMD-Xilinx深度学习处理单元（DPU）为实例，展示了该方法的应用。\n\n我们的方法结合了电路原理图分析，并创新性地引入电磁（EM）侧信道分析技术，以揭示DNN加速器内部的数据流与任务调度机制。据我们所知，本研究是首个成功实现对商业加密DNN加速器IP进行逆向工程的尝试。进一步，我们基于逆向工程所揭示的信息，深入探讨了由此暴露的攻击面，包括成功恢复DNN模型架构以及提取模型参数。这些成果对现实世界中的商业化FPGA-DNN加速系统构成了重大安全威胁。\n\n最后，我们讨论了可能的防御对策，并针对FPGA平台上的IP保护提出了具体建议。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Universal Neural-Cracking-Machines：Self-Configurable Password Models from Auxiliary Data.pdf": {
        "title": "Universal Neural-Cracking-Machines：Self-Configurable Password Models from Auxiliary Data",
        "abstract": "我们提出了“通用”密码模型的概念——这是一种一旦经过预训练，便可根据目标系统自动调整其猜测策略的密码模型。为实现这一目标，该模型无需访问目标凭证中的任何明文密码。相反，它利用用户的辅助信息（如电子邮件地址）作为代理信号，来预测潜在的密码分布。\n\n具体而言，该模型利用深度学习技术，捕捉一组用户（例如某个网络应用的用户）的辅助数据与其密码之间的相关性。随后，在推理阶段，模型利用这些学习到的模式，为目标系统生成一个量身定制的密码模型。整个过程无需额外的训练步骤，也无需专门收集目标数据，或对目标用户群体的密码分布有任何先验知识。\n\n除了比现有的密码强度评估技术更具优势外，该模型还使得任何终端用户（如系统管理员）都能自主为其系统生成定制化的密码模型，而无需满足传统方法中那些往往难以实现的要求，例如收集合适的训练数据或对底层机器学习模型进行拟合。最终，我们的框架实现了精准校准密码模型的“民主化”，使其能够广泛服务于整个用户社区，从而解决了大规模部署密码安全解决方案时面临的一项关键挑战。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Pulling Off The Mask：Forensic Analysis of the Deceptive Creator Wallets Behind Smart Contract Fraud.pdf": {
        "title": "Pulling Off The Mask：Forensic Analysis of the Deceptive Creator Wallets Behind Smart Contract Fraud",
        "abstract": "——犯罪分子利用被称为“欺骗性创建者钱包”（Deceptive Creator Wallets, DCWs）的加密钱包，通过诱骗受害者将资金转入欺诈性智能合约，策划了一系列欺诈活动。由于此类交易几乎无法撤销，且难以追踪犯罪分子的真实身份，业界目前主要采取将这些合约标记为风险合约，向用户发出警告的方式进行应对。然而，现有的防范措施仅聚焦于单个欺诈合约，却忽视了幕后的“欺骗性创建者钱包”（DCWs）。我们的研究发现，正是这种盲区使得欺诈行为得以持续蔓延。\n\n为此，我们开发了名为 **CoCo** 的自动化取证分析系统。该系统可针对一个欺诈合约进行分析，并生成执法机构所需的证据，以有效打击和遏制欺诈行为。在对157个已确认的欺诈合约应用CoCo后，我们的研究揭示出与91个DCW相关联的1,283,198个合约，这些合约累计非法获利高达2,638,752 ETH（约合2,089,504,682美元）。更令人担忧的是，CoCo将此类欺诈活动追溯至2017年9月，表明此类犯罪已长期存在且持续演化。\n\n为应对这一严峻形势，我们正与区块链浏览器Etherscan以及美国联邦调查局（FBI）密切合作，共同打击本研究中识别出的欺诈网络。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Architectural Mimicry：Innovative Instructions to Efficiently Address Control-Flow Leakage in Data-Oblivious Programs.pdf": {
        "title": "Architectural Mimicry：Innovative Instructions to Efficiently Address Control-Flow Leakage in Data-Oblivious Programs",
        "abstract": "—程序的控制流通常可通过旁道攻击（side-channel attacks）被观察。因此，当控制流依赖于秘密信息时，攻击者便能从中推断出这些秘密的相关信息。目前广泛使用的基于软件的防御措施，旨在确保控制流中攻击者可观察的部分不依赖于秘密数据，其依赖于诸如“虚拟执行”（dummy execution，用于平衡代码）或“条件执行”（conditional execution，用于线性化代码）等技术。然而，在当前实践中，实现这些技术所需的原语（primitives）必须从现有的指令集架构（ISA）中寻找，而这些ISA在设计之初并未预先考虑提供此类功能，从而导致性能、安全性和可移植性方面的问题。\n\n为应对这些问题，本文提出了一种轻量级的硬件扩展方案，以系统化、结构化的方式支持上述防御技术。我们提出了：(1) 一种新颖的硬件机制——“模拟执行”（mimic execution），该机制仅执行指令流中能被攻击者观察到的部分（如时序、缓存访问等），同时抑制（大部分）对架构状态（architectural effects）的可见影响；(2) 配套的ISA支持（称为AMi，即Architectural Mimicry，架构级模拟）以及编程模型，以高效地利用模拟执行来实现代码的平衡或线性化。\n\n我们通过在一种32位、乱序执行的RISC-V核心上实现“模拟执行”和AMi机制，验证了该方案的可行性及其优势。该核心存在多种控制流泄漏途径（例如通过分支预测器、指令执行时间、数据缓存等）。实验评估表明，该方案的硬件开销极低（最重要的是，未对处理器的关键路径造成影响），并且AMi带来了显著的性能提升。具体而言，在我们的基准测试中，AMi将当前最先进的线性化代码的开销降低了60%。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/A Systematic Study of Physical Sensor Attack Hardness.pdf": {
        "title": "A Systematic Study of Physical Sensor Attack Hardness",
        "abstract": "——针对机器人载具（Robotic Vehicles, RV）的物理传感器攻击，因其普遍性以及对物理安全的潜在威胁，已成为一个严峻的担忧。然而，RV软件开发人员通常并未部署适当的防御措施。这种犹豫源于他们的一种普遍认知：攻击者在实施传感器攻击时面临巨大挑战，例如需要绕过硬件层面的传感器冗余机制，以及规避软件层面的传感器数据滤波处理。然而，我们发现，攻击者只要满足特定前提条件，并对攻击参数进行精细调整，便能够克服这些挑战。开发人员之所以存在此类误解，是因为他们缺乏对攻击者成功实现攻击目标所面临难度的系统研究——我们称之为“攻击难度”（attack hardness）。\n\n在本文中，我们评估了12种已知传感器攻击的攻击难度。首先，我们识别出成功实施每种攻击所需的前提条件；随后，我们通过量化这些前提条件在现实世界中的出现频率，来衡量每种攻击的难度。为自动化这一分析过程，我们提出了**RVP ROBER**——一个攻击前提分析框架。利用RVP ROBER，我们发现这12种传感器攻击平均需要4.4个前提条件，这表明以往的研究往往忽略了实施这些攻击所必需的关键细节。通过满足已识别的前提条件并精细调整攻击参数，我们将成功攻击的数量从6种提升至11种。此外，我们的分析表明，平均有57.08%的实际RV用户面临传感器攻击的脆弱性。最后，基于已识别的前提条件，我们进一步分析了每种攻击成功背后的原因，并发现了此前未被揭示的根本成因，例如RV软件中“故障安全”（fail-safe）逻辑的设计缺陷。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/OdScan：Backdoor Scanning for Object Detection Models.pdf": {
        "title": "OdScan：Backdoor Scanning for Object Detection Models",
        "abstract": "——基于深度学习的目标检测技术在许多现实生活场景中具有重要应用。然而，与其他的深度学习模型一样，目标检测模型也容易受到后门攻击（backdoor attacks）的威胁。目标检测任务具有其独特性，例如需要返回一组带有类别标签的物体边界框（bounding boxes），这给后门扫描（backdoor scanning）带来了新的挑战。针对旨在通过逆向工程还原触发器（trigger）以判断模型是否被植入后门的“触发器逆向技术”（trigger inversion），必须考虑多个复杂因素：哪些边界框可能被攻击？攻击是否会导致边界框位置发生偏移？攻击是否可能引入人类无法察觉的“幽灵物体”（ghost objects）？这些因素极大地扩展了攻击面，使得触发器逆向变得极为困难。\n\n为此，我们提出了一种新的触发器逆向技术，该技术基于若干关键观察，将庞大的搜索空间有效压缩至可处理的范围。我们在334个良性模型和360个被植入后门的模型上进行了实验，这些模型涵盖了4种网络结构和6种不同的攻击方式。实验结果表明，我们的方法能够稳定实现超过0.9的ROC-AUC值。在最新的TrojAI目标检测后门检测竞赛中，我们的解决方案取得了0.926的ROC-AUC，性能比第二名的方案（ROC-AUC为0.763）高出21.4%，显著领先。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Kairos：Practical Intrusion Detection and Investigation using Whole-system Provenance.pdf": {
        "title": "Kairos：Practical Intrusion Detection and Investigation using Whole-system Provenance",
        "abstract": "溯源图（Provenance graphs）是一种结构化的审计日志，用于描述系统执行的历史过程。近期研究探索了多种分析溯源图的技术，旨在实现主机的自动化入侵检测，尤其关注高级持续性威胁（APT）。通过梳理这些研究的设计文档，我们识别出推动基于溯源的入侵检测系统（PIDS）发展的四个关键维度：\n\n1. **检测范围**（Scope）：PIDS能否检测出跨越应用边界渗透的现代攻击？  \n2. **攻击无关性**（Attack Agnosticity）：PIDS能否在不预先掌握攻击特征的情况下检测出新型攻击？  \n3. **时效性**（Timeliness）：PIDS能否在主机系统运行过程中高效地进行实时监测？  \n4. **攻击重建能力**（Attack Reconstruction）：PIDS能否从庞大的溯源图中提炼出攻击活动，生成易于系统管理员理解、便于快速响应的入侵事件描述？\n\n我们提出了 **KAIROS**，这是首个在以上四个维度上同时满足理想要求的PIDS系统。而现有方法通常需要至少牺牲其中一个维度，难以达到可比的检测性能。\n\nKAIROS采用一种新颖的基于图神经网络（GNN）的编码器-解码器架构，通过学习溯源图结构随时间演变的模式，量化每个系统事件偏离正常行为的异常程度。基于这种细粒度的异常评分，KAIROS能够重建攻击轨迹，生成简洁的摘要图（summary graphs），准确刻画系统审计日志流中的恶意活动。\n\n在最新的基准数据集上的实验表明，KAIROS在检测性能上显著优于现有方法，展现了其在实际部署中的强大潜力。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/DNSBomb：A New Practical-and-Powerful Pulsing DoS Attack Exploiting DNS Queries-and-Responses.pdf": {
        "title": "DNSBomb：A New Practical-and-Powerful Pulsing DoS Attack Exploiting DNS Queries-and-Responses",
        "abstract": "——DNS 采用多种机制来保障可用性、保护安全性并提升可靠性。然而，在本文中，我们揭示出这些原本有益的固有机制，包括查询超时（timeout）、查询聚合（query aggregation）和响应快速返回（response fast-returning），可能被转化为恶意攻击的载体。我们提出了一种新颖、实用且极具破坏力的脉冲式拒绝服务（DoS）攻击，称之为 **DNSBOMB 攻击**。\n\nDNSBOMB 攻击利用多种广泛部署的 DNS 机制，将低速率发送的 DNS 查询进行累积，将这些查询放大为体积庞大的响应数据包，并将所有响应集中在一个短暂但高容量的周期性脉冲流量中，从而同时压垮目标系统。通过对 10 种主流 DNS 软件、46 个公共 DNS 服务以及约 180 万个开放 DNS 解析器的大规模评估，我们证明：**所有被测试的 DNS 解析器均可能被利用来发动比以往脉冲式 DoS 攻击更具实战性和破坏力的 DNSBOMB 攻击**。\n\n小规模实验表明，攻击产生的脉冲峰值流量可达 **8.7 Gb/s**，带宽放大倍数甚至超过 **20,000 倍**。我们的受控攻击可导致无状态连接（如 UDP）和有状态连接（如 TCP、QUIC）均出现完全丢包或服务降级。此外，我们提出了有效的缓解方案，并进行了详细评估。\n\n我们已负责任地向所有受影响的厂商披露了研究发现，其中 **24 家厂商已确认问题并采纳我们的解决方案进行软件修复**，包括 BIND、Unbound、PowerDNS 和 Knot 等知名 DNS 软件。目前，该漏洞已获得 **10 个 CVE 编号**。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/BUSted... Microarchitectural Side-Channel Attacks on the MCU Bus Interconnect.pdf": {
        "title": "BUSted... Microarchitectural Side-Channel Attacks on the MCU Bus Interconnect",
        "abstract": "——Spectre和Meltdown漏洞促使研究界深入了解了处理器微架构所蕴含的安全隐患，这种理解在以往是难以获得的。然而，现有研究主要集中在高端处理器上（例如Intel、AMD、Arm Cortex-A系列），而对驱动数十亿嵌入式和物联网（IoT）设备的微控制器（MCU）却鲜有关注。在本文中，我们提出了BUSted。BUSted是一种新型侧信道攻击方法，它通过利用MCU总线互连仲裁逻辑产生的副作用，绕过由内存保护机制所实施的安全保障。针对MCU的侧信道攻击带来了前所未有的新挑战，这些挑战与这类系统资源受限的特性密切相关（例如单核CPU、无状态总线）。我们提出了一种独特的方法，其核心是“硬件小工具”（hardware gadgets）的概念。我们在搭载TrustZone-M技术、运行可信固件TF-M（Trusted Firmware-M）的最先进Armv8-M架构MCU上，成功实施了实际攻击。与Nemesis攻击不同，我们的攻击在Arm Cortex-M系列MCU上具有实际可行性，且实验结果表明，该攻击可扩展到整个MCU产品线。\n\n关键词——侧信道攻击，微架构，总线，微控制器，可信执行环境（TEE），TrustZone-M。  \n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SyzTrust：State-aware Fuzzing on Trusted OS Designed for IoT Devices.pdf": {
        "title": "SyzTrust：State-aware Fuzzing on Trusted OS Designed for IoT Devices",
        "abstract": "——物联网（IoT）设备中嵌入的可信执行环境（Trusted Execution Environments, TEEs）为在硬件层面保护IoT应用提供了一种可部署的解决方案。在设计上，可信操作系统（Trusted OS）是TEE的核心组件，它使TEE能够采用基于安全的设计技术，例如数据加密和身份认证。一旦可信操作系统被攻破，TEE便无法再保障安全性。然而，针对IoT设备的可信操作系统却鲜有深入的安全分析，这主要面临以下几个方面的挑战：(1) 可信操作系统多为闭源系统，且缺乏便于发送测试用例并收集反馈的测试环境；(2) 可信操作系统具有复杂的数据结构，并依赖于有状态（stateful）的工作流程，这限制了现有漏洞检测工具的适用性。\n\n为应对上述挑战，我们提出了 **S YZTRUST**——首个面向资源受限可信操作系统的**状态感知模糊测试（state-aware fuzzing）框架**，用于系统性地评估其安全性。S YZTRUST 采用**硬件辅助的架构**，可直接在IoT设备上对可信操作系统进行模糊测试，同时以非侵入方式跟踪程序状态和代码覆盖率。S YZTRUST 利用**复合反馈机制**（composite feedback）引导模糊测试引擎，更高效地探索各种系统状态，并显著提升代码覆盖率。\n\n我们在来自三大主流厂商（三星、Tsinglink Cloud 和阿里云）的可信操作系统上对 S YZTRUST 进行了评估。这些系统均运行于基于 Cortex-M23/M33 的微控制器（MCU）上，该类芯片为嵌入式TEE提供了必要的硬件抽象支持。实验中，我们共发现了**70个此前未知的漏洞**，并已获得**10个新的CVE编号**。此外，与基线方法相比，S YZTRUST 展现出显著的性能提升：代码覆盖率提高**66%**，状态覆盖率提升**651%**，漏洞发现能力增强**31%**。我们已将所有新发现的漏洞报告给相关厂商，并开源了 S YZTRUST 框架。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Attacking and Improving the Tor Directory Protocol.pdf": {
        "title": "Attacking and Improving the Tor Directory Protocol",
        "abstract": "Tor网络通过将流量经由志愿者提供的中继节点构成的覆盖网络进行路由，从而增强用户的隐私保护。Tor使用一种分布式协议，由九个硬编码的目录权威服务器（Directory Authority, DA）协作运行，每小时间隔安全地分发关于这些中继节点的信息，并生成一份新的共识文档（consensus document）。该协议采用简单的投票机制来确保一致性，即使少数目录权威服务器被攻破，系统理论上仍应保持安全。然而，当前的共识协议存在缺陷：它允许一种“模棱两可攻击”（equivocation attack），即仅需一个被攻破的目录权威服务器，就能构造出一个包含恶意中继节点的、形式上有效的共识文档。\n\n更重要的是，这一漏洞并非无害。我们证明，被攻破的权威服务器可以以无法被察觉的方式，诱骗特定客户端使用这个伪造的、模棱两可的共识文档。此外，尽管我们自Tor网络诞生起就已存档所有共识文档，但我们仍无法确定是否曾有客户端被成功欺骗。\n\n为此，我们提出了一个两阶段解决方案。在短期内，我们开发并已部署了一个名为**TorEq**的监控工具，用于被动检测此类攻击：Tor客户端在更新共识文档前，可查询该监控工具，以确保不存在模棱两可的情况。从长远来看，为从根本上解决问题，我们首先将Tor目录权威的共识问题，重新形式化为分布式计算领域中的**交互式一致性**（Interactive Consistency, IC）问题。随后，我们设计了**DirCast**——一种全新的安全拜占庭广播（Byzantine Broadcast）协议。该协议仅需对当前Tor目录权威的代码库进行最小程度的修改。我们的协议效率接近最优：在当前九个权威节点的系统中，理想情况下仅需五轮通信，最多不超过九轮，即可达成共识。\n\n我们的方案具有实际可行性：性能分析表明，在不修改权威服务器代码的前提下，我们的监控工具可在五分钟内检测出模棱两可行为；而安全的交互式一致性协议在真实场景中每小时可生成多达500个共识文档。目前，我们正与Tor安全团队积极沟通，推动将这些解决方案集成到Tor项目中。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SHERPA：Explainable Robust Algorithms for Privacy-Preserved Federated Learning in Future Networks to Defend Against Data Poisoning Attacks.pdf": {
        "title": "SHERPA：Explainable Robust Algorithms for Privacy-Preserved Federated Learning in Future Networks to Defend Against Data Poisoning Attacks",
        "abstract": "——随着通信技术的飞速发展和大数据在数十亿设备上的本地化部署，分布式机器学习（ML）技术正应运而生，以支持人工智能（AI）服务在分布式环境下的发展。联邦学习（Federated Learning, FL）正是这样一种创新方法，它能够在保护隐私的前提下实现AI模型的构建，使各参与方在无需共享原始数据的情况下，实现机器学习模型的协同训练与聚合。然而，近期研究发现，联邦学习面临来自**数据投毒攻击**（poisoning attacks）的严重威胁。已有研究提出了一些基于相似性度量或异常检测过滤等技术的鲁棒算法作为应对方案。但这些方法大多未深入探究攻击者的意图，也未能为识别可疑客户端（即潜在的投毒者）提供充分的解释依据和证据支持。\n\n为此，我们提出了 **SHERPA**——一种基于**Shapley可加性解释**（SHAP）的鲁棒算法，用于在联邦学习系统中识别潜在的投毒者。在此基础上，我们进一步开发了一种新颖的算法，通过**特征归因聚类**（feature attribution clustering）来区分真正的投毒者与正常客户端。我们在多个数据集上针对多种攻击场景实施了数据投毒攻击，并展示了SHERPA在缓解此类攻击方面的有效性。更进一步，我们证明，即使是**以隐私破坏为目标的投毒攻击**，也能通过我们的方法得到有效抑制。\n\n结合可解释人工智能（Explainable AI, XAI）的防御机制，本研究揭示了**事后特征归因**（post-hoc feature attributions）在对抗数据投毒攻击中的巨大潜力：不仅提升了防御过程的**可解释性**，还为在模型聚合阶段排除潜在恶意客户端提供了更充分的**理由与证据支持**。\n\n**关键词**：联邦学习，可解释人工智能（XAI），SHAP，数据投毒，5G/6G之后通信，隐私保护，防御机制，鲁棒算法"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Sophon：Non-Fine-Tunable Learning to Restrain Task Transferability For Pre-trained Models.pdf": {
        "title": "Sophon：Non-Fine-Tunable Learning to Restrain Task Transferability For Pre-trained Models",
        "abstract": "——如今，开发者不再从零开始构建深度学习模型，而是越来越多地依赖对预训练模型进行调整，以适应其特定任务。然而，功能强大的预训练模型也可能被滥用，用于不道德或非法的任务，例如隐私推断和生成不安全内容。在本文中，我们提出了一种开创性的学习范式——**不可微调学习**（non-fine-tunable learning），其目标是在保持预训练模型原始任务性能的同时，阻止其被微调用于不恰当的任务。\n\n为实现这一目标，我们提出了 **SOPHON**，一种保护性框架，用于增强给定的预训练模型，使其对预定义的限制领域（如涉及隐私或有害内容的任务）具备抗微调能力。然而，这一目标极具挑战性，因为攻击者可能采用多种多样且复杂的微调策略。受模型无关元学习（model-agnostic meta-learning）的启发，我们通过设计精细的**微调模拟算法**和**微调评估算法**，克服了这一难题。\n\n此外，我们精心设计了优化过程，使预训练模型在针对受限领域时陷入一个难以逃离的局部最优状态，从而有效阻止其被成功微调。我们针对两种深度学习模型（分类与生成）、七个受限领域以及六种模型架构，开展了广泛的实验，以验证 SOPHON 的有效性。实验结果表明，对受 SOPHON 保护的模型进行微调，其计算开销与从零训练相当，甚至更高。\n\n进一步地，我们验证了 SOPHON 对三种微调方法、五种优化器、多种学习率及批量大小的鲁棒性。SOPHON 的提出，有望推动关于**安全、负责任的人工智能**的进一步研究，为模型的可控使用和伦理部署提供关键技术支撑。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/From Individual Computation to Allied Optimization：Remodeling Privacy-Preserving Neural Inference with Function Input Tuning.pdf": {
        "title": "From Individual Computation to Allied Optimization：Remodeling Privacy-Preserving Neural Inference with Function Input Tuning",
        "abstract": "——隐私保护的机器学习即服务（Privacy-preserving Machine Learning as a Service, MLaaS）使得资源受限的客户端能够以较低的成本，获取由云服务器所持有的、经过良好训练的神经网络模型的推理结果，同时确保客户端的输入数据和服务器端的模型参数均得到隐私保护。尽管效率在实际部署隐私保护MLaaS系统中起着核心作用，且近年来在提升效率方面已取得令人鼓舞的进展，但现有方法在性能上仍与真实世界应用需求存在显著差距。\n\n当前最先进的主流框架基本逻辑是：针对神经网络模型中的每一个函数，独立地基于特定密码学原语执行计算。这种“按函数逐项处理”的方法固然合理，但我们重新审视了其必要性，并首次发起对隐私保护MLaaS进行**协同优化**（allied optimization）的全面探索。基于这一新视角，我们将主流研究中常见的“从某一函数的输入到其输出的串行计算流程”，重新建模为一种“协同式”计算流程——即从一个函数的输入（伴随昂贵计算开销的起点）出发，跨越至下一个函数的输出，从而在流程中有效规避不必要的计算成本。\n\n基于此，我们提出了**FIT（Function Input Tuning，函数输入调优）** 框架，其核心特征在于引入了一个用于复合函数的计算模块，并配套一系列联合优化策略。从理论上讲，FIT在不引入额外加密机制的前提下，成功消除了最昂贵的密码学操作，同时使得运行时密码学计算复杂度与卷积核（filter）大小无关，实现了本质性突破。\n\n实验结果表明，FIT在现代模型的各种函数维度上均实现了数十倍的加速；当将其嵌入从小型数据集（如MNIST）到大型数据集（如ImageNet）的神经网络中时，整体计算时间获得了**4.5倍至35.5倍**的性能提升。这充分验证了FIT在推动隐私保护MLaaS走向实际部署方面的巨大潜力。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/CORELOCKER：Neuron-level Usage Control.pdf": {
        "title": "CORELOCKER：Neuron-level Usage Control",
        "abstract": "——现代应用领域中深度神经网络模型的日益复杂化，要求训练过程涉及海量数据、精密的设计和庞大的计算资源。训练完成的模型天然凝聚了模型开发者（或称模型所有者）的知识产权。因此，如何防止那些能够访问该模型的主体（即模型控制者）未经授权地使用模型，从而保护模型所有者的基本权利和专有利益，已成为一项关键而迫切的需求。\n\n在本研究中，我们提出了一种名为 **CORE LOCKER** 的模型保护方法，其核心思想是：从神经网络中策略性地提取一小部分关键权重，作为解锁模型完整功能的“访问密钥”。该密钥的提取可根据模型所有者希望释放的模型效用程度进行灵活定制。持有该密钥的授权用户可完全访问模型的全部能力，而未授权用户仅能访问模型的部分功能。\n\n我们为 CORE LOCKER 建立了严格的理论基础，明确了受保护前与受保护后网络之间效用差异的上下界，从而为模型保护效果提供了理论保障。我们在 Fashion-MNIST、CIFAR-10 和 CIFAR-100 等代表性数据集，以及 VGGNet、ResNet 和 DenseNet 等真实世界模型上对 CORE LOCKER 进行了评估。实验结果充分验证了其有效性。此外，我们还证明了 CORE LOCKER 在面对基于微调（fine-tuning）和剪枝（pruning）等先进模型恢复攻击时，具有强大的抗攻击能力，展现出良好的鲁棒性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Communication-efficient, Fault Tolerant PIR over Erasure Coded Storage.pdf": {
        "title": "Communication-efficient, Fault Tolerant PIR over Erasure Coded Storage",
        "abstract": "——私有信息检索（PIR）是一种技术，允许客户端从公共数据库中检索某项数据，同时不向具有敌意的服务器泄露所查询的具体项目。尽管多服务器PIR已被广泛研究，以在通信和计算方面优于单服务器方案，但目前能够抵御恶意敌手、在故障情况下仍能正常工作的容错PIR方案却非常稀少。在本文中，我们提出了一种结合密码学和信息论领域技术的新方法，设计出更为鲁棒的PIR协议，在计算开销、通信成本和存储效率方面均优于现有最先进的方案。实验结果表明，对于大小为4GB的数据库，我们的PIR协议相比现有最先进鲁棒PIR协议，延迟降低高达9.1倍，总通信量减少至少39.2倍，计算量降低达7.3倍，且能够抵御两个恶意服务器的攻击。此外，在各种参数配置和不同故障场景下，我们的方案均持续优于现有的鲁棒PIR基准方案。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Enforcing End-to-end Security for Remote Conference Applications.pdf": {
        "title": "Enforcing End-to-end Security for Remote Conference Applications",
        "abstract": "远程会议应用程序的使用正日益广泛，但目前其不恰当的数据加密方式、专有的实现机制以及拨号接入功能引发了人们对隐私泄露的担忧。因此，亟需为这些生产级工具提供可信且安全的解决方案。\n\n在本文中，我们提出了 mTunnel——一种部署在主机系统中的透明软件层，旨在保障会议应用的安全性，同时不牺牲其核心功能和使用的便捷性。mTunnel 的基本思想是：在敏感数据（如音频、视频、文本等）被不可信的应用程序客户端获取之前，就对其进行加密。mTunnel 利用会议应用自身的音视频流传输能力，将加密后的内容通过“隧道”方式传输到远端。\n\nmTunnel 构建了一个软件框架，通过基于虚拟驱动器的 I/O 虚拟化技术，实现对媒体数据的拦截与重构。此外，mTunnel 还支持在混合网络环境（包括 IP 网络和公共交换电话网络 PSTN）中实现完整的端到端加密（E2EE）群组通信。我们对 mTunnel 进行了原型实现，并在多个商用会议产品上进行了测试评估。实验结果表明，mTunnel 在具备良好可行性的同时，仅引入可接受的性能开销。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Secure Messaging with Strong Compromise Resilience, Temporal Privacy, and Immediate Decryption.pdf": {
        "title": "Secure Messaging with Strong Compromise Resilience, Temporal Privacy, and Immediate Decryption",
        "abstract": "近年来，安全通信协议的设计取得了诸多进展，其目标要么是在理论上实现可证明的强安全性，要么是追求在实际部署中的高效率。然而，在这些设计目标之间的关键权衡领域，至今仍未被充分探索。\n\n在本工作中，我们设计了首个在理论上可证明安全、同时满足以下三个特性的协议：(i) 对细粒度泄露具有强鲁棒性；(ii) 实现时间维度上的隐私保护（时态隐私）；(iii) 在解密延迟方面实现即时解密，且仅引入恒定大小的开销——尤其值得注意的是，这些特性均在后量子（Post-Quantum, PQ）安全设置下达成。除了上述核心设计目标，我们还提出了一种适用于本场景的新型“离线可否认性”（offline deniability）定义，并证明我们的协议满足该性质，尤其当结合一种后量子安全的离线可否认初始密钥交换方案时，这一特性尤为成立。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Who Left the Door Open. Investigating the Causes of Exposed IoT Devices in an Academic Network.pdf": {
        "title": "Who Left the Door Open. Investigating the Causes of Exposed IoT Devices in an Academic Network",
        "abstract": "—许多研究发现，面向互联网的系统存在暴露易受攻击的服务的情况。这些通常被认为是配置错误的系统，本不该将这些服务暴露于网络中，尤其是在企业网络中。在本研究中，我们明确了一所大学企业网络中暴露Telnet和FTP服务的物联网（IoT）设备的成因，这也有助于厘清责任归属。我们对网络进行了扫描，发现共有185台IoT设备暴露了Telnet或FTP服务，涉及30种暴露Telnet的设备型号和49种暴露FTP的设备型号。我们向设备所有者发送了安全通知并附上一份调查问卷。调查结果显示，在21位Telnet设备所有者中，有2人故意在其所有设备上启用了Telnet；在41位FTP设备所有者中，有8人故意启用了FTP。在收到安全通知后，47位所有者中有38人表示愿意对其至少一台IoT设备采取整改措施。这些愿意整改的所有者中，除一台设备外，其余设备均成功完成修复。\n\n我们还查阅了相关设备的用户手册，发现对于暴露Telnet的30种设备型号，有15种型号的手册中完全未提及暴露服务的信息；对于暴露FTP的49种设备型号，有10种型号的手册中同样未作任何披露。此外，通过结合对设备制造商的调查与设备手册内容，我们进一步确认：在30种Telnet设备中，有22种出厂时默认启用了Telnet；在49种FTP设备中，有29种默认启用了FTP。\n\n基于以上结果，我们得出结论：这些“配置错误”设备的存在，其主要原因并非设备所有者的人为失误，而更多源于制造商的设计选择。一旦设备所有者意识到安全风险，大多数都表现出积极的整改意愿。\n\n**关键词**：物联网（IoT）、安全、设备所有者与制造商调查、设备手册分析、安全通知"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/WeSee：Using Malicious #VC Interrupts to Break AMD SEV-SNP.pdf": {
        "title": "WeSee：Using Malicious #VC Interrupts to Break AMD SEV-SNP",
        "abstract": "— AMD SEV-SNP 提供了虚拟机级别的可信执行环境（TEE），用于保护敏感云工作负载的**机密性**和**完整性**，使其免受云服务商所控制的不可信虚拟机监控器（hypervisor）的影响。为实现虚拟机与不可信 hypervisor 之间的通信，AMD 引入了一种新的异常类型：**#VC 异常**。我们提出了 **WESEE攻击**，该攻击中，hypervisor 向受害虚拟机的 CPU 注入恶意的 #VC 异常，从而破坏 AMD SEV-SNP 的安全保障机制。\n\n具体来说，WESEE 攻击通过注入中断号 29，向虚拟机传递一个 #VC 异常，虚拟机随后会执行相应的异常处理程序，该程序负责在虚拟机与 hypervisor 之间进行数据和寄存器内容的复制操作。WESEE 攻击表明，通过精心构造的 #VC 异常注入，攻击者可以诱使虚拟机执行任意行为。\n\n我们的案例研究证实，WESEE 攻击能够实现以下危害：  \n- 泄露虚拟机中的敏感信息（如 NGINX 的 kTLS 密钥）；  \n- 篡改内核数据（如防火墙规则）；  \n- 注入任意代码（例如从内核空间启动一个 root shell）。\n\n该攻击揭示了即使在使用 AMD SEV-SNP 这类硬件级可信执行保护机制的情况下，若未对异常处理机制进行充分安全验证，仍可能通过 hypervisor 的恶意干预造成严重安全漏洞。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Nyx：Detecting Exploitable Front-Running Vulnerabilities in Smart Contracts.pdf": {
        "title": "Nyx：Detecting Exploitable Front-Running Vulnerabilities in Smart Contracts",
        "abstract": "——智能合约容易受到抢先交易（front-running）攻击，即恶意用户利用对即将发生交易的提前了解，抢先执行攻击性交易，从而谋取自身利益。现有的合约分析技术在检测此类漏洞时存在大量误报（false positives）和漏报（false negatives），其原因在于：这些技术过于简单地将合约中的数据竞争（data race）直接等同于抢先交易漏洞，并且仅能对合约进行孤立分析，缺乏上下文关联。\n\n在本研究中，我们基于对历史攻击案例的实证分析，对“可利用的抢先交易漏洞”进行了形式化定义，并提出了一种新型静态分析工具 Nyx，用于精准检测此类漏洞。Nyx 的核心设计包含两个阶段：首先，采用基于 Datalog 的预处理流程，高效且可靠地剪枝搜索空间，大幅减少后续分析的计算负担；其次，通过一个符号化验证引擎，结合 SMT 求解器，精确定位合约中存在的漏洞。\n\n我们使用一个包含 513 个真实世界中智能合约抢先交易攻击案例的大型数据集对 Nyx 进行了评估。与六种现有最先进的分析技术相比，Nyx 在召回率（recall）上提升了 32.64% 至 90.19%，在精确率（precision）上提升了 2.89% 至 70.89%。此外，Nyx 还在实际部署的智能合约中发现了四个此前未知的零日漏洞（zero-days）。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Security, Privacy, and Data-sharing Trade-offs When Moving to the United States：Insights from a Qualitative Study.pdf": {
        "title": "Security, Privacy, and Data-sharing Trade-offs When Moving to the United States：Insights from a Qualitative Study",
        "abstract": "移居到一个新的国家，往往意味着人们要离开自己“熟悉的环境”，与全新的机构和社会体系打交道，常常需要分享敏感且私密的信息。这使他们面临多种风险。在本研究中，我们探讨了最近移居美国的人群在安全、隐私和数据共享方面所面临的挑战与担忧。\n\n通过半结构化访谈（n = 25），我们发现，大多数受访者在签证申请过程中对提供包含个人及敏感信息的文件（如财务资料和亲属关系证明）感到不安。分享这些信息让他们担心自身的安全与隐私，有时还违背了他们文化中的信息共享规范。移居到一个新的环境，尤其是美国，也使人们更容易遭遇诈骗，特别是虚假的租房广告和诈骗电话。此外，移民者还需应对官僚、行政和技术层面的重重挑战，这些因素进一步加剧了他们对安全和隐私的担忧。\n\n我们还发现，签证申请人面临一种权力不对等的关系：为了避免签证被拒，他们不得不按要求提交所有信息，但往往对相关申请要求以及现有的保护措施并不充分知情。这种信息不对称使他们处于被动和焦虑之中。\n\n本研究强调，使领馆需要提供更多的指导、提高透明度，并更加尊重个人的隐私权；同时，技术设计者也应设计出更完善的工具，以更好地支持和保护跨国迁移的人群。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：Prudent Evaluation Practices for Fuzzing.pdf": {
        "title": "SoK：Prudent Evaluation Practices for Fuzzing",
        "abstract": "——在过去的十年中，模糊测试（fuzzing）已被证明是一种极为有效的发现软件漏洞的方法。自从AFL（American Fuzzy Lop）提出了开创性的轻量级覆盖反馈机制以来，模糊测试领域涌现了大量科学研究，不断提出新技术、改进现有方法的方法论层面，或将已有方法移植到新的应用场景。所有这些研究工作都必须通过实证评估来证明其价值：即展示其在实际问题中的适用性、衡量其性能表现，并通常在全面、系统的实验中证明其优于已有方法。\n\n然而，模糊测试对测试目标、运行环境以及具体条件极为敏感，例如测试过程中的随机性。毕竟，依赖随机性正是模糊测试的核心原则之一，它深刻影响着模糊器的诸多行为。再加上测试环境往往难以精确控制，实验的可重复性成为一个关键问题，因此需要精心设计评估方案。为应对这些有效性威胁，已有若干研究（尤其是Klees等人发表的《Evaluating Fuzz Testing》）提出了如何构建严谨评估框架的指导建议。但截至目前，尚不清楚这些建议在实践中究竟被采纳了多少。\n\n在本研究中，我们系统地分析了2018至2023年间发表于顶级安全会议上的150篇模糊测试相关论文的评估方法。我们考察了现有指南在这些论文中的实施情况，并识别出潜在的问题与常见陷阱。我们发现，许多研究在统计检验和系统性误差处理方面明显忽视甚至违背了已有指南。例如，在调查论文中报告的漏洞时，我们发现，由于对现实世界软件进行漏洞挖掘，部分作者申请并获得了质量存疑的CVE（通用漏洞披露编号）——这些CVE可能缺乏足够的复现证据或技术细节。\n\n为进一步将文献分析延伸到实践层面，我们尝试复现了八篇模糊测试论文中的核心主张。这些案例研究使我们能够评估模糊测试研究的实际可重复性，并识别出评估设计中典型的错误模式。不幸的是，我们的复现结果表明，所研究的多篇论文存在若干缺陷，我们无法完全支持或复现其原始结论。\n\n为推动模糊测试领域向科学、可重复的评估标准迈进，我们提出了更新版的模糊测试评估指南，建议未来研究工作遵循。这些指南旨在提升实验设计的严谨性、增强结果的可信度与可比性，最终促进整个领域的健康发展。1"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/You Only Prompt Once：On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content.pdf": {
        "title": "You Only Prompt Once：On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content",
        "abstract": "——网络上有害内容的传播是一个重要问题，它不仅损害了用户的在线体验，也对整个社会产生了负面影响。鉴于该问题的重要性和广泛影响，当前的研究主要集中在开发检测有害内容的解决方案，通常依赖于基于人工标注数据集训练而成的机器学习（ML）模型。尽管这些努力具有重要意义，但此类模型往往泛化能力较差，难以应对新兴趋势（例如新出现的有害词汇）。目前，我们正目睹应对网络社会问题的策略发生转变，特别是利用像GPT-3或T5这样的大规模语言模型（LLMs）——这些模型在海量文本语料上训练而成，具备强大的泛化能力。\n\n在本研究中，我们探讨如何利用大规模语言模型（LLMs）和提示学习（prompt learning）来解决有害内容的问题，重点聚焦于以下三项任务：1）有害性分类（Toxicity Classification），2）有害片段检测（Toxic Span Detection），以及3）去毒化（Detoxification）。我们在五种模型架构和八个数据集上进行了广泛的实验评估，结果表明，采用提示学习的LLMs能够达到与专门针对这些任务训练的模型相当、甚至更优的性能。我们发现，在有害性分类任务中，提示学习相比基线模型实现了约10%的性能提升；在有害片段检测任务中，其表现也优于最佳基线模型（F1分数为0.643 vs. 0.640）。最后，在去毒化任务中，我们发现提示学习能够成功将平均有害性得分从0.775降至0.213，同时较好地保留了原文的语义含义。\n\n**免责声明**：本文包含未经审查的有害内容，可能会引起读者不适或冒犯，请谨慎阅读。\n\n¹ 注：文中所涉数据基于实验设定与评估标准得出。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Don't Shoot the Messenger：Localization Prevention of Satellite Internet Users.pdf": {
        "title": "Don't Shoot the Messenger：Localization Prevention of Satellite Internet Users",
        "abstract": "——卫星互联网在地理政治冲突中正扮演着日益重要的角色。这一观点在2022年初爆发的乌克兰冲突中得到了印证：当时，Starlink卫星互联网服务被大规模部署，充分展现了信息自由流动所具有的战略意义。除了军事用途外，许多平民也通过社交媒体平台发布敏感信息，以影响公众舆论的走向。然而，卫星通信的使用已被证明具有危险性——因为通信信号可能被其他卫星监测，并被用于对地面信号源进行三角定位。不幸的是，针对记者的定点清除事件已表明，这种威胁真实且有效。尽管卫星互联网的广泛部署为冲突中的平民提供了前所未有的发声渠道，但如何保护他们免受定位威胁，仍是一个尚未解决的关键问题。\n\n为应对这一威胁，我们提出了AnonSat，一种保护卫星互联网用户免受三角定位攻击的新型方案。AnonSat可与廉价、现成的商用设备配合使用，利用远距离无线通信技术，在多个卫星基站之间构建一个本地通信网络。该网络能够将用户的通信数据重路由至距离其较远的另一个卫星基站，从而有效防止其真实位置被精确定位。AnonSat的设计注重易于部署和用户友好性，我们通过原型实现验证了这些特性。基于真实世界数据集的大规模网络仿真表明，AnonSat在多种实际应用场景中均表现出显著的有效性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Asterisk：Super-fast MPC with a Friend.pdf": {
        "title": "Asterisk：Super-fast MPC with a Friend",
        "abstract": "——安全多方计算（MPC）使多个互不信任的参与方能够在各自持有的敏感数据上实现隐私保护的协同计算。然而，在最常见的情形下，即大多数参与方可能是恶意腐化（也称为“恶意多数”场景），传统的MPC协议会引入高昂的计算和通信开销，且所提供的安全保证弱于实际应用所需的理想水平。在本文中，我们通过引入一个额外的、半诚实且非共谋的辅助方（helper party，简称HP），探索克服这些缺陷的可能性，旨在构建兼具实际高效性和强安全保证的恶意多数MPC协议。我们认为，这种假设比“诚实多数”假设更具现实意义，因为在许多涉及大量参与方的现实MPC应用中（例如暗池交易），通常存在一个中央管理机构，可自然地建模为该辅助方HP。\n\n在上述模型下，我们首次设计、实现并评估了一个实用高效、通用的多方计算框架——Asterisk。该框架仅需调用辅助方HP常数次，即可实现强安全保证中的“公平性”（即要么所有参与方都获得输出结果，要么都没有）；该框架可扩展至数百个参与方，性能全面优于现有的所有恶意多数MPC协议，甚至在性能上可与最先进的诚实多数MPC协议相媲美。实验表明，与当前最优的恶意多数MPC协议相比，Asterisk在预处理阶段实现了228至288倍的加速。在在线计算阶段，Asterisk可在约20秒内完成由100个参与方对一个包含10⁶个乘法门的电路进行求值。此外，我们还基于Asterisk实现了高效且高度可扩展的暗池应用实例，并进行了性能评估。相应的运行时间充分展示了Asterisk在实现具有强安全保证的现实隐私保护应用中的有效性。\n\n¹ 辅助方HP（helper party）被假设为半诚实（即遵循协议但可能试图从数据中推断信息），且不会与其他参与方串谋。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：Security and Privacy of Blockchain Interoperability.pdf": {
        "title": "SoK：Security and Privacy of Blockchain Interoperability",
        "abstract": "近年来，跨链技术取得了显著进展。然而，该领域仍面临两大紧迫挑战。一方面，跨链桥接连遭受黑客攻击，已造成约31亿美元的经济损失，暴露出当前互操作性机制在安全模型设计上的缺陷，以及事件响应框架的失效。另一方面，用户和桥接运营方的隐私受到严重限制，进一步扩大了潜在的攻击面。\n\n本文首次对区块链互操作性的安全性与隐私性展开了迄今为止最为全面的研究。我们采用系统性文献综述方法，从531项检索结果中筛选出212份相关文献，包括58篇学术论文和154份灰色文献（如技术报告、白皮书等）。基于我们提出的新型安全与隐私分类体系，我们系统地对57种互操作性解决方案进行了分类。本研究的数据集涵盖了学术研究、漏洞赏金计划披露的信息以及审计报告，共识别出45种跨链漏洞、4类隐私泄露问题，以及92项缓解策略。\n\n基于上述数据，我们对18起重大跨链桥攻击事件进行了分析，这些事件累计造成超过29亿美元的损失，并将每起攻击映射至已识别的漏洞类型。研究发现，被盗资金中有高达65.8%来自那些依赖“中间权限网络”（intermediary permissioned networks）进行安全保护的项目，但这些项目在加密密钥操作方面却缺乏安全保障。在隐私方面，我们发现：跨链交易能否实现“不可关联性”（unlinkability），取决于底层账本是否提供某种形式的保密性（confidentiality）支持。\n\n本研究为跨链系统的安全与隐私问题提供了17项关键洞见，并指出了未来极具前景的研究方向，强调亟需加强跨链技术在安全与隐私方面的投入。所提出的改进措施有望显著降低因桥接攻击导致的金融风险，增强用户对区块链生态系统的信任，从而推动更广泛的采用。\n\n**关键词**：跨链、安全、隐私、漏洞、区块链技术、加密货币、经济损失、系统性文献综述、分类体系、缓解策略。\n\n∗. 前两位作者对本研究贡献均等。Rafael在MIT连接科学研究所（MIT Connection Science）期间完成本研究，其研究由富布赖特奖学金（Fulbright Scholarship）资助。  \n†. 联系方式：  \n- André Augusto（andre.augusto@tecnico.ulisboa.pt）、Rafael Belchior（rafael.belchior@tecnico.ulisboa.pt）、Miguel Correia（miguel.p.correia@tecnico.ulisboa.pt）和 André Vasconcelos（andre.vasconcelos@tecnico.ulisboa.pt），隶属于INESC-ID与里斯本理工大学（Técnico Lisboa）；  \n- Luyao Zhang（lz183@duke.edu），昆山杜克大学（Duke Kunshan University）；  \n- Thomas Hardjono（hardjono@mit.edu），MIT连接科学研究所。\n\n时间线：2021年6月 – 2024年3月  \n（图表说明）  \n**图1：2021年5月至2024年2月跨链桥攻击事件时间线**  \n该数据集包含33起跨链桥攻击事件，累计损失超过32亿美元。  \n- X轴：时间（年-月）  \n- Y轴：被盗金额（百万美元），刻度为5、100、400、600  \n- 图表标题：跨链桥攻击时间线（Timeline of Cross-Chain Bridge Hacks）\n\n---\n\n**补充说明（基于图表内容）**：  \n自2021年中以来，跨链桥攻击事件频发，且单次攻击规模屡创新高。例如，2022年2月发生的**Ronin Network攻击**（损失约6.25亿美元）和2023年3月的**Euler Finance攻击**（部分通过跨链桥实现资产转移）等重大事件，凸显了跨链基础设施在安全设计上的系统性薄弱环节。随着跨链生态的快速发展，安全与隐私问题已成为制约行业健康发展的核心瓶颈。本研究通过系统性分析，为构建更安全、更私密的跨链系统提供了理论依据与实践指导。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/DeepVenom：Persistent DNN Backdoors Exploiting Transient Weight Perturbations in Memories.pdf": {
        "title": "DeepVenom：Persistent DNN Backdoors Exploiting Transient Weight Perturbations in Memories",
        "abstract": "——后门攻击在机器学习（ML）系统中引发了广泛关注。主流的ML后门攻击通常通过污染受害者的训练样本，或提供预训练好的带毒模型供受害者使用来实现。与此同时，近年来基于硬件的攻击技术进展表明，在模型推理阶段，通过诱导模型权重中的瞬态故障（transient faults），可以严重破坏ML模型的完整性。然而，这类硬件故障攻击在模型训练阶段可能造成的对抗性影响，此前尚未得到充分研究。\n\n在本文中，我们提出了**DeepVenom**，这是首个在受害者模型训练过程中实施的、端到端的基于硬件的深度神经网络（DNN）后门攻击方法。具体而言，DeepVenom能够在受害者模型进行微调（fine-tuning）运行时，通过在模型权重内存中引入瞬态故障（利用“行锤”Rowhammer技术），持久地植入一个目标后门。DeepVenom的攻击过程分为两个主要阶段：  \ni）**离线阶段**：利用一种基于集成的本地模型比特搜索算法，识别出可迁移至受害者模型的关键权重扰动模式；  \nii）**在线阶段**：结合先进的系统级技术，高效地对权重张量进行“调优”（massage），以实现精准的基于Rowhammer的比特翻转。\n\n此外，DeepVenom引入了一种新颖的**迭代后门增强机制**，通过多轮权重扰动来稳定后门效果，确保其鲁棒性。我们在配备DDR3/DDR4内存的真实系统上实现了端到端的DeepVenom攻击，并基于当前最先进的卷积神经网络（CNN）和视觉Transformer（Vision Transformer）模型进行了评估。\n\n实验结果表明，DeepVenom仅需**总共11次权重比特翻转**（最多49次），即可在受害者微调后的模型中成功植入后门，攻击成功率最高达**99.8%**（平均为97.8%）。进一步评估显示，该攻击在不同受害者微调的超参数设置下依然有效，且对**灾难性遗忘**（catastrophic forgetting）具有高度鲁棒性。\n\n本研究揭示了通过硬件层面的权重扰动在训练阶段实施后门攻击的现实可行性，为对抗性机器学习开辟了一个全新的攻击维度，凸显了此类攻击的实际威胁。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities (Yet.)：A Comprehensive Evaluation, Framework, and Benchmarks.pdf": {
        "title": "LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities (Yet.)：A Comprehensive Evaluation, Framework, and Benchmarks",
        "abstract": "——尽管大型语言模型（LLMs）已被提议用于自动化漏洞修复，但目前仍缺乏能够证明其可稳定识别安全相关缺陷的基准测试。为此，我们开发了SecLLMHolmes，这是一个完全自动化的评估框架，旨在对LLMs能否可靠识别并推理安全相关漏洞这一问题，开展迄今为止最详尽的考察。我们构建了228个代码场景，并利用该框架，从八个不同的分析维度对目前最具能力的八种LLMs进行了评估。\n\n评估结果表明，LLMs的响应具有非确定性，其推理过程常出现错误且不可靠，在实际场景中表现欠佳。尤为重要的是，我们的研究发现，即使是像“PaLM2”和“GPT-4”这样最先进的模型，其鲁棒性也显著不足：仅通过修改函数名或变量名，或在源代码中添加库函数，这些模型分别有26%和17%的概率会给出错误答案。这些发现表明，在LLMs能够作为通用的安全辅助工具投入使用之前，仍需要进一步的技术突破与性能提升。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/\"Len or index or count, anything but v1\"：Predicting Variable Names in Decompilation Output with Transfer Learning.pdf": {
        "title": "\"Len or index or count, anything but v1\"：Predicting Variable Names in Decompilation Output with Transfer Learning",
        "abstract": "——二进制逆向工程是一项由技术娴熟且成本高昂的人工分析人员执行的艰巨而繁琐的任务。在编译过程中，源代码的相关信息被不可逆转地丢失。尽管现代反编译器试图从二进制文件中生成类C语言的源代码，但它们无法恢复丢失的变量名。此前已有研究探索利用机器学习技术来预测反编译代码中的变量名。然而，目前最先进的系统DIRE和DIRTY在泛化能力上表现较差，对于测试集中未出现在训练集中的函数，其准确率明显下降——在DIRTY数据集上，DIRE的准确率仅为31.8%，而DIRTY自身的准确率为36.9%。\n\n在本文中，我们提出了VARBERT，一种基于Transformer的双向编码器表示（BERT）模型，用于预测反编译输出中有意义的变量名。VARBERT的一个优势在于：我们可以先在人类编写的源代码上进行预训练，然后再针对变量名预测任务对模型进行微调。此外，我们还构建了一个新的数据集VarCorpus，显著提升了数据集的规模和多样性。\n\n我们在VarCorpus上对VARBERT进行了评估，结果表明，对于经过O2优化的二进制文件，VARBERT在还原开发者原始变量名方面取得了显著提升，在IDA和Ghidra反编译结果上的准确率分别达到54.43%和54.49%。VARBERT严格优于现有最先进技术：在VarCorpus的一个子集上，VARBERT能够以50.70%的概率准确预测出开发者原始的变量名，而DIRE和DIRTY的对应概率仅为35.94%和38.00%。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Budget Recycling Differential Privacy.pdf": {
        "title": "Budget Recycling Differential Privacy",
        "abstract": "差分隐私（Differential Privacy, DP）机制通常在严格的隐私预算下，会因引入噪声而导致数据效用下降，产生“超出合理范围”的噪声结果。为此，我们提出了**预算回收差分隐私**（Budget-Recycling Differential Privacy, BR-DP）框架，旨在为现有多种DP机制提供**软边界噪声输出**。所谓“软边界”，是指该机制能够使大多数输出结果落在预设的误差范围之内，从而在保持隐私保护的同时显著提升数据效用。\n\nBR-DP的核心由两个组件构成：  \n1. **DP核心**（DP kernel）：在每次迭代中生成一个带噪声的查询结果；  \n2. **回收器**（recycler）：以概率方式决定是“回收/重新生成”该噪声结果，还是将其最终发布。\n\n我们深入研究了BR-DP的隐私核算（privacy accounting）方法，最终提出了一种**预算分配原则**，能够最优地将可用隐私预算在DP核心与回收器之间进行子分配。此外，我们设计了适用于组合场景（composition scenarios）的精确BR-DP核算算法。研究结果表明，在多次组合后，BR-DP相比传统DP机制实现了更低的累计隐私泄露。\n\n我们还探索了在BR-DP框架下通过**子采样实现隐私放大**（privacy amplification via subsampling）的机制，并针对不同类型的查询，提出了BR-DP的最优采样率设计。\n\n通过在真实数据集上的实验验证，结果表明：BR-DP显著提升了传统DP机制在**隐私-效用权衡**（utility-privacy tradeoff）方面的性能，有效缓解了隐私保护与数据可用性之间的矛盾，为差分隐私的实际应用提供了更优的解决方案。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Efficient and Generic Microarchitectural Hash-Function Recovery.pdf": {
        "title": "Efficient and Generic Microarchitectural Hash-Function Recovery",
        "abstract": "现代CPU采用多种未公开的微型架构哈希函数，以高效地将数据分布到缓存等微型架构结构中。一个广为人知的例子是缓存分片（cache slice）函数，它将缓存行（cache lines）分配至末级缓存（last-level cache）的各个分片中。掌握这些函数能够显著提升诸如“Prime+Probe”或“Rowhammer”等微型架构攻击的效率。然而，尽管一些线性哈希函数已被成功逆向工程，目前仍缺乏一种通用或自动化的方法，可用于逆向工程非线性的哈希函数——而这类非线性函数在现代CPU中十分普遍。\n\n在本文中，我们提出了一种全新的通用方法，能够自动逆向工程多种微型架构哈希函数。我们的方法结合了最初用于逻辑门最小化的技术以及计算机代数（computer algebra）中的技术，通过侧信道观察获得的输入-输出对，来推断出哈希函数的具体形式。利用这一框架，我们成功推断出了3种此前未知的非线性哈希函数，分别存在于AMD和Intel的CPU上，其中包括最新的Alder Lake混合架构CPU。我们通过复现已知的哈希函数，并评估依赖这些函数的侧信道攻击效果，验证了我们方法的有效性，实验结果显示攻击成功率超过97.65%。\n\n我们强调，在设计此类哈希函数时，必须同时兼顾性能与安全性。此外，我们还讨论了未来CPU中可采用的其他替代设计方案，以提升安全性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Serberus：Protecting Cryptographic Code from Spectres at Compile-Time.pdf": {
        "title": "Serberus：Protecting Cryptographic Code from Spectres at Compile-Time",
        "abstract": "我们提出了 **SERBERUS**，这是首个在现有硬件上全面强化恒定时间（Constant-Time, CT）代码以抵御 **Spectre 攻击**（涉及 PHT、BTB、RSB、STL 和/或 PSF 等推测执行原语）的综合缓解方案。SERBERUS 基于三项关键洞察：\n\n第一，某些硬件控制流完整性（Control-Flow Integrity, CFI）保护机制对瞬态控制流（transient control-flow）施加了足够强的限制，使得软件层面的分析能够全面考虑这些控制流行为。\n\n第二，尽管遵循了公认的 CT 代码编写规范，但仍存在两种代码模式在后 Spectre 时代是不安全的。也就是说，即使代码满足传统 CT 要求，也可能因推测执行机制而泄露秘密信息。\n\n第三，一旦解决了上述两种不安全代码模式，CT 程序中所有由 Spectre 导致的秘密信息泄露，均可归结为四类“污点原语”（taint primitives）——即那些可能将秘密值瞬态地赋给公开类型寄存器（publicly-typed register）的指令。\n\n我们在 **OpenSSL**、**Libsodium** 和 **HACL*** 等密码学库中的密码原语上对 SERBERUS 进行了评估。结果表明，SERBERUS 平均引入 **21.3% 的运行时间开销**，相比之下，目前最接近的最先进软件缓解方案平均开销为 **24.9%**，但其安全性却低于 SERBERUS。\n\n---\n\n**说明与理解补充：**\n\n- **恒定时间代码（CT）**：传统上用于防御侧信道攻击，要求程序执行时间不依赖于敏感数据。然而，Spectre 攻击利用 CPU 的推测执行机制，在瞬态执行路径中泄露秘密，绕过了传统 CT 的防护。\n- **SERBERUS 的创新点**：不仅识别出传统 CT 代码中仍存在的漏洞模式，还结合硬件 CFI 能力，系统性分析并阻断所有可能的瞬态执行泄露路径，将问题归约到四类“污点原语”，从而实现全面防护。\n- **性能优势**：相比其他缓解方案（如插入屏障指令或重写所有条件分支），SERBERUS 更精准地定位真正危险的代码模式，因此性能开销更低，同时提供更强的安全保障。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Lower Bounds for R&#233;nyi Differential Privacy in a Black-Box Setting.pdf": {
        "title": "Lower Bounds for R&#233;nyi Differential Privacy in a Black-Box Setting",
        "abstract": "我们提出了一种评估算法在Rényi差分隐私（Rényi Differential Privacy）下隐私保障的新方法。据我们所知，这是首个在**黑盒场景**（即仅能获取算法输出）下解决该问题的研究。为量化隐私泄露程度，我们设计了一种新的估计量，用于计算一对输出分布之间的Rényi散度。该估计量进一步转化为一个统计下界，并证明其在样本量较大时以高概率成立。我们的方法适用于广泛的算法类别，包括隐私研究领域中许多经典算法。通过实验，我们验证了该方法的有效性，实验涵盖了相关研究中未涉及的一些算法和隐私增强技术，进一步展现了本方法的普适性和优势。\n\n（注：根据中文表达习惯，对部分措辞和句式进行了调整，例如将被动语态转为主动语态，拆分长句，补充逻辑衔接词，并保留关键术语如“Rényi差分隐私”“黑盒场景”以确保学术准确性。）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/GPU.zip：On the Side-Channel Implications of Hardware-Based Graphical Data Compression.pdf": {
        "title": "GPU.zip：On the Side-Channel Implications of Hardware-Based Graphical Data Compression",
        "abstract": "——压缩是一种广泛部署的优化技术，能够减少现代计算体系结构中数据的传输量。然而，压缩也是一个众所周知的侧信道信息泄露源头，可能泄露底层数据的（潜在的）细粒度函数信息。不过，此前仍存在一个“安全阀”：压缩通常是软件可见的。因此，当涉及敏感数据时，软件可以主动“规避风险”，通过禁用压缩来避免泄露，并针对已知、公开的标准压缩算法量身定制缓解措施。\n\n本文挑战了上述传统观点，通过证明压缩存在**软件不可见（软件透明）的应用方式**，并利用这些方式实现攻击。具体而言，我们发现英特尔（Intel）和AMD厂商的集成显卡会以厂商专有且未公开的方式对图形数据进行压缩——**即使软件并未明确请求压缩**。这种压缩会导致与数据相关的DRAM访问流量和缓存使用情况的变化，而这些变化可通过侧信道分析手段被探测和测量。我们通过浏览器中的跨源SVG滤镜像素窃取攻击，验证了这一侧信道的有效性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Make Revocation Cheaper：Hardware-Based Revocable Attribute-Based Encryption.pdf": {
        "title": "Make Revocation Cheaper：Hardware-Based Revocable Attribute-Based Encryption",
        "abstract": "作为一种先进的“一对多”公钥加密系统，属性基加密（Attribute-Based Encryption, ABE）被广泛认为是实现不可信存储服务器（如公共云服务器）上加密数据灵活、细粒度访问控制的一项有前景的技术。然而，ABE 中的用户撤销是一个关键且具有挑战性的问题，设计高效的、可撤销的 ABE 系统在过去十年中一直是活跃的研究方向。\n\n现有绝大多数可撤销 ABE 方案在加密算法中引入时间戳，使得被撤销的用户无法解密未来时间段生成的密文。然而，为防止被撤销用户解密过去的密文，存储服务器需要执行一种称为“密文委托”（ciphertext delegation，Sahai 等，CRYPTO’12）的操作，即定期更新所有密文的时间戳。由于存储系统中的密文数量可能极其庞大，密文委托会给服务器带来巨大的计算开销。\n\n受通用可信执行环境（Trusted Execution Environment, TEE）技术日益普及的启发，本文首次提出了基于硬件的可撤销 ABE（Hardware-based Revocable ABE, HR-ABE）的研究，旨在消除这种（不可扩展的）密文委托机制，并防止不可信存储服务器与被撤销用户之间的共谋攻击。我们形式化地定义了这一新概念，并提出了一种高效的 HR-ABE 构造方案，该方案还支持将解密过程外包，以满足资源受限数据用户的需求。\n\n此外，HR-ABE 还针对 TEE 可能存在的秘密信息泄露问题（例如由侧信道攻击引起）进行了设计，确保即使 TEE 所持有的秘密信息发生泄露，也不会导致用户数据的泄露。我们形式化地证明了 HR-ABE 的安全性，并通过实验对其性能进行了基准测试。\n\n**关键词**：属性基加密，可信执行环境，数据共享，用户撤销"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Scores Tell Everything about Bob：Non-adaptive Face Reconstruction on Face Recognition Systems.pdf": {
        "title": "Scores Tell Everything about Bob：Non-adaptive Face Reconstruction on Face Recognition Systems",
        "abstract": "人脸识别系统（FRSs）通常会将每位注册用户的面部图像提取为具有判别性的实值模板向量，并存储在数据库中。这类模板数据库必须严格保护，以维护用户隐私——事实上，模板泄露所引发的安全隐患已在大量文献中被广泛报道。相比之下，查询图像与注册用户之间的相似度分数却往往缺乏保护，可通过典型的人脸识别系统API直接查询获取。这些相似度分数为攻击者提供了针对FRS的潜在攻击路径。然而，近期提出的基于分数的攻击方法大多仍不实用，因为它们本质上依赖于试错策略，需要发起大量自适应查询（超过5万次）才能实现人脸重建。\n\n我们首次提出了一种**实用的基于分数的面部重建与身份冒用攻击**，成功针对三种商用FRS API（AWS CompareFaces、FACE++ 和 KAIROS）以及五种广泛使用的预训练开源FRS实施了攻击。该攻击基于**黑盒FRS模型**，即攻击者对FRS的内部机制（如底层模型、参数、模板数据库等）一无所知，仅能进行有限次数的相似度分数查询。\n\n值得注意的是，该攻击**易于实现**，**无需试错猜测**，且仅需**少量非自适应分数查询**。我们通过分析相似度分数的拓扑含义来揭示攻击的理论基础，并提出了一种基于**正交人脸集合**（orthogonal face sets）的全新方法：即一组预先计算好的人脸近似基向量集合，这些基向量具有类似人类面部的特征，使得我们仅需少量非自适应查询，即可获取具有实际意义的相似度分数。\n\n我们的方法仅需**100次查询**，在三个测试数据集上对AWS CompareFaces API（直接攻击）和开源CosFace FRS分别实现了**超过20%和96%** 的重建成功率，所需查询次数比此前方法减少了**两个数量级**。我们通过将重建结果应用于**迁移式攻击场景**（transfer-like attack settings）以及使用其他图像相似性度量指标，验证了重建图像中确实保留了可识别的个人生物特征信息，表明攻击成功提取了用户的敏感生物特征。\n\n---\n\n**核心贡献总结：**\n\n- 首次实现**实用、高效、低查询成本**的基于分数的黑盒人脸重建与冒用攻击；\n- 提出**正交人脸集合**方法，利用预计算的人脸基向量，避免试错，实现快速、非自适应攻击；\n- 在真实商用与开源FRS上验证了攻击有效性，揭示了当前API暴露相似度分数所面临的严重隐私风险；\n- 提供了重建图像包含可识别个人生物特征的证据，凸显了此类攻击的实际威胁。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/MEA-Defender：A Robust Watermark against Model Extraction Attack.pdf": {
        "title": "MEA-Defender：A Robust Watermark against Model Extraction Attack",
        "abstract": "近年来，利用深度学习算法训练出了大量极具价值的深度神经网络（DNN）。为保护这些DNN模型原所有者的知识产权（IP），基于后门的数字水印技术已被广泛研究。然而，大多数此类水印在面对模型窃取攻击（Model Extraction Attack）时均告失效——该攻击通过向目标模型输入样本并获取对应输出，再利用这些输入-输出对训练一个替代模型，从而实现对原模型的复制。\n\n在本文中，我们提出了一种新型水印技术，用于抵御模型窃取攻击，保护DNN模型的知识产权，命名为**MEA-Defender**。具体而言，我们通过在输入空间中融合来自两个不同源类的样本生成水印；同时设计了一种水印损失函数，使得水印样本在输出空间中的分布与主任务样本的输出空间保持一致。由于我们的水印在输入域和输出域上均为主任务样本对应空间的重要组成部分，因此在模型窃取过程中，该水印将不可避免地与主任务一同被提取到被盗模型中。\n\n我们在四种模型窃取攻击场景下进行了广泛实验，涵盖五个数据集，以及基于监督学习和自监督学习算法训练的六种模型。实验结果表明，MEA-Defender对多种模型窃取攻击均具有高度鲁棒性，且能有效抵抗各类水印移除与检测手段。\n\n---\n\n**翻译说明与理解补充**：\n\n- **backdoor-based watermarks**：基于后门的数字水印，指通过在模型中植入特定触发样本（即“后门”），在验证时通过该样本的输出来判断模型所有权。\n- **model extraction attack**：模型窃取攻击，攻击者通过黑盒访问目标模型，利用查询-响应机制训练出功能相似甚至相同的替代模型，从而非法复制模型。\n- **input domain / output domain**：输入域指模型输入数据的分布空间，输出域指模型输出（如分类概率、嵌入向量等）的分布空间。MEA-Defender的核心思想是使水印样本在输入和输出两个空间中都与主任务数据“不可分割”，从而确保其被一同窃取。\n- **supervise & self-supervised learning**：涵盖当前主流训练范式，增强方法普适性。\n\n本文方法的关键创新在于**水印与主任务的域一致性设计**，使其难以被剥离，显著提升了抗窃取能力。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Securely Fine-tuning Pre-trained Encoders Against Adversarial Examples.pdf": {
        "title": "Securely Fine-tuning Pre-trained Encoders Against Adversarial Examples",
        "abstract": "随着自监督学习的不断发展，预训练范式已成为深度学习领域中的主流解决方案。模型提供者提供预训练编码器，这些编码器被设计为通用的特征提取器，使下游用户能够通过微调，以极小的努力利用大规模模型的强大能力。然而，近期研究揭示了预训练编码器存在一个关键漏洞：它们容易受到攻击者精心设计的“与下游任务无关的对抗样本”（Downstream-Agnostic Adversarial Examples, DAEs）的攻击。一个尚未解决的核心问题是：在预训练编码器对攻击者公开可访问的情况下，是否仍有可能增强下游模型对DAEs的鲁棒性？\n\n本文首先深入探讨了当前在预训练范式下针对对抗样本的防御机制。我们发现，现有防御方法失效的根本原因在于：预训练数据与下游任务之间存在领域偏移（domain shift），以及编码器参数本身对扰动的高度敏感性。为应对这些挑战，我们提出了一种名为**遗传进化引导的对抗微调**（Genetic Evolution-Nurtured Adversarial Fine-tuning, Gen-AF）的两阶段对抗微调方法，旨在提升下游模型的鲁棒性。\n\nGen-AF 的第一阶段采用**遗传引导的双轨对抗微调策略**，以有效继承预训练编码器的知识。该方法将预训练编码器和分类器分别进行优化，同时引入**遗传正则化**机制，以保留模型原有的拓扑结构，防止微调过程中关键特征表示的退化。在第二阶段，Gen-AF 评估模型每一层的鲁棒敏感性，并据此构建一个敏感性字典，从中筛选出鲁棒性最强的 top-k 冗余层，其余层则保持固定。在此基础上，我们进一步执行**进化适应性微调**，以提升模型在未知扰动下的泛化能力。\n\n我们在十种自监督训练方法和六个数据集上进行了广泛的实验，结果表明：Gen-AF 在面对当前最先进的DAEs攻击时，不仅保持了较高的测试准确率，还显著提升了模型的鲁棒测试准确率。这一成果充分验证了 Gen-AF 在提升下游模型对抗攻击鲁棒性方面的有效性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/GAuV：A Graph-Based Automated Verification Framework for Perfect Semi-Honest Security of Multiparty Computation Protocols.pdf": {
        "title": "GAuV：A Graph-Based Automated Verification Framework for Perfect Semi-Honest Security of Multiparty Computation Protocols",
        "abstract": "——证明多方计算（MPC）协议的安全性是一项极具挑战性的任务。在当前基于模拟（simulation-based）的MPC安全定义下，一个安全证明通常包括一个模拟器（simulator），该模拟器通常针对具体协议设计，需要人工手动构造，同时还需要对模拟器输出的分布以及真实世界中被攻陷方的视图（views）进行理论分析。这给验证一个给定MPC协议的安全性带来了显著障碍。此外，一个原本安全的MPC协议实例，可能由于实现上的疏忽而轻易丧失其安全保障，而这类安全问题在实际中往往难以察觉。\n\n在本工作中，我们提出了一种通用的自动化框架，用于验证MPC协议实例在半诚实（semi-honest）敌手模型下的**完美安全性**。我们的框架具有**完美可靠性（perfect soundness）**：任何通过本框架被证明安全的协议，也必然满足基于模拟的MPC安全定义。我们通过展示该框架的**完备性**来进一步验证其能力：对于著名的BGW协议的任意实例，我们的框架均可在多项式时间内，针对每一个可能被攻陷的参与方集合，自动完成其安全性证明。与以往仅关注“黑盒隐私性”（即要求被攻陷方的输出中不包含任何关于诚实方输入的信息）的工作不同，我们的框架具备更广泛的适用性，**有望用于证明任意MPC协议的安全性**。\n\n我们将该框架实现为一个原型系统。实验评估表明，该原型能够在合理的时间内，自动证明BGW协议以及B2A（二进制到算术）转换协议在半诚实模型下的完美安全性。\n\n**关键词**：多方计算协议，完美半诚实安全性，自动化验证，图变换"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Nurgle：Exacerbating Resource Consumption in Blockchain State Storage via MPT Manipulation.pdf": {
        "title": "Nurgle：Exacerbating Resource Consumption in Blockchain State Storage via MPT Manipulation",
        "abstract": "——区块链拥有复杂的架构，涵盖了多种组件，例如共识网络、智能合约、去中心化应用（DApps）以及各类辅助服务。尽管这些组件带来了诸多优势，但它们也暴露了多种攻击面，从而对区块链系统构成严重威胁。在本研究中，我们揭示了一种全新的攻击面——**状态存储（state storage）**。该组件基于**默克尔帕特里夏树（Merkle Patricia Trie, MPT）**构建，在维护区块链状态一致性方面发挥着关键作用。\n\n此外，我们设计并提出了**NURGLE**，这是首个专门针对状态存储的**拒绝服务攻击（Denial-of-Service, DoS）**。NURGLE通过大量生成状态存储中的中间节点，迫使区块链节点在状态维护与验证过程中消耗额外的计算和内存资源，从而显著降低系统整体性能。我们对NURGLE进行了全面而系统的评估，涵盖影响其攻击效果的关键因素、对区块链性能的实际影响、实施攻击的经济成本，并在真实环境中实际演示了其对区块链系统造成的破坏。\n\nNURGLE的影响不仅限于区块链性能的下降，更可能削弱用户对区块链系统的信任，进而降低其原生加密货币的市场价值。此外，我们还进一步探讨了三项切实可行的防御措施，以缓解NURGLE带来的威胁。\n\n截至本文撰写时，NURGLE所利用的漏洞已被**六大主流区块链平台**确认，我们也因此获得了来自这些平台总计**数千美元**的漏洞赏金奖励。\n\n---\n\n**说明与翻译要点解析：**\n\n- **\"attack surface\"** 译为“攻击面”，是网络安全中的标准术语，指系统中可能被攻击者利用的薄弱区域。\n- **\"state storage\"** 译为“状态存储”，是区块链中用于记录账户余额、合约状态等实时数据的核心组件。\n- **\"Merkle Patricia Trie\"** 保留英文术语并补充中文“默克尔帕特里夏树”，因其为密码学数据结构专有名词，广泛采用音译+意译结合方式。\n- **\"NURGLE\"** 为作者提出的新型攻击名称，采用大写斜体（原文风格），中文译为“NURGLE”并加粗以突出其作为专有攻击术语的地位。\n- **\"proliferating intermediate nodes\"** 译为“大量生成中间节点”，准确反映攻击机制：通过构造复杂树结构增加节点数量，从而消耗资源。\n- **\"financial cost\"** 译为“经济成本”，强调攻击实施所需的实际支出（如Gas费、硬件资源等）。\n- 最后一段强调研究的影响力：漏洞被主流链确认、获得赏金，体现研究价值与现实意义。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Learn What You Want to Unlearn：Unlearning Inversion Attacks against Machine Unlearning.pdf": {
        "title": "Learn What You Want to Unlearn：Unlearning Inversion Attacks against Machine Unlearning",
        "abstract": "——机器遗忘（Machine unlearning）已成为实现“被遗忘权”的一种有前景的解决方案。在该权利下，个人可以请求将其数据从机器学习模型中删除。然而，现有的机器遗忘研究主要关注遗忘方法的有效性与效率，却忽视了对遗忘过程中隐私脆弱性的深入探究。当攻击者能够同时访问模型的两个版本——即原始模型和被遗忘后的模型时，机器遗忘实际上开辟了一个新的攻击面。\n\n在本文中，我们首次系统性地研究了机器遗忘可能泄露被遗忘数据机密内容的程度。具体而言，在“机器学习即服务”（Machine Learning as a Service, MLaaS）的背景下，我们提出了**遗忘逆向攻击**（unlearning inversion attacks），仅通过访问原始模型和遗忘后的模型，即可恢复被遗忘样本的特征信息和标签信息。\n\n我们通过在多个基准数据集上，针对不同的模型架构，以及对精确型和近似型代表性遗忘方法进行大量实验，评估了所提出的遗忘逆向攻击的有效性。实验结果表明，该攻击能够成功揭示被遗忘数据中的敏感信息。\n\n为此，我们进一步提出了三种可能的防御机制，有助于缓解上述攻击，但这些方法在一定程度上会降低遗忘后模型的实用性。本文的研究揭示了在机器遗忘与遗忘数据隐私保护之间一个尚未被充分探讨的漏洞，凸显了设计机器遗忘机制时需格外谨慎，必须确保在实现数据遗忘的同时，不会泄露被遗忘数据的相关信息。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Ligetron：Lightweight Scalable End-to-End Zero-Knowledge Proofs Post-Quantum ZK-SNARKs on a Browser.pdf": {
        "title": "Ligetron：Lightweight Scalable End-to-End Zero-Knowledge Proofs Post-Quantum ZK-SNARKs on a Browser",
        "abstract": "——零知识（Zero-Knowledge, ZK）证明最早由Goldwasser、Micali和Rackoff在1985年的STOC会议上提出，是当代密码学的基石之一。随着区块链技术的发展，以ZK-SNARKs形式部署零知识证明系统重新引发了广泛兴趣。ZK-SNARKs因其**非交互性**（实际上可公开验证）和**简洁性**而极具吸引力。然而，当前的实际部署仍面临巨大挑战：证明生成时间过长、内存占用极高，且在普通硬件上难以扩展至大规模计算电路。\n\n为此，我们设计并实现了一个高效的**亚线性非交互式零知识系统**——**Ligetron**。该系统可作为**网页应用部署**，并能扩展至**数十亿逻辑门**的电路规模。本系统的核心创新在于选择了一种理想的中间表示形式——**WebAssembly（WASM）**，其优势在于：（1）具备表达复杂计算的多样性；（2）可从大多数主流高级语言编译而来；（3）蕴含丰富的语义信息，有助于实现空间高效性。\n\n在系统后端，我们基于Ames等人于2017年ACM CCS提出的Ligero零知识系统，设计并实现了一个**空间高效的变种版本**，该版本能够充分利用WASM的语义信息。Ligetron是**首个可在浏览器中运行、可扩展至十亿级逻辑门的抗量子ZK-SNARK系统**。\n\n在普通硬件上，Ligetron能够支持任意规模的大型电路，同时展现出极具竞争力的证明生成与验证时间，其**证明长度也优于所有已有的抗量子ZK-SNARK方案**。\n\n**关键词**：ZK-SNARKs，空间高效，浏览器部署，抗量子，零知识证明"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/ConjunCT：Learning Inductive Invariants to Prove Unbounded Instruction Safety Against Microarchitectural Timing Attacks.pdf": {
        "title": "ConjunCT：Learning Inductive Invariants to Prove Unbounded Instruction Safety Against Microarchitectural Timing Attacks",
        "abstract": "过去十年中，出现了大量源于各类硬件结构（如缓存、分支预测器、执行端口、TLB、推测执行等）的微架构侧信道攻击。这些攻击的根源在于：软件将敏感数据传递给了所谓的“不安全”或“可传输”指令——即那些执行时间依赖于其操作数数值的指令。相应地，学术界和工业界提出了大量防御机制（涵盖硬件和软件层面），旨在强制执行如下安全策略：**敏感数据 ⇏ 不安全指令的操作数**。然而，实现这一策略的前提是：能够识别出在特定微架构下哪些指令是不安全的。\n\n但这一任务极具挑战性——它要求设计者分析动态指令间可能存在的无限组合，以揭示它们之间微妙的交互行为。这种复杂性使得人工分析几乎不可行。\n\n本文针对上述挑战，提出了 **CONJUNCT** 框架。给定一个处理器的寄存器传输级（RTL）设计，CONJUNCT 能够**对所有可能的执行路径进行形式化证明**，判断每条指令集架构（ISA）中的指令是：i）在任何执行周期内始终安全，还是 ii）存在不安全的情况。该方法结合了**符号化分析**（用于生成反例或示例）和**归纳不变式学习**（以符号分析生成的示例为起点进行引导），并引入了一种新颖的**条件信息流谓词**，我们证明该谓词在分析处理器流水线中的信息流时具有强大能力。\n\n我们在多个复杂度各异的 RISC-V 微架构上验证了该分析方法，并成功提取出每条指令的“安全/不安全”集合。通过巧妙地利用程序合成技术，我们实现了从输入 RTL 到最终分析结果**几乎完全自动化的端到端流程**。例如，仅需要设计者添加**8 个注解**，即可完整分析 RISC-V RocketChip 核心。\n\n最后，我们通过多个案例研究展示了 CONJUNCT 的实用价值：一方面，微架构设计师可借助 CONJUNCT 理解某项高级优化（如推测执行或缓存预取）可能带来的安全隐患；另一方面，CONJUNCT 生成的归纳不变式能够帮助精准定位微架构中不安全行为发生的**具体模块或阶段**，从而为安全修复提供明确指导。\n\n简而言之，CONJUNCT 不仅是一种自动化识别不安全指令的新方法，更是一种赋能微架构设计者系统性理解并提升处理器安全性的强大工具。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：Technical Implementation and Human Impact of Internet Privacy Regulations.pdf": {
        "title": "SoK：Technical Implementation and Human Impact of Internet Privacy Regulations",
        "abstract": "——随着对个人数据被滥用的潜在风险以及此前隐私保护制度缺陷的认识日益加深，全球范围内已出台了大量新的隐私法规。其中，一些法律（尤其是欧盟的《通用数据保护条例》（GDPR）和美国的《加州消费者隐私法案》（CCPA））已成为计算机科学领域大量研究的焦点，而另一些法规则较少受到关注。在本研究中，我们从全球范围选取了24项隐私法律和数据保护条例——既包括计算机科学界频繁研究的，也包括此前被忽视的——并构建了一套关于这些法律所赋予权利与施加义务的分类体系（taxonomy）。随后，我们利用这一分类体系，系统梳理了发表在计算机科学领域会议和期刊上的270篇技术论文，这些论文探讨了上述法律的影响，并探索了技术手段如何补充法律层面的隐私保护。最后，我们从跨学科视角分析该领域的研究现状，并对未来计算机科学与法律隐私交叉领域的研究方向提出建议。\n\n关键词：系统综述（SoK），隐私法规，数据保护，可用隐私，测量分析"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/MAWSEO：Adversarial Wiki Search Poisoning for Illicit Online Promotion.pdf": {
        "title": "MAWSEO：Adversarial Wiki Search Poisoning for Illicit Online Promotion",
        "abstract": "——作为恶意篡改编辑的一个典型例子，针对维基百科（Wiki）的搜索污染（Wiki search poisoning）是一种网络犯罪行为，其目的是通过篡改维基百科文章内容，使相关查询的搜索结果显示非法商业推广信息。在本文中，我们首次报告了一项研究，揭示了这种隐蔽的黑帽搜索引擎优化（blackhat SEO）手段在维基百科上可以被自动化实现。我们提出的技术名为MAWSEO（Malicious Adversarial Wiki Search Engine Optimization），利用对抗性文本修改来实现现实世界中的网络犯罪目标，包括提升搜索排名、逃避恶意编辑检测、保持主题相关性、语义一致性，以及确保用户能感知推广内容但又不至于引起警觉（即不触发用户反感）等。我们的实验评估与用户研究表明，MAWSEO能够有效且高效地生成对抗性恶意编辑，不仅能够绕过当前最先进的维基百科内置恶意编辑检测系统，还能成功将推广内容传递给维基百科用户，而不会引发用户的怀疑或警惕。此外，我们还研究了针对此类攻击的潜在防御措施，包括在维基生态系统中基于内容连贯性（coherence）的检测方法，以及通过对抗训练增强恶意编辑检测模型的鲁棒性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Exploring the Orthogonality and Linearity of Backdoor Attacks.pdf": {
        "title": "Exploring the Orthogonality and Linearity of Backdoor Attacks",
        "abstract": "——后门攻击通过在输入中嵌入攻击者指定的模式，导致模型发生错误分类。这种对机器学习的安全威胁长期以来备受关注。学术界已提出了多种防御技术，但它们是否能在广泛的后门攻击场景中有效发挥作用？\n\n我们认为，后门攻击在当代研究中既重要又普遍，因此我们对14种攻击方法和12种防御技术进行了系统性研究。实证结果表明，现有的防御机制在面对某些特定攻击时常常失效。为深入理解其原因，我们从理论角度对后门攻击的特性进行了分析。特别地，我们将后门投毒建模为一个持续学习（continual learning）任务，并引入了两个关键属性：**正交性**（orthogonality）和**线性性**（linearity）。这两个特性从理论上深入揭示了模型如何学习后门模式。这一分析有助于解释为何多种防御技术会失败。\n\n通过本研究，我们指出了当前防御后门攻击所面临的开放性挑战，并提出了未来可能的研究方向。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Device-Oriented Group Messaging：A Formal Cryptographic Analysis of Matrix' Core.pdf": {
        "title": "Device-Oriented Group Messaging：A Formal Cryptographic Analysis of Matrix' Core",
        "abstract": "——聚焦于其密码学核心，我们首次对Matrix安全群组消息协议给出了形式化描述。我们注意到，现有文献中的安全消息模型均未能刻画用户、其设备以及所参与群组之间的关系（以及共享状态）。为此，我们提出了**面向设备的群组消息模型**（Device-Oriented Group Messaging model），以准确刻画Matrix协议中的这些关键特征。利用这一新的形式化方法，我们分析得出：只要Matrix引入了经过认证的群组成员机制，该协议即可实现机密性和身份认证等基本安全目标。\n\n另一方面，Matrix中状态共享的功能虽然与文献中一些高级安全概念——如前向安全性（forward security）和破坏后安全性（post-compromise security）——存在冲突，但它却实现了诸如历史消息共享和账户恢复等实用功能。这引发了一个更广泛的问题：我们应当如何重新思考和概念化这些安全目标，以在保障安全的同时兼顾实际可用性和用户体验。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/LACMUS：Latent Concept Masking for General Robustness Enhancement of DNNs.pdf": {
        "title": "LACMUS：Latent Concept Masking for General Robustness Enhancement of DNNs",
        "abstract": "深度神经网络（DNNs）对对抗性攻击的易感性，以及其在真实世界变化下有限的鲁棒性，严重阻碍了它们的大规模应用。尽管对抗训练在增强模型抵御此类扰动方面展现出潜力，但现有方法通常仅针对单一类型的攻击，并可能显著降低模型的整体性能。为此，我们提出了**LA tent C oncept M asking for robUS tness**（LACMUS，即“基于潜在概念掩码的鲁棒性增强”）——一种新颖的、以感知为导向的方法，能够在无需预先了解对抗性环境的前提下，提升DNN的鲁棒性。\n\n我们认为，DNN对对抗性扰动和分布漂移的敏感性，根源在于其对数据集中“非共性概念”（non-common concepts）的过拟合。这种过拟合导致模型过度依赖某些特定的学习实例，从而增加了其脆弱性。LACMUS通过将高维数据映射到一个**潜在概念空间**，识别并分析该空间中“非共性概念”的分布模式。随后，该方法采用**概念掩码策略**，有选择性地遮蔽数据中的某些特征，迫使模型在决策时依赖更广泛、更泛化的信息，从而提升其决策的鲁棒性。\n\nLACMUS的独特之处在于，它是一个**通用的、与攻击无关的框架**，利用**基于概念的增强**（concept-wise augmentation）手段，有效应对包括对抗性攻击、语义变化和分布偏移在内的多种挑战。我们的主要贡献包括：\n\n1. 开发了一种用于提升模型鲁棒性的工具；  \n2. 提出了一种将数据映射到潜在概念空间的机制；  \n3. 设计了一种识别“基于概念的误分类模式”的策略；  \n4. 构建了一个创新的数据增强模块，该模块充分利用潜在概念信息进行数据扩充。\n\n实验表明，LACMUS能够显著增强模型的鲁棒性和泛化能力，即使在训练数据稀缺的情况下依然有效。我们在MNIST、CIFAR-10、ImageNet和CelebA等多个数据集上验证了其有效性。此外，我们还将经过增强的数据集公开提供给研究社区，以支持训练出更具鲁棒性的模型，推动该领域的发展。\n\n总之，LACMUS不仅提供了一种新颖的鲁棒性增强范式，还为理解DNN的脆弱性根源提供了概念层面的视角，为构建更安全、更可靠的人工智能系统奠定了坚实基础。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Secure Ranging with IEEE 802.15.4z HRP UWB.pdf": {
        "title": "Secure Ranging with IEEE 802.15.4z HRP UWB",
        "abstract": "—安全测距（Secure ranging）指的是能够以可靠的方式对两个设备之间的实际物理距离设定一个**上界**的能力。这一能力在多种应用场景中至关重要，例如用于物理系统的解锁操作。在本研究中，我们将聚焦于基于IEEE 802.15.4z（简称4z）标准中规定的超宽带脉冲无线电（UWB-IR）技术的安全测距机制。特别地，4z标准在高速率脉冲重复频率（HRP）工作模式下定义了一种加密波形，即**加扰时间戳序列**（Scrambled Timestamp Sequence, STS），用于实现安全测距。\n\n本研究对4z HRP模式在采用合理接收机设计时的安全性进行了分析，并证明STS波形确实能够支持安全测距。我们首先回顾了已有研究中采用的STS接收机设计，并分析了其存在的安全漏洞。随后，我们提出了一种**参考型STS接收机**，并证明在4z HRP模式下使用STS波形可实现安全测距。同时，我们也对该参考型安全STS接收机的性能边界进行了刻画。数值实验结果进一步验证了理论分析的正确性，并证明了该参考STS接收机具备实际安全性。\n\n**关键词** — 安全测距，脉冲无线电，超宽带（UWB），IEEE，802.15.4z，STS。\n\n---\n\n**说明与理解补充**：  \n- “Upper-bounding the actual physical distance” 指的是通过测距机制确保测量出的距离不会小于真实距离（即防止攻击者通过信号重放或中继等手段“缩短”感知距离），从而保证只有物理上足够近的设备才能通过认证，防止中继攻击（relay attack）。  \n- STS（加扰时间戳序列）是IEEE 802.15.4z中为增强测距安全性而引入的加密脉冲序列，其随机性可有效抵御时间同步攻击和信号复制攻击。  \n- 本研究的核心贡献在于：指出传统STS接收机可能存在安全缺陷，提出一种更安全的参考接收机架构，并从理论和实验两方面验证其安全性和性能边界。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/More Haste, Less Speed：Cache Related Security Threats in Continuous Integration Services.pdf": {
        "title": "More Haste, Less Speed：Cache Related Security Threats in Continuous Integration Services",
        "abstract": "持续集成（CI）平台已广泛采用缓存机制，通过存储和复用依赖包来加速CI任务的执行。然而，当缓存对象在不受信任的边界之间共享时，CI缓存也暴露了新的攻击面。在本文中，我们对七种主流CI平台（CIPs）中的CI缓存功能所面临的潜在安全威胁进行了系统性研究。我们发现，现有CI平台在缓存共享和继承策略上存在隔离缺陷，可能导致缓存投毒（cache poisoning）和数据泄露等问题。通过利用这些脆弱机制，我们进一步揭示了四种攻击向量，攻击者可借此在缓存中隐蔽地注入恶意代码，或窃取敏感数据。更严重的是，许多CI平台提供的官方缓存模板本身存在漏洞，默认情况下会错误地将敏感数据存储在缓存中，从而导致其暴露。为评估我们所披露威胁的潜在影响，我们开发了一款分析工具，并对开源仓库开展了大规模实证测量。测量结果表明，许多热门开源仓库可能受到这些攻击的影响。我们还识别出78个在缓存对象中暴露高价值机密信息、存在机密泄露风险的仓库。我们已及时将所发现的安全漏洞通报给相关责任方，并获得了积极回应。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Understanding and Benchmarking the Commonality of Adversarial Examples.pdf": {
        "title": "Understanding and Benchmarking the Commonality of Adversarial Examples",
        "abstract": "语音识别系统利用深度学习算法将音频转换为文本。已有大量研究表明，存在多种对抗样本（Adversarial Example, AE）攻击方式，即通过添加精心设计的噪声，可以诱使语音识别系统输出完全错误的文本。本文旨在从语音学（音系学）角度揭示对抗音频的独特性质。我们认为，分析这些独特性质对于理解自动语音识别（ASR）模型上的对抗攻击至关重要，同时也能指导对抗样本的生成与防御。因此，本文旨在回答以下三个问题：（1）在不同攻击方式中普遍存在的对抗音频有哪些独特性质？（2）如何量化这些独特性质？（3）如何利用这些性质来提升ASR模型的安全性？为回答这些问题，我们基于声学特征和统计分析开展了一项大规模测量研究。通过对2,400个音频样本共计612,000个声学-统计特征向量进行测量，我们总结出对抗音频的四个关键特性：填补能量间隙（filling energy gap）、类语音形态（speech-like morphology）、信号无序性（disordered signal）以及异常语言模式（abnormal linguistic pattern）。基于这些特性，我们设计了一种“自然度评分”（naturalness score）来评估攻击的隐蔽性，并提出了一种对抗样本检测器，其平均准确率达到91.1%。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Breach Extraction Attacks：Exposing and Addressing the Leakage in Second Generation Compromised Credential Checking Services.pdf": {
        "title": "Breach Extraction Attacks：Exposing and Addressing the Leakage in Second Generation Compromised Credential Checking Services",
        "abstract": "——凭证篡改攻击（Credential tweaking attacks）利用已泄露的密码，生成语义上相似的密码变体，从而尝试获取受害者的账户访问权限。这类攻击能够绕过第一代“已泄露凭证检测”（C3，Compromised Credential Checking）服务，因为这些服务通常只检查用户输入的密码是否**完全匹配**数据库中的已知泄露密码，而无法识别其语义相近的变体。\n\n为应对这一问题，第二代C3服务应运而生，其代表是名为“**我可能被入侵了吗？**”（Might I Get Pwned, 简称 MIGP）的隐私保护协议。MIGP 允许客户端查询：某个密码或其语义上相似的变体，是否存在于服务器所维护的已泄露凭证数据库中。该协议的核心隐私目标是：**服务器无法获知用户输入的具体密码**，同时**客户端也无法获取任何服务器存储的泄露凭证信息**。\n\n在本研究中，我们首先对 MIGP 协议的密码学层面的信息泄露（cryptographic leakage）进行了形式化建模，并开展了安全分析，以评估该泄露对服务器所保存凭证集合的影响。我们特别关注这种信息泄露如何被用于**数据泄露提取攻击**（breach extraction attacks）——即一个“诚实但好奇”（honest-but-curious）的客户端，通过遵循协议流程与服务器交互，试图从中推断出服务器数据库中存储的某些具体凭证信息。\n\n此外，我们还发现了**由 Cloudflare 实际部署 MIGP 时所引入的额外信息泄露**，这些泄露源于具体实现层面的设计选择。我们进一步评估了这些泄露如何增强攻击者在数据泄露提取攻击中的密码猜测能力，即显著提升其推断出真实泄露凭证的效率。\n\n最后，我们提出了 **MIGP 2.0**——MIGP 协议的新版本，旨在最大限度地减少信息泄露，有效防御上述攻击。MIGP 2.0 在保持原有隐私保护目标的基础上，通过优化协议结构，消除了原有协议和实现中的安全弱点，从而提供更强的安全保障。\n\n---\n\n**总结**：  \n本研究揭示了当前 MIGP 协议在理论设计和实际部署中存在的隐私泄露问题，分析了其对服务器凭证库构成的威胁，并提出了改进方案 MIGP 2.0，为下一代隐私保护型凭证检测服务提供了更安全、更可靠的技术路径。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Why Does Little Robustness Help. A Further Step Towards Understanding Adversarial Transferability.pdf": {
        "title": "Why Does Little Robustness Help. A Further Step Towards Understanding Adversarial Transferability",
        "abstract": "——深度神经网络（DNN）的对抗样本具有可迁移性：能够成功欺骗某个白盒代理模型的对抗样本，往往也能欺骗其他架构不同的黑盒模型。尽管已有大量实证研究为生成高可迁移性对抗样本提供了指导，但这些发现大多缺乏深入解释，甚至在实际应用中给出了相互矛盾或令人困惑的建议。\n\n本文旨在进一步深入理解对抗样本的可迁移性，尤其聚焦于代理模型（surrogate）层面的因素。我们从“弱鲁棒性”这一引人注目的现象出发：即使用轻微扰动的对抗样本进行对抗训练的模型，反而能作为更优的代理模型，提升迁移攻击的成功率。我们认为，这一现象源于两个主导因素之间的权衡：**模型平滑性**（model smoothness）与**梯度相似性**（gradient similarity）。本文的研究重点在于揭示二者**协同作用**对可迁移性的影响，而非孤立地分析它们各自的作用。\n\n通过结合理论分析与实证研究，我们提出假设：对抗训练中因“脱离数据流形”（off-manifold）的对抗样本所引起的数据分布偏移，是导致梯度相似性下降的根本原因。\n\n基于上述洞察，我们进一步探究了常见的数据增强（data augmentation）和梯度正则化（gradient regularization）方法对可迁移性的影响，并系统分析了这种“平滑性-相似性”权衡在不同训练范式下的具体表现，从而构建了一个关于可迁移性背后调控机制的全面框架。\n\n最终，我们提出了一种构建更优代理模型以增强可迁移性的通用路径：**同时优化模型平滑性与梯度相似性**。例如，将输入梯度正则化（input gradient regularization）与感知锐度最小化（Sharpness-Aware Minimization, SAM）相结合的方法，已在大量实验中得到验证，显著提升了迁移攻击效果。\n\n总之，我们呼吁：在执行高效的迁移攻击时，应关注这两个因素的**联合影响**，而非仅优化其一而忽视另一个；同时强调，**对代理模型的精心设计**在其中发挥着至关重要的作用。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Video-Based Cryptanalysis：Extracting Cryptographic Keys from Video Footage of a Device's Power LED Captured by Standard Video Cameras.pdf": {
        "title": "Video-Based Cryptanalysis：Extracting Cryptographic Keys from Video Footage of a Device's Power LED Captured by Standard Video Cameras",
        "abstract": "在本文中，我们提出了一种名为“基于视频的攻击分析”（video-based cryptanalysis）的新方法，该方法通过分析设备电源指示灯（power LED）的视频录像，从设备中恢复出密钥。我们指出，CPU执行的密码学运算会改变设备的功耗，进而影响设备电源LED的亮度。基于这一现象，我们展示了攻击者如何利用商用摄像头（例如iPhone 13的摄像头或联网的安防摄像头）从目标设备中恢复出密钥。\n\n具体方法是：首先获取设备电源LED的视频录像（视频中画面几乎全部为电源LED），然后利用摄像头的“卷帘快门”（rolling shutter）效应，将采样率从视频帧率（如60帧/秒，即每秒60次测量）提升至卷帘快门的扫描速率（例如iPhone 13 Pro Max可达每秒6万次测量），从而将采样率提高三个数量级。随后，对视频帧在RGB色彩空间进行分析，提取LED亮度对应的RGB值，并据此推断设备的功耗变化，最终恢复出密钥。\n\n我们通过实施两种基于旁道的时序攻击，验证了该方法的有效性，成功恢复出以下密钥：  \n（1）通过分析距离智能卡读卡器16米外、被劫持的联网安防摄像头拍摄的视频，从智能卡中恢复了256位的ECDSA密钥；  \n（2）利用iPhone 13 Pro Max摄像头拍摄Logitech Z120 USB音箱电源LED的视频，从三星Galaxy S8手机中恢复了378位的SIKE密钥。该音箱与手机连接在同一USB集线器上，手机正在通过该集线器充电，因此其功耗变化通过共用的电源路径影响了音箱LED的亮度。\n\n此外，我们还探讨了针对此类攻击的防御对策、现有方法的局限性，并结合未来摄像头技术的预期发展（如更高分辨率、更快帧率和更先进的图像处理能力），展望了基于视频的攻击分析的发展前景。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：Collusion-resistant Multi-party Private Set Intersections in the Semi-honest Model.pdf": {
        "title": "SoK：Collusion-resistant Multi-party Private Set Intersections in the Semi-honest Model",
        "abstract": "——私有集合交集协议允许双方基于各自私有的数据集合，在不泄露集合中其他信息的前提下，计算两个集合的交集。这类协议已研究近20年，期间在计算开销和通信成本方面均取得了显著优化。然而，当参与方超过两个时，这些经典协议便不再适用。尽管已有针对多方场景的扩展方案，但其效率远低于两方情形。如何设计出具备抗合谋能力、且效率接近两方协议的多方私有集合交集（MPSI）协议，仍是一个尚未解决的开放性问题。\n\n这一目标的实现面临诸多挑战：一方面，已有方案种类繁多，缺乏系统性的归纳与分类；另一方面，每项新研究通常仅参考少数已有协议，忽视了早期工作中提出的重要进展。此外，MPSI协议所依赖的多种构造方法和基础组件尚未得到系统总结。\n\n本工作的目标是：为协议设计者指明当前研究中的空白与潜在发展方向，指出常见的安全漏洞，并构建一个参考性分析框架。为此，我们主要聚焦于半诚实（semi-honest）安全模型。我们得出结论：当前的多方私有集合交集协议并非“万能解”，实际上存在多种协议，各自适用于特定的应用场景，在不同需求下表现出相对优势。\n\n**关键词**——私有集合交集，知识系统化，隐私增强技术"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/TCP Spoofing：Reliable Payload Transmission Past the Spoofed TCP Handshake.pdf": {
        "title": "TCP Spoofing：Reliable Payload Transmission Past the Spoofed TCP Handshake",
        "abstract": "——TCP欺骗攻击，即通过暴力破解服务器选定的32位初始序列号（ISN），建立IP地址伪造的TCP连接，这一攻击方式已有数十年历史。然而，在实际应用中，TCP欺骗的影响一直较为有限。其主要限制之一在于，攻击者不仅需要猜中ISN以完成三次握手，还必须准确模拟服务器的发送窗口（send window），才能可靠地传输后续的数据载荷。尽管已知的暴力破解攻击可在握手阶段就包含部分载荷数据，但这种方式无法正确模拟交互式的TCP对话过程，且在传输较大载荷时成本极高（甚至不可行）。正是由于TCP欺骗在实践中的不切实际，一些服务至今仍依赖源IP地址进行关键安全决策，例如防火墙规则、垃圾邮件分类，或数据库中的网络层身份认证。\n\n我们证明，攻击者不仅可以成功建立伪造的TCP连接，还能通过这些连接可靠地发送伪造的TCP载荷。为此，我们提出了两种新型载荷发送原语（sending primitives）。\n\n首先，我们揭示了攻击者可以滥用TCP发送窗口的宽松处理机制，通过高效的暴力破解方式向连接中注入载荷。其次，我们提出了“基于反馈的TCP欺骗”（feedback-guided TCP spoofing）技术，使攻击者能够泄露服务器选定的ISN。我们设计了三种反馈信道：第一种利用TCP SYN Cookie机制；另外两种则分别针对电子邮件和数据库应用中的特定操作行为进行利用。\n\n我们发现，这类载荷发送原语能够在伪造的TCP连接上稳定传输数据，并且其潜在应用场景广泛存在。最后，我们讨论了相应的防御对策，并介绍了我们与相关方进行漏洞披露的过程。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Node-aware Bi-smoothing：Certified Robustness against Graph Injection Attacks.pdf": {
        "title": "Node-aware Bi-smoothing：Certified Robustness against Graph Injection Attacks",
        "abstract": "—深度图学习（Deep Graph Learning, DGL）已成为多个领域中的关键技术。然而，近期研究揭示了DGL模型存在的安全漏洞，例如容易受到逃避攻击（evasion attacks）和投毒攻击（poisoning attacks）的影响。尽管已有经验性（empirical）和可证明的（provable）鲁棒性技术被提出，用于防御图结构修改攻击（Graph Modification Attacks, GMAs），但针对图注入攻击（Graph Injection Attacks, GIAs）的可验证鲁棒性（certified robustness）问题仍基本未被探索。为填补这一空白，我们提出了**节点感知的双平滑框架**（node-aware bi-smoothing framework），这是首个针对一般节点分类任务、在图注入攻击下具备可验证鲁棒性的方法。值得注意的是，该节点感知双平滑机制是**模型无关的**（model-agnostic），适用于逃避攻击和投毒攻击两种场景。\n\n通过严格的理论分析，我们确立了所提出平滑机制的**可验证鲁棒性条件**。同时，我们进一步探讨了该节点感知双平滑方案在实际中的两种应用：一是作为针对真实世界中图注入攻击的经验性防御手段，二是应用于推荐系统场景。此外，我们将两种当前最先进的可验证鲁棒性框架进行扩展，以应对节点注入攻击，并将其与我们的方法进行对比。\n\n大量实验评估验证了我们所提出鲁棒性证书的有效性。1"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Optimal Flexible Consensus and its Application to Ethereum.pdf": {
        "title": "Optimal Flexible Consensus and its Application to Ethereum",
        "abstract": "——经典拜占庭容错（BFT）共识协议在所有副本中少于三分之一发生故障时，能够保证所有客户端的安全性（safety）和活性（liveness）。然而，在一些高价值支付等应用场景中，某些客户端可能更倾向于优先保障安全性，而非活性。灵活共识（flexible consensus）允许每个客户端自行选择更高的安全性容错能力，即使这意味着牺牲部分活性容错能力。我们首次提出了一种构造方案，能够**同时为每个客户端实现最优的安全性与活性之间的权衡**。该方案采用模块化设计，可作为附加组件叠加在现有的共识协议之上运行。\n\n这一附加组件通过在副本上增加一轮投票和永久锁定机制，绕过了先前解决方案中基于法定交集（quorum intersection）所导致的次优约束。我们将该构造适配到现有的以太坊协议中，推导出**最优的灵活确认规则**，客户端可单方面采用这些规则，而无需对整个系统进行协议层面的变更。之所以可行，是因为以太坊现有协议中的某些功能，恰好可兼作我们所需的额外投票与锁定机制。我们还展示了基于以太坊共识API的具体实现。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Jbeil：Temporal Graph-Based Inductive Learning to Infer Lateral Movement in Evolving Enterprise Networks.pdf": {
        "title": "Jbeil：Temporal Graph-Based Inductive Learning to Infer Lateral Movement in Evolving Enterprise Networks",
        "abstract": "——横向移动（Lateral Movement, LM）是高级持续性威胁（APT）的核心阶段之一，持续对大型企业网络的安全态势构成威胁。近期研究采用图神经网络（GNN）技术来检测复杂网络中的横向移动行为。然而，这些方法依赖于**直推式图学习**（transductive graph learning），即在训练阶段使用具有完整节点可见性的静态图，并仅输入正常（良性）数据。这种设定在现实场景中面临三大问题：\n\n（i）它忽略了企业网络的动态本质——主机、用户、虚拟化环境和应用之间的连接关系和特征始终处于不断变化之中；  \n（ii）仅基于正常数据进行训练，难以有效识别现代恶意行为所表现出的**隐蔽性强、行为类似良性活动**的横向移动攻击，导致检测能力受限；  \n（iii）复杂网络通常无法获得其运行时网络进程的完整视图，即便拥有部分可见性，也因被动数据分析带来的延迟问题，难以实时动态追踪横向移动行为。\n\n为此，本文提出 **Jbeil**——一个面向时序演化网络的**自监督深度学习数据驱动框架**，将网络表示为一系列带时间戳的认证事件序列。该方法的核心思想是：  \n- 使用一个**编码器**对连续时间演化的图进行处理，为每个时间步生成当前可见图节点的嵌入表示；  \n- 再通过一个**解码器**，利用这些嵌入来预测未在训练阶段出现的节点之间的横向移动连接（即链路预测），实现对未知威胁的推断。\n\n此外，Jbeil 还内置了**威胁样本增强机制**，以增强模型对高级横向移动攻击的认知能力，提升检测的鲁棒性和泛化性。\n\n我们在来自**洛斯阿拉莫斯国家实验室网络**的带时间戳认证日志数据上对 Jbeil 进行了评估。实验结果显示：即使在训练阶段缺失 30% 的节点和边的情况下，Jbeil 仍能实现 **99.73% 的 AUC 值**和 **99.25% 的召回率（Recall）**，准确预测横向移动路径。同时，我们还测试了多种现实攻击场景，结果表明：Jbeil 在其**归纳式**（inductive）和**直推式**（transductive）设置下，预测横向移动路径的 AUC 均达到 **99%**，显著优于现有最先进方法。\n\n**关键词**：横向移动（Lateral Movement）、时序图神经网络（Temporal Graph Neural Networks）、认证日志（Authentication Logs）、动态演化企业网络（Evolving Enterprise Networks）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SwiftRange：A Short and Efficient Zero-Knowledge Range Argument For Confidential Transactions and More.pdf": {
        "title": "SwiftRange：A Short and Efficient Zero-Knowledge Range Argument For Confidential Transactions and More",
        "abstract": "——零知识范围证明在区块链系统的机密交易（Confidential Transactions, CT）中扮演着至关重要的角色。它们用于证明承诺的交易支付金额是非负的，而无需泄露其具体数值。近年来，具有对数级大小和透明设置（transparent setup）的范围证明（如 Bulletproofs）日益流行，尤其适用于对通信效率要求较高的区块链系统。这类证明旨在验证一个承诺值落在区间 $[0, 2^N - 1]$ 内，其中 $N$ 是范围的二进制位宽。由于其对数级的大小，它们显著提升了系统的可扩展性，使每个区块能容纳更多交易。\n\n在本文中，我们提出了 **SwiftRange**，一种新型的对数大小、透明设置、基于离散对数假设的零知识范围论证（range argument）。我们的方案可以直接作为区块链机密交易中现有范围证明的“即插即用”式替代方案。与 Bulletproofs 相比，SwiftRange 在 $N \\in \\{32, 64\\}$ 这类对机密交易友好的范围内，具有更高的计算效率、更低的交互轮次复杂度，同时通信开销相近。具体而言，在两种位宽下，单个 SwiftRange 证明的生成效率分别达到 Bulletproofs 的 **1.73 倍**和 **1.37 倍**，而通信开销不超过其 **1.1 倍**。更重要的是，我们的方案在验证效率上实现了“双重高效”（doubly efficient），即验证速度显著提升。\n\n此外，当 $N \\leq 16$ 时，SwiftRange 的证明尺寸更小，使其在许多其他对通信敏感的应用中也具备竞争力。我们的方案还支持将多个独立证明进行聚合（aggregation），从而在通信和验证方面进一步提升整体效率。最后，我们通过实验对 SwiftRange 与当前最先进的范围证明方案进行了性能基准测试，充分验证了其实际可行性与优越性。\n\n**关键词**：零知识范围论证、离散对数、对数大小、透明设置、机密交易、区块链"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Backdooring Multimodal Learning.pdf": {
        "title": "Backdooring Multimodal Learning",
        "abstract": "——深度神经网络（DNNs）容易受到后门攻击（backdoor attacks）的影响，这类攻击通过污染训练数据集，使模型对带有特定触发器（trigger）的样本产生错误的预测。尽管现有研究主要集中在单模态场景下，但现代人工智能系统通常采用多模态（如视觉、文本、音频等）来提升模型性能，这使得多模态后门攻击更具现实可行性。然而，由于模态之间固有的交互性、多个攻击入口（attack surfaces）、各模态贡献不均衡等因素，多模态后门攻击在结构上更加复杂。这些因素显著影响多模态学习中的后门攻击效果，但尚未得到充分研究。\n\n为填补这一空白，我们首次提出了针对多模态学习的**数据与计算高效的后门攻击方法**。我们的解决方案包含两项创新：  \n第一，我们提出了一种新颖的**基于梯度的后门评分方法（BAGS, Backdoor Gradient-based Score）**，该方法能够在训练初期就准确量化每个训练样本对后门学习过程的贡献。因此，攻击者可以大幅节省时间与计算资源。  \n第二，我们引入了一种包含两种攻击模式的搜索策略，能够高效地确定最优的污染模态（即选择哪些模态注入后门）和污染样本。\n\n我们的方法带来了以下研究成果：  \n首先，我们在最先进的多模态任务、模型、数据集和实验设置上，对所提出的方案进行了全面评估，验证了其**有效性、高效性与可迁移性**。例如，在视觉问答（Visual Question Answering）任务中，我们仅需污染训练样本的**0.005%**，即可实现**超过96%的攻击成功率**；在视听语音识别（Audio Video Speech Recognition）任务中，仅需污染**0.05%**的样本，即可达到**超过93%的成功率**。\n\n其次，我们在实验中揭示了几项有趣的发现：  \n（1）**同时污染所有模态并不总是优于单独污染某一模态，有时甚至会降低攻击效果**；  \n（2）在多模态后门攻击中，**模态间的竞争与互补现象并存**；  \n（3）在多模态学习中占据主导地位（dominant）的模态，**未必在后门攻击中也占据主导地位**。\n\n我们希望本研究能推动未来对多模态学习安全性的深入研究。相关代码已开源：  \nhttps://github.com/multimodalbags/BAGS_Multimodal。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/PIRANA：Faster Multi-query PIR via Constant-weight Codes.pdf": {
        "title": "PIRANA：Faster Multi-query PIR via Constant-weight Codes",
        "abstract": "——私有信息检索（Private Information Retrieval, PIR）是一种密码学协议，能够支持广泛的隐私保护应用。尽管数十年来被广泛研究，但其效率仍不足以在实际中大规模应用。在本文中，我们提出了一种名为 **PIRANA** 的新型 PIR 协议，该协议基于近年来在恒定重量码（constant-weight codes）方面的进展。与最初提出的恒定重量码 PIR 协议（发表于 Usenix SEC ’22）相比，PIRANA 的性能最高可提升 **188.6 倍**。更重要的是，PIRANA 天然支持**多查询**（multi-query）功能：客户端可以以极小的额外开销从服务器检索一批数据元素，相较于单次检索一个元素，这种批量查询方式相比当前最先进的多查询 PIR 协议（发表于 Oakland ’23）实现了最高达 **14.4 倍**的性能提升。\n\n此外，我们还探讨了将 PIRANA 扩展至**带标签的私有集合交集**（Labeled Private Set Intersection, LPSI）的方法。与现有的 LPSI 协议相比，PIRANA 更适用于数据库频繁更新的应用场景，表现出更强的适应性和实用性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Non-Atomic Arbitrage in Decentralized Finance.pdf": {
        "title": "Non-Atomic Arbitrage in Decentralized Finance",
        "abstract": "以太坊生态系统中最大可提取价值（MEV）的普遍存在，使得该系统被形象地比喻为一片“黑暗森林”。截至目前，对MEV的研究主要集中在纯粹的链上MEV，例如三明治攻击（sandwich attacks）、循环套利（cyclic arbitrage）和清算（liquidations）。在本项研究中，我们重点揭示了以太坊区块链上去中心化交易所（DEX）中**非原子套利**（non-atomic arbitrage）的普遍性。值得注意的是，非原子套利不仅利用以太坊区块链上不同DEX之间的价格差异，还利用以太坊链下交易所（即中心化交易所，或其他区块链上的DEX）之间的价格差异。因此，非原子套利是一种涉及以太坊链上和链下操作的MEV类型。\n\n在我们的研究中，我们发现：自以太坊合并（The Merge）至2023年10月31日期间，以太坊五大主要DEX的交易量中，**超过四分之一**很可能可归因于这类非原子套利行为。我们进一步指出，仅有**11个“搜索者”**（searchers）就贡献了已识别非原子套利交易量的**80%以上**，其累计交易额高达惊人的**1320亿美元**。此外，我们还揭示了**区块构建市场中心化**与非原子套利之间存在的关联。\n\n最后，我们讨论了这些高价值交易所带来的安全性影响——它们已占以太坊**总区块价值**的**10%以上**，并提出了可能的缓解措施。\n\n---\n\n### 关键概念说明（辅助理解）：\n- **黑暗森林**：比喻以太坊生态中，交易一旦公开便可能被“捕食者”（如MEV机器人）迅速捕捉并剥削的残酷竞争环境。\n- **非原子套利**：指套利过程不保证原子性（即无法确保“全部成交或全部失败”），通常涉及跨链、跨交易所的复杂操作，需承担部分执行失败的风险。\n- **搜索者（Searchers）**：专门监听内存池（mempool）、寻找MEV机会并提交优化交易的用户或机器人。\n- **区块构建市场中心化**：当前以太坊中，少数实体（如Flashbots、Builders）主导了区块打包权，这可能导致MEV资源分配不均，加剧非原子套利的集中化趋势。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Don't Eject the Impostor：Fast Three-Party Computation With a Known Cheater.pdf": {
        "title": "Don't Eject the Impostor：Fast Three-Party Computation With a Known Cheater",
        "abstract": "安全多方计算（MPC）能够在保护隐私的前提下，对敏感数据进行联合计算。在实际应用场景中，最现实的往往是**非对称信任假设**：即一个相对可信的实体与多个小型客户端进行交互。为此，我们将此前适用于两方计算（2PC）的协议（如MUSE，USENIX Security 2021；SIMC，USENIX Security 2022）推广至**三方计算（3PC）环境**，其中允许存在一个恶意参与方，从而规避了2PC在“恶意多数”（dishonest-majority）场景下固有的性能瓶颈。\n\n我们提出了两种新的协议：**AUXILIATOR** 和 **SOCIUM**，其设计充分考虑了机器学习（ML）应用的需求，具备高效的**在线计算阶段**，并在**预处理（setup）阶段**引入了新颖的验证技术。这些协议填补了此前3PC方案中的空白——此前的研究通常只考虑完全半诚实（fully semi-honest）或完全恶意（fully malicious）的极端场景，而我们的协议则支持更细粒度的混合信任模型。\n\n- **AUXILIATOR** 在半诚实两方计算的基础上，引入了一个**恶意辅助方（malicious helper）**，显著提升了效率，通信开销至少降低两个数量级。\n- **SOCIUM** 则扩展了“客户端-恶意”（client-malicious）模型，支持一个恶意客户端和一个半诚实服务器，相较于SIMC协议，其通信开销也实现了至少一个数量级的显著优化。\n\n除了实现我们提出的新协议外，我们还首次提供了**开源实现**：\n- 半诚实3PC协议 **ASTRA**（CCSW’19）的完整开源实现；\n- 以及恶意3PC协议 **SWIFT**（USENIX Security’21）的一个变体版本。\n\n**关键词**：多方计算，客户端-恶意设置，三方计算（3PC），非对称信任，MPC"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Few-shot Unlearning.pdf": {
        "title": "Few-shot Unlearning",
        "abstract": "我们研究机器遗忘（machine unlearning）问题，旨在从已训练好的模型中消除用于训练但存在错误或敏感信息的目标数据集的影响。通常人们假设：需要遗忘或保留的每一个数据样本都能被完全识别，从而明确遗忘后模型应有的行为。然而，在实际应用中，这种完美的样本识别往往难以实现。我们提出一个更贴近现实但更具挑战性的场景，称为“少样本遗忘”（few-shot unlearning），即仅提供目标数据中的少量样本，同时仍需实现该目标数据集背后的原始意图（例如：纠正错误标签、抵御特定隐私攻击，或无需明确具体意图）。为此，我们设计了一种少样本遗忘方法，其中包括一种专为遗忘场景设计的新型模型反演技术，用于在必要时从已训练模型中重构出训练数据集的近似表示（即代理数据集）。实验表明，即使仅使用目标数据的一小部分，我们的方法仍能达到与那些能访问完整目标数据的先进方法相近的性能。相关代码和实验结果已开源：https://github.com/ml-postech/Few-shot-Unlearning。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Automated Synthesis of Effect Graph Policies for Microservice-Aware Stateful System Call Specialization.pdf": {
        "title": "Automated Synthesis of Effect Graph Policies for Microservice-Aware Stateful System Call Specialization",
        "abstract": "我们提出了一种混合程序分析框架，能够自动合成描述容器化程序允许行为的有状态系统调用策略。该框架以容器镜像作为输入，生成一个参考策略，该策略编码了一个安全自动机（security automaton），其通过在对容器镜像元数据和运行环境所提取的约束条件下，对容器对应的可执行入口点进行符号化微执行（symbolic micro-execution）而获得。\n\n我们通过为DARPA网络大挑战（CGC）语料库中的25个挑战程序、5个真实世界的容器化程序（包括广泛使用的NGINX Web服务器），以及来自公开基准测试的一个完整微服务应用合成安全策略，展示了本方法的有效性和实用性。在运行时策略监控器的保护下，我们分别在正常（良性）和攻击场景下运行每个程序或微服务。\n\n此外，我们通过将我们合成的策略与四种最先进的系统调用特化工具生成的策略进行对比，评估了本方法的有效性。实验结果表明，我们的技术能够扩展到大型程序，并能准确提取出用于安全监控的简洁参考应用模型。\n\n**关键词**：系统调用特化、微服务、云安全、基于语言的安全、二进制分析、安全监控。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Saturn：Host-Gadget Synergistic USB Driver Fuzzing.pdf": {
        "title": "Saturn：Host-Gadget Synergistic USB Driver Fuzzing",
        "abstract": "通用串行总线（USB）是现代操作系统中不可或缺的组成部分，它使各种外设能够便捷地连接到计算机。操作系统中的USB协议栈通常由以下两个关键组件构成：主机端驱动程序（host-side driver）和设备端小工具驱动程序（device-side gadget driver），二者均处于特权模式，对系统安全至关重要。一旦这些驱动程序中的漏洞被利用，恶意或异常构造的USB设备便可能导致整个系统崩溃。模糊测试（Fuzzing）是一种广泛应用的自动化漏洞检测技术，已被用于测试包括驱动程序在内的内核组件，并取得了不同程度的成果。\n\n然而，现有研究大多仅聚焦于USB通信的一侧（主机端或设备端），通过模拟来自用户空间或外设的恶意输入来测试驱动，却忽略了只有在主机端与设备端交互时才会触发的复杂内部状态。这种片面的测试方式导致大量潜藏在内核交互逻辑中的漏洞未被发现。\n\n本文提出了一种名为 **SATURN** 的主机-小工具协同式USB驱动模糊测试方法，旨在覆盖USB通信全链路的完整处理流程。为实现这一目标，SATURN首先利用提取的驱动程序信息，系统性地挂载小工具（gadget）设备，以触发更多类型的驱动行为，促进向交互逻辑的过渡。随后，SATURN通过在主机端和设备端同时进行规范操作注入，实现一种持续的协同模糊测试过程，使两端各自发挥关键作用，显著扩展了被探索的状态空间，并有效暴露了交互逻辑中的缺陷。\n\n与现有最先进的USB模糊测试工具（如 Syzkaller、USBFuzz 和 FUZZUSB）相比，SATURN 在对应USB协议栈上的分支覆盖率分别提升了 **1.53倍、3.69倍 和 2.3倍**。此外，SATURN 发现了26个此前未知的漏洞，其中包括4个已分配CVE编号的严重漏洞，这些漏洞涉及主机端和设备端的驱动程序，充分验证了该方法在全面检测USB驱动漏洞方面的有效性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Distribution Preserving Backdoor Attack in Self-supervised Learning.pdf": {
        "title": "Distribution Preserving Backdoor Attack in Self-supervised Learning",
        "abstract": "自监督学习被广泛应用于多个领域，用于构建基础模型，已在多种任务中展现出最先进的性能。在计算机视觉领域，自监督学习被用于生成一种称为“编码器”的图像特征提取器，使得各种下游任务仅需少量数据和资源，即可在其基础上构建分类器。尽管自监督学习表现优异，但它容易受到后门攻击的威胁：攻击者可以向其无标签训练数据中注入后门。基于被植入后门的编码器构建的下游分类器，一旦输入中包含特定触发器（trigger），就会将样本错误分类至目标标签。\n\n现有的自监督学习后门攻击具有一种关键的“分布外”（out-of-distribution）特性：被投毒样本在特征空间中与干净数据存在显著差异。此外，被投毒数据的分布高度集中，导致被投毒样本之间具有极高的成对相似性。正因如此，这些攻击可以被当前最先进的防御技术检测出来。\n\n为此，我们提出一种新型**分布保持型攻击**（distribution-preserving attack），通过减小被投毒样本与干净数据之间的分布距离，将其转化为“分布内”（in-distribution）数据。同时，我们将被投毒数据散布到目标类别分布的更广区域内，缓解其分布过度集中的问题。\n\n我们在五个主流数据集上的评估表明，与现有攻击相比，我们的攻击方法 D RUPE 显著降低了被投毒分布的分布距离和集中程度。D RUPE 成功绕过了两种当前最先进的自监督学习后门防御机制，并且即使在面对具备充分知识的防御者时，也表现出很强的鲁棒性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/R-CAID：Embedding Root Cause Analysis within Provenance-based Intrusion Detection.pdf": {
        "title": "R-CAID：Embedding Root Cause Analysis within Provenance-based Intrusion Detection",
        "abstract": "在现代企业安全体系中，终端检测产品会在进程活动与已知攻击行为模式匹配时触发告警。随后，人工分析人员需基于事件日志进行根因分析（Root Cause Analysis, RCA），以判断该告警是否确实代表了一次真实攻击。数据溯源（Data Provenance）技术有助于自动化RCA过程，其方法是将事件日志表示为因果依赖图；事实上，已有研究人员开始探讨：是否应完全用基于溯源的异常检测取代传统的基于模式的检测。然而，我们注意到，当前的方法大多依赖现成的图嵌入技术，这些技术无法将事件与其根本原因建立关联。这一缺陷不仅未能充分发挥溯源技术在根因分析方面的潜力，还使基于溯源的入侵检测系统（IDS）容易受到模仿攻击（mimicry）和规避攻击（evasion）的威胁。\n\n本文提出了一种新颖的方法——R-CAID，旨在将根因分析能力有效融入基于溯源的入侵检测系统中。R-CAID在构建因果图的过程中，预先计算每个节点的根因，并在后续的图嵌入阶段直接将这些节点与其根因建立连接。此外，R-CAID的分类模型采用节点/进程级别（node/process-level）的粒度，而非图/系统级别（graph/system-level），使其在检测精度上更贴近商业系统的实际表现。在被动攻击者模型下，R-CAID在性能上始终优于基线图神经网络、基于序列的日志IDS，甚至超过某商业终端检测系统。在面对白盒主动攻击者模型时，R-CAID仍能保持较高的检测性能（例如在DARPA Theia数据集上，被动场景下AUC为0.99，主动对抗场景下仍达0.94）。R-CAID之所以具备这种鲁棒性，是因为它将每个系统实体与其不可变且不可伪造的根因相关联，从而阻止攻击者伪装成合法进程。\n\n因此，本研究首次以实际可行的方式展示了基于溯源的入侵检测系统的潜力，并成功规避了模仿与规避攻击所带来的陷阱。\n\n**关键词**：入侵检测"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/DeepTheft：Stealing DNN Model Architectures through Power Side Channel.pdf": {
        "title": "DeepTheft：Stealing DNN Model Architectures through Power Side Channel",
        "abstract": "深度神经网络（DNN）模型通常以“机器学习即服务”（MLaaS）的形式部署在资源共享的云环境中，以提供推理服务。为窃取具有重大知识产权价值的模型架构，已有研究通过不同的侧信道泄露提出了一系列攻击方法，这给MLaaS带来了严峻的安全挑战。\n\n针对MLaaS，我们提出了一种新型端到端攻击方法——DeepTheft，该方法通过基于RAPL（运行平均功率限制）的功耗侧信道，在通用处理器上精确还原复杂的DNN模型架构。尽管在裸机操作系统（bare-metal OS）中，非特权用户已被禁止访问RAPL，但我们发现，在平台即服务（PaaS）环境中，例如本研究中使用的Docker 20.10.18最新版本，RAPL仍可被合法访问。然而，攻击者仅能从RAPL接口获取较低采样率（1 kHz）的时间序列能量轨迹，这使得现有技术难以有效窃取大型且深层的DNN模型。\n\n为此，我们设计了一种新颖且通用的基于学习的框架，该框架由一组元模型（meta-models）组成。基于此框架，DeepTheft在恢复不同模型家族的数千种模型架构（包括最深的ResNet152）时表现出极高的准确率。具体而言，DeepTheft在还原网络结构方面实现了99.75%的**编辑距离准确率**（Levenshtein Distance Accuracy），在还原各层多样化超参数方面达到了99.60%的**加权平均F1分数**。\n\n此外，我们提出的学习框架具有良好的通用性，可适用于其他时间序列侧信道信号。为验证其泛化能力，我们进一步利用了另一种现有侧信道——**CPU频率**。与RAPL不同，CPU频率在裸机操作系统中可被非特权用户访问。通过使用我们的通用学习框架，并基于CPU频率轨迹进行训练，DeepTheft在窃取模型架构方面同样表现出极高的攻击成功率。\n\n---\n\n**总结亮点：**  \n- DeepTheft是首个利用RAPL低采样率功耗侧信道实现高精度模型架构窃取的攻击方法。  \n- 提出通用元模型学习框架，显著提升对大规模、深层DNN架构的恢复能力。  \n- 框架可迁移至其他侧信道（如CPU频率），在更广泛的系统环境下保持高效攻击性能。  \n- 实验验证了其在真实云环境（如Docker）中的可行性与高准确性，对MLaaS平台构成实质性威胁。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/From Virtual Touch to Tesla Command：Unlocking Unauthenticated Control Chains From Smart Glasses for Vehicle Takeover.pdf": {
        "title": "From Virtual Touch to Tesla Command：Unlocking Unauthenticated Control Chains From Smart Glasses for Vehicle Takeover",
        "abstract": "本文研究了可穿戴设备与自动化控制系统交叉领域中的安全漏洞。我们特别聚焦于以智能眼镜作为攻击入口点，揭示了无需用户验证或交互即可接管关键安全自动化控制链的潜在威胁。这类漏洞在以下场景中尤为突出：安全机制仅依赖于入口点的安全性，而用户验证环节极为薄弱（即自动化控制链中后续节点完全信任前序节点）。我们在真实世界系统中验证了攻击的实际效果，例如通过Apple Shortcuts或IFTTT等软件与自动化工具控制的Tesla电动汽车。研究展示了我们提出的非接触式、与扬声器无关、基于电磁干扰的攻击方式，即使在受害者手机处于锁屏状态时，仍可成功控制诸如车门解锁、远程启动车辆等功能。这些发现不仅揭示了未经授权操控自动化互联系统的可能性，更凸显出在将可穿戴技术集成至更广泛自动化框架时，亟需采用更强健的安全防护措施的紧迫性。\n\n（译文说明：在保持学术严谨性的基础上，采用符合中文表达习惯的句式重构，突出以下要点：\n1. 将\"entry point\"译为\"入口点\"并补充\"攻击\"以明确技术语境\n2. \"lock-screen status\"具体化为\"锁屏状态\"增强可读性\n3. 使用\"非接触式、与扬声器无关、基于电磁干扰\"的并列结构准确传达技术特征\n4. 通过\"即\"、\"例如\"等连接词提升逻辑连贯性\n5. 末句采用\"不仅...更...\"句式强化递进关系，符合中文论述习惯）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/MQTTactic：Security Analysis and Verification for Logic Flaws in MQTT Implementations.pdf": {
        "title": "MQTTactic：Security Analysis and Verification for Logic Flaws in MQTT Implementations",
        "abstract": "物联网（IoT）消息协议对于连接用户与物联网设备至关重要。在众多协议中，消息队列遥测传输协议（MQTT）可以说是应用最广泛的一种。主流物联网平台普遍采用MQTT代理（MQTT broker）——即MQTT在服务器端的实现——来实现并中介用户与设备之间的通信（例如控制命令的传输）。目前已有超过70种开源的MQTT代理，并在实际生产环境中得到广泛部署。这些开源MQTT代理中一旦存在安全缺陷，极易被大量厂商引入其物联网系统部署中，从而造成影响被放大的安全风险，不可避免地危及整个物联网应用及数百万用户的安全。\n\n我们首次对实际环境中广泛使用的开源MQTT代理进行了系统性安全分析。为实现这一目标，我们设计并开发了MQTTactic——一种半自动化工具，能够基于生成的安全属性，对MQTT代理的实现进行形式化验证。MQTTactic融合了静态代码分析、形式化建模以及自动化模型检测（使用现成的模型检测工具Spin）技术。在设计MQTTactic的过程中，我们识别并解决了若干关键技术挑战。目前，MQTTactic主要聚焦于与授权相关的安全属性，已实际发现了7个新颖的、零日（zero-day）级别的逻辑漏洞，这些漏洞可被利用实现严重的未授权访问。我们已向相关责任方报告了所有漏洞，各方均已确认问题，并正在积极采取措施进行修复。\n\n全面评估结果表明，MQTTactic在发现安全漏洞方面具有高效性和实用性。\n\n关键词：物联网安全；MQTT；逻辑漏洞"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Undefined-oriented Programming：Detecting and Chaining Prototype Pollution Gadgets in Node.js Template Engines for Malicious Consequences.pdf": {
        "title": "Undefined-oriented Programming：Detecting and Chaining Prototype Pollution Gadgets in Node.js Template Engines for Malicious Consequences",
        "abstract": "——原型污染（Prototype Pollution）是一种近年来被发现、影响重大的 JavaScript 代码漏洞。关于原型污染，一个重要且富有挑战性的研究问题是：如何影响目标程序的逻辑，更确切地说，是控制流或数据流，从而实现攻击者的恶意目的，例如任意代码执行（Arbitrary Code Execution, ACE）和文件访问篡改（File Access Manipulation）。此前的研究主要关注“小工具”（gadgets）的检测，这些小工具能够将受污染的原型属性传递到与代码执行相关的“汇聚点”（sink）。尽管现有的小工具已成功实现恶意攻击目标，但它们属于“直接型小工具”，即受污染属性直接从源头流向汇聚点，过程中不受其他受污染属性的影响。\n\n然而，随着越来越多的小工具被修复，且某些库中已缺乏直接型小工具，因此对更复杂的小工具（即间接、可组合的小工具）的需求日益凸显。\n\n在本文中，我们设计并实现了首个名为“未定义导向编程框架”（Undefined-oriented Programming Framework, UOPF）的自动化框架，用于通过**具体与符号混合执行**（concolic execution）技术，以“未定义属性”作为符号变量，检测并串联能够通向汇聚点的小工具。我们称之为“未定义导向编程”，是因为一个污染操作可能通过污染原本未定义的属性，改变另一个小工具的控制流或数据流，从而实现小工具之间的联动与组合。UOPF 能够同时生成原型污染输入和普通程序输入，引导混合执行引擎探索程序路径，最终抵达汇聚点。\n\n我们在 Node.js 模板引擎上对 UOPF 进行了评估，结果表明：UOPF 成功检测出 25 个现有工具无法发现的零日（zero-day）小工具，其中 13 个为可串联的链式小工具。我们已负责任地向相关开发者报告了这些漏洞，其中已有 5 个小工具被修复。此外，我们将 UOPF 与当前最先进的工具 Silent Spring 进行了对比，评估结果显示，UOPF 在误报率和漏报率方面均显著优于 Silent Spring。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/To Auth or Not To Auth. A Comparative Analysis of the Pre- and Post-Login Security Landscape.pdf": {
        "title": "To Auth or Not To Auth. A Comparative Analysis of the Pre- and Post-Login Security Landscape",
        "abstract": "——互联网已从最初用于提供静态内容的方式，演变为一个功能完备的应用程序平台。鉴于其在我们日常生活中的广泛存在，因此亟需开展能够准确反映当前网络真实安全状况的研究。许多研究工作集中于漏洞检测、衡量安全响应头的部署情况，或识别通往更安全网络道路上的障碍。为了大规模开展此类研究，这些工作都有一个共同点：它们都以自动化方式运行，无需人工干预，即在不登录（未认证）的状态下访问网站。\n\n为了判断这种未认证视角下的网络是否真实反映了普通用户实际体验到的安全状况，我们对200个网站进行了对比分析。我们采用一种半自动化的框架，实现登录应用程序并对其进行爬取，从而比较未认证（未登录）与认证（已登录）状态下在以下几方面的差异：客户端XSS漏洞、安全响应头的使用、postMessage处理程序以及JavaScript的引入情况。通过这项分析，我们发现，未认证视角下的网络可能会根据研究问题的不同，呈现出显著偏离真实情况的网络安全图景。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Baffle：Hiding Backdoors in Offline Reinforcement Learning Datasets.pdf": {
        "title": "Baffle：Hiding Backdoors in Offline Reinforcement Learning Datasets",
        "abstract": "——强化学习（RL）使智能体通过与环境的交互，从试错经验中学习。近年来，离线强化学习（Offline RL）已成为一种流行的强化学习范式，因为它减少了对环境交互的依赖。在离线强化学习中，数据提供者共享大量预先收集好的数据集，其他人无需与环境交互即可训练出高质量的智能体。这种范式在机器人控制、自动驾驶等关键任务中已展现出显著的有效性。然而，目前对离线强化学习系统的安全威胁研究较少。本文聚焦于**后门攻击**（backdoor attacks）：通过在数据（即观测值）中注入特定扰动，使得智能体在面对正常观测时采取高奖励动作，而在带有触发器（trigger）的观测下却执行低奖励动作。\n\n本文提出了一种名为 **BAFFLE**（Backdoor Attack for Offline Reinforcement Learning，面向离线强化学习的后门攻击）的方法，该方法通过污染离线强化学习数据集，自动向智能体植入后门，并评估不同离线强化学习算法对这种攻击的响应。我们在四项任务（三项机器人控制任务和一项自动驾驶任务）上，针对九种主流离线强化学习算法进行了实验，结果揭示了一个令人担忧的事实：**现有的所有离线强化学习算法均未能幸免于这种后门攻击**。\n\n具体而言，BAFFLE 在四类任务中仅修改了原始数据集的10%（包括3个机器人控制任务和1个自动驾驶任务）。在正常环境下，使用被污染数据集训练的智能体表现良好；然而，当输入中包含触发器时，智能体在这四项任务上的性能平均分别下降了63.2%、53.9%、64.7%和47.4%。更严重的是，即使将受过污染训练的“中毒”智能体在干净数据集上进行微调，后门依然持续存在。\n\n我们进一步证明，这种植入的后门也难以被当前一种主流防御方法所检测。本文呼吁学术界和产业界关注开源离线强化学习数据集的安全性问题，亟需开发更有效的防护机制，以保障离线强化学习系统的可靠性与安全性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Pandora：Principled Symbolic Validation of Intel SGX Enclave Runtimes.pdf": {
        "title": "Pandora：Principled Symbolic Validation of Intel SGX Enclave Runtimes",
        "abstract": "近年来，英特尔SGX（Software Guard Extensions）技术的广泛应用催生了一系列“屏蔽运行时”（shielding runtimes），旨在透明地保护安全飞地（secure enclave）应用程序，使其免受恶意操作系统的攻击。然而，对这些关键且数量众多的屏蔽运行时进行充分验证，却是一项复杂且快速演变的挑战——因为针对SGX飞地的新型攻击技术不断被发现，通常要求在整个SGX生态系统中进行大规模的软件补丁更新。\n\n本文提出了Pandora，一种实用的、具备飞地感知能力的符号执行工具，专门用于应对这一挑战。与现有工具不同，Pandora首次实现了对经过认证的飞地二进制文件进行**忠实且与运行时无关的符号执行**，从而能够直接验证关键的飞地屏蔽运行时本身是否安全。此外，Pandora通过引入以下机制，为应对飞地软件安全“目标不断移动”的特性提供了系统性的理论基础：  \n- 对攻击者输入进行**精确的污点追踪**（taint tracking）；  \n- 构建**精细的符号化飞地内存模型**；  \n- 支持**可插拔的漏洞检测器**（pluggable vulnerability detectors）。\n\n我们使用4种针对不同漏洞类型的检测插件，对11种不同的SGX屏蔽运行时对Pandora进行了全面评估。实验结果表明，Pandora能够自动发现**200个新的**以及**69个已知的存在漏洞的代码位置**。尤其值得注意的是，Pandora是首个能够大规模、系统性评估现实世界中SGX飞地运行时所采用的**指针对齐类软件缓解措施**（pointer-alignment mitigations）效果的工具，为SGX生态系统的安全分析提供了前所未有的深度与广度。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/FLShield：A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks.pdf": {
        "title": "FLShield：A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks",
        "abstract": "联邦学习（Federated Learning, FL）正在彻底改变我们从数据中学习的方式。随着其日益普及，FL 已被广泛应用于许多对安全性要求极高的领域，例如自动驾驶汽车和医疗健康。然而，在这种协作式学习环境中，成千上万的参与方可能共同参与，如何确保系统的安全性和可靠性成为一个巨大挑战。因此，亟需设计出既能抵御恶意参与方攻击、又能在保障本地数据高实用性、隐私性和系统效率的前提下运行的FL系统。\n\n在本文中，我们提出了一种名为 **FLShield** 的新型联邦学习框架。该框架利用来自FL参与方的良性数据，在将这些本地模型纳入全局模型生成过程之前，先对其进行验证。这与现有防御方法形成鲜明对比——现有方法通常假设服务器可以访问干净的数据集，而这种假设在实际场景中往往不切实际，且与联邦学习“数据不出本地”的核心理念相冲突。\n\n我们进行了大量实验，在不同设置下评估了FLShield框架的性能，结果表明，该框架能够有效抵御多种类型的攻击，包括数据投毒攻击、后门攻击，甚至包括攻击者已意识到防御机制存在的情况（即“防御感知型”攻击）。此外，FLShield还能有效防止梯度反演攻击，从而保护本地数据的隐私性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Towards Smart Contract Fuzzing on GPUs.pdf": {
        "title": "Towards Smart Contract Fuzzing on GPUs",
        "abstract": "模糊测试（Fuzzing）是发现智能合约漏洞的主要技术之一。其有效性在很大程度上取决于测试的吞吐量，但不幸的是，现有的智能合约模糊测试工具由于以下原因而吞吐量较低：EVM（以太坊虚拟机）执行速度缓慢、共识机制引入的延迟、CPU并行处理能力有限，以及经过插桩（instrumented）的EVM带来的额外开销。为了解决这一关键问题，本文首次尝试利用GPU的并行计算能力来显著提升智能合约模糊测试的吞吐量。\n\n具体而言，我们将模糊测试的工作负载转换为单指令多数据（SIMD）任务，从而能够同时激活GPU上的数千个核心来并行测试智能合约。为实现这一目标，我们设计了新的解决方案，以应对三大主要挑战：  \n1）开发增量式存储机制，以降低GPU的内存开销；  \n2）提出一种“有状态位图”（stateful bitmap），将交易依赖关系嵌入到反馈指标中；  \n3）设计并行反馈算法，以排除导致冗余重叠的无效种子。\n\n我们实现了一个名为**MAU**的原型系统：首先将智能合约的字节码转换为PTX汇编形式的SIMD应用程序，然后在GPU上并行运行。我们使用大规模和小规模的测试基准对MAU进行了评估。实验结果表明，MAU的吞吐量分别达到每秒162,370次执行（162.37K execs/sec）和每秒328,060次执行（328.06K execs/sec），相比现有最先进的工具，性能提升了**8.69至15.38倍**。\n\n更重要的是，如此高的吞吐量使MAU能够比基线工具检测到**1.01至2.50倍**更多的漏洞，并获得**1.03至4.71倍**更高的代码覆盖率。这表明，利用GPU并行能力不仅提升了模糊测试的效率，还显著增强了在有限时间内发现更多深层漏洞的能力，为智能合约的安全分析提供了强有力的技术支持。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Specular：Towards Secure, Trust-minimized Optimistic Blockchain Execution.pdf": {
        "title": "Specular：Towards Secure, Trust-minimized Optimistic Blockchain Execution",
        "abstract": "乐观卷叠（Optimistic Rollup, ORU）通过将计算任务委托给一个不受信任的远程链（即 L2 层），并借助一种交互式争议解决协议，来处理互不信任的 L2 运营者之间对状态声明的分歧，从而提升区块链的吞吐量。当前最先进的乐观卷叠系统采用一种**单一的争议解决协议**，该协议将 L1 层的仲裁者（referee）与特定的 L2 客户端二进制程序**紧密耦合**，却完全忽略了系统更高层次的语义信息。\n\n我们认为，这种做法存在以下三大问题：\n\n1. **加剧了单一技术栈（monoculture）的失败风险**：由于系统强制使用运营者所选的特定客户端软件，排除了基于信任最小化和无需许可参与的替代客户端，导致整个系统依赖于单一实现，一旦该实现出现漏洞，整个生态将面临系统性风险；\n2. **导致信任计算基（TCB, Trusted Computing Base）过大且难以审计**：由于争议逻辑与特定客户端实现深度绑定，TCB 不仅包含共识逻辑，还不得不包含大量客户端专有代码，使得安全审查变得复杂且低效；\n3. **频繁触发且过程不透明的升级机制**：争议解决逻辑与客户端耦合，导致任何客户端变更都可能迫使整个争议系统进行升级，这不仅增加了审计负担，还扩大了治理层面的攻击面（如恶意升级、权限滥用等）。\n\n为解决上述问题，我们提出了一种设计**安全、健壮且信任计算基最小化**的乐观卷叠的方法，其核心是支持**机会主义的 N 版本编程（1-of-N-version programming）** —— 即允许多个独立实现（客户端）在无需信任的前提下参与系统运行，只要其中至少一个正确执行，系统即可保持安全。\n\n由于该领域存在独特的技术挑战与机遇，我们将研究具体落地于**以太坊生态系统**—— 当前乐观卷叠技术在此已获得广泛采纳。具体而言，我们设计了一套**具有语义感知能力的证明系统**，原生支持以太坊虚拟机（EVM）及其指令集，能够理解 EVM 执行的语义，而非仅验证底层字节码。\n\n我们在一款名为 **Specular** 的新型乐观卷叠中实现了这一方案：该系统通过**极小规模的源码修改**，机会主义地利用以太坊现有的**客户端多样性**（如 Geth、Erigon、Nethermind 等），无需强制统一客户端实现，即可实现去中心化、抗故障的争议验证。\n\n本工作通过 Specular 的实现，验证了上述方法的可行性：在保持安全性和去中心化的同时，显著缩小了 TCB，降低了审计难度，并增强了系统对客户端实现故障和治理攻击的抵御能力。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/On (the Lack of) Code Confidentiality in Trusted Execution Environments.pdf": {
        "title": "On (the Lack of) Code Confidentiality in Trusted Execution Environments",
        "abstract": "可信执行环境（Trusted Execution Environments, TEEs）被提出作为一种解决方案，用于在将计算任务外包给不可信操作者时，保护代码的机密性。我们研究了此类方案在两种常见部署场景下对侧信道攻击的抵抗能力：一是机密代码作为原生二进制文件被分发并在TEE内部执行；二是机密代码以中间表示（Intermediate Representation, IR）的形式，在运行于TEE之上的运行时环境中执行。\n\n我们发现，在TEE内部运行如WASM字节码这类IR代码时，运行时会以较高精度泄露大部分IR指令，从而暴露了机密代码。与之相反，原生代码执行对信息泄露的敏感度要低得多，甚至能够抵御最强大的侧信道攻击。我们在Intel SGX和AMD SEV平台上评估了原生代码执行的泄露情况，并通过实验在Intel SGX上实现了端到端的指令提取：实验中以WASM字节码作为IR，在两种主流的WASM运行时环境——WAMR和wasmi中运行。实验结果表明，从这类系统中提取IR代码是实际可行且高效的，这直接质疑了多个依赖“TEE+WASM”架构来保障代码机密性的商业方案所宣称的安全性。\n\n（第1部分）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/DY Fuzzing：Formal Dolev-Yao Models Meet Cryptographic Protocol Fuzz Testing.pdf": {
        "title": "DY Fuzzing：Formal Dolev-Yao Models Meet Cryptographic Protocol Fuzz Testing",
        "abstract": "— 关键且广泛使用的密码协议，其设计和实现中屡次被发现存在缺陷。其中一类尤为突出的漏洞是逻辑攻击，即利用协议逻辑错误实施的攻击。基于Dolev-Yao（DY）攻击模型的自动化形式化验证方法，能够形式化地定义并高效地发现此类逻辑缺陷，但这些方法仅作用于抽象的协议规范模型。目前，对现有协议实现进行完全自动化的验证仍然难以实现，这使得我们无法确定这些实际实现是否真正安全。不幸的是，这一盲区隐藏着大量攻击，例如近期因实现缺陷而出现的针对主流TLS实现的逻辑攻击。\n\n为应对这一问题，我们提出一种新颖而有效的技术，称为**DY模型引导的模糊测试（DY model-guided fuzzing）**，该技术能够防范针对协议实现的逻辑攻击。其核心思想是：将Dolev-Yao攻击者可能执行的所有抽象攻击路径作为候选测试用例集合，并利用一种新型的基于变异的模糊测试器（mutation-based fuzzer）来探索该集合。DY模糊测试器将每一条抽象执行实例化为具体的输入，用于在实际待测程序上运行测试。\n\n该方法使得测试能够在更结构化和与安全相关的层次上对消息进行操作——例如，将消息解密后再用不同的密钥重新加密——这与传统的随机比特级修改相比，能够更有效地生成具有实际攻击意义的逻辑性对抗行为。我们实现了一个功能完整且模块化的DY协议模糊测试器，并通过在三个主流TLS实现上进行模糊测试验证了其有效性，最终发现了四个此前未知的安全漏洞。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/NFCEraser：A Security Threat of NFC Message Modification Caused by Quartz Crystal Oscillator.pdf": {
        "title": "NFCEraser：A Security Threat of NFC Message Modification Caused by Quartz Crystal Oscillator",
        "abstract": "——近场通信（NFC）已被广泛用于电子设备之间在极短距离内的快速数据交换。在本文中，我们揭示了一种NFC被动通信信道中的新型安全漏洞：传输中的数据可被实时篡改。这种由该漏洞引发的数据篡改安全威胁被称为**NFCEraser**。NFCEraser利用电磁干扰（EMI），向NFC设备晶体振荡器的电极注入干扰信号，并调节NFC通信信道中的载波信号幅度。通过操控电磁干扰信号的参数，NFCEraser能够任意翻转NFC对端设备发送的数据载荷中的比特位，可能导致严重的安全后果。\n\n为评估NFCEraser的威胁严重性，我们在NFC-A/B通信模式下对六种NFC模块进行了测试，并在多种数据长度下成功实施了读取操作。实验结果表明，NFCEraser能够以最高达89%的准确率篡改NFC对端设备响应帧中的数据比特，且延迟约为0.21微秒。进一步分析表明，在具有典型电磁噪声水平的环境中，NFCEraser仍能保持不低于85%的攻击成功率。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Specious Sites：Tracking the Spread and Sway of Spurious News Stories at Scale.pdf": {
        "title": "Specious Sites：Tracking the Spread and Sway of Spurious News Stories at Scale",
        "abstract": "——错误信息、宣传内容乃至彻头彻尾的谎言在网络上肆意传播，某些叙事甚至对公众健康、选举公正和个人安全造成了危险的现实后果。然而，尽管虚假信息影响深远，研究界至今仍普遍缺乏自动化、程序化的方法来跨平台追踪网络新闻叙事。在本研究中，我们利用每日抓取的1,334个不可靠新闻网站的数据，结合大型语言模型MPNet和DP-Means聚类算法，开发了一套能够自动识别并追踪在线生态系统中传播叙事内容的系统。通过对这1,334个网站进行分析，我们共识别出52,036个叙事，总结了2022年传播最广泛的主要叙事，并找出了在叙事起源与传播过程中最具影响力的网站。此外，我们还展示了该系统如何被用于检测源自不可靠新闻网站的新兴叙事，从而帮助事实核查人员更迅速地应对虚假信息。我们已将相关代码和数据公开，发布地址为：https://github.com/hanshanley/specious-sites。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/The Dark Side of Scale：Insecurity of Direct-to-Cell Satellite Mega-Constellations.pdf": {
        "title": "The Dark Side of Scale：Insecurity of Direct-to-Cell Satellite Mega-Constellations",
        "abstract": "——新兴的面向终端直连的低地球轨道（LEO）卫星巨型星座，有望让我们的普通手机和物联网设备无需地面基站即可实现无处不在的LTE/5G接入。尽管其庞大的规模和高度移动性在一定程度上能够抵御多种攻击，但我们发现，这两个新特性本身也可能被利用，从而放大LTE/5G中固有的信令协议漏洞，并掩盖攻击行为，对卫星服务构成严重威胁。\n\n我们通过在“SatOver”这一控制平面跨层攻击中的实践展示了这一点：SatOver允许一个贪婪的地面运营商或中间人攻击者，在城市区域完全阻断所有面向终端直连的卫星通信。该攻击可复用现有的地面LTE/5G基站，或仅使用商用软件定义无线电（SDR）设备伪装成虚假卫星，悄无声息地劫持受害设备，延迟其连接卫星的时机，阻止其探测其他可用卫星，最终导致整个巨型星座服务被全面封锁。\n\n我们通过在真实卫星环境下的测试、使用商用3GPP NR/IoT-NTN协议栈的实验室测试，以及基于真实运行数据驱动的网络仿真，验证了SatOver对现有商用（COTS）及未来非地面网络（NTN）手机和物联网设备的攻击可行性。最后，我们还探讨了针对SatOver攻击所利用的“攻击放大”与“攻击隐蔽”机制的潜在防御对策。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/BadVFL：Backdoor Attacks in Vertical Federated Learning.pdf": {
        "title": "BadVFL：Backdoor Attacks in Vertical Federated Learning",
        "abstract": "联邦学习（Federated Learning, FL）允许多个参与方在不共享各自数据的前提下，协作训练一个机器学习模型。各参与方在本地训练自己的模型，并将模型更新上传至中央服务器进行聚合，而无需暴露原始数据。根据数据在不同参与方之间的分布方式，联邦学习可分为横向联邦学习（Horizontal FL, HFL）和纵向联邦学习（Vertical FL, VFL）。在纵向联邦学习（VFL）中，各参与方拥有相同的训练样本（即相同的实例集合），但仅掌握整体特征空间中互不重叠的不同子集。而在横向联邦学习（HFL）中，各参与方拥有相同的特征集合，但训练数据被划分为各自本地持有的样本子集。\n\nVFL正被越来越多地应用于金融欺诈检测等实际场景，然而，目前针对其安全性的研究却非常有限。本文聚焦于VFL中的鲁棒性问题，特别是后门攻击（backdoor attacks）——即攻击者试图在训练过程中操纵聚合模型，使其在特定触发条件下产生错误分类。与HFL相比，在VFL中实施后门攻击更具挑战性，原因在于：i）攻击者在训练过程中无法获取标签信息；ii）攻击者仅能访问特征嵌入（feature embeddings），因此无法直接修改标签。\n\n为此，我们提出了一种**在VFL中首个基于干净标签的后门攻击方法**（clean-label backdoor attack），该方法包含两个阶段：**标签推断阶段**和**后门注入阶段**。我们在三个不同的数据集上验证了该攻击的有效性，深入分析了影响攻击成功的关键因素，并进一步探讨了可行的防御对策，以减轻此类攻击带来的潜在危害。\n\n**关键词**——联邦学习，后门攻击，安全性"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/APP-Miner：Detecting API Misuses via Automatically Mining API Path Patterns.pdf": {
        "title": "APP-Miner：Detecting API Misuses via Automatically Mining API Path Patterns",
        "abstract": "—从源代码中提取API模式已被广泛用于检测API误用。然而，现有研究通常需要人工提供模式模板作为先决条件，这不仅要求具备先验的软件知识，还限制了模式提取的覆盖范围。本文提出了一种新颖的静态分析框架APPMiner（API路径模式挖掘器），它无需模式模板，即可通过频繁子图挖掘技术自动提取API路径模式。其核心洞察在于：API模式通常由与数据相关的API操作构成，并且在代码中频繁出现。因此，我们将API路径定义为由API数据相关操作组成的控制流图，进而这些API路径中的最大频繁子图即为潜在的API路径模式。我们实现了APPMiner，并在四个广泛使用的开源软件系统（Linux内核、OpenSSL、FFmpeg和Apache httpd）上进行了全面评估。结果分别从上述系统中发现了116、35、3和3个新的API误用，并据此获得了19个CVE（通用漏洞披露）编号。\n\n关键词 —API误用，规范推断，控制流图，频繁子图挖掘，静态分析  \n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Private Hierarchical Governance for Encrypted Messaging.pdf": {
        "title": "Private Hierarchical Governance for Encrypted Messaging",
        "abstract": "——仇恨、骚扰以及其他形式的网络滥用行为所造成的危害日益加剧，促使各大平台开始探索“层级化治理”（hierarchical governance）模式。其核心理念是：允许社区指定部分成员承担内容审核与领导职责，同时保留成员将问题上报至平台的权利。然而，目前这些富有前景的治理模式仅被应用于内容对平台可见的明文环境（plaintext settings）中。对于大量且日益增长的、为追求隐私而采用端到端加密（E2EE）通信的在线社区而言，如何在加密环境下实现层级化治理，仍是一个悬而未决的问题。\n\n为此，我们提出了“私有层级化治理系统”（private hierarchical governance systems）。这类系统应能在保障与明文环境同等水平的社区治理能力的同时，确保社区内容以及未向平台报告的治理行为（如投票、任命等）具备密码学级别的数据隐私性。\n\n我们设计了首个此类系统，采用分层架构，在加密通信协议之上叠加治理逻辑。我们证明，只需对消息层安全协议（Message Layer Security, MLS）进行适当扩展，即可支持丰富的治理策略。我们的方法使开发者能够快速原型化新的治理功能，其设计灵感源自一个名为 PolicyKit 的明文治理系统。基于此，我们构建了一个名为 MlsGov 的端到端加密消息系统原型，支持基于内容的社区与平台两级审核、社区管理员选举、投票驱逐滥用用户等多种治理机制。\n\n（第1节）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/DrSec：Flexible Distributed Representations for Efficient Endpoint Security.pdf": {
        "title": "DrSec：Flexible Distributed Representations for Efficient Endpoint Security",
        "abstract": "——随着攻击手段日益复杂，出现了各种旨在应对深层任务的安全应用，其功能涵盖告警分类（alert triage）到攻击行为重建等多个方面。然而，当前诸如端点检测与响应（EDR）等安全产品，往往将彼此独立开发的应用模块简单拼合，导致产生大量误报、漏报真实攻击，并且仅能提供有限的标注数据，难以有效支持监督学习模型的训练。\n\n为应对这些挑战，我们提出了 **DrSec** 系统——该系统采用**自监督学习**技术，对基础语言模型（Language Models, LMs）进行预训练，使其能够处理事件序列数据，并为各类进程生成分布式表示（distributed representations）。一旦完成预训练，这些语言模型即可被迁移适配至多种下游任务中，且仅需极少甚至无需人工标注的监督，从而有助于整合当前碎片化的安全应用生态。\n\n我们在包含约 **9100万** 个进程和约 **25.5亿** 个事件的真实数据集上，使用两种类型的语言模型对 DrSec 进行了训练，并在三个实际应用场景中进行了测试。结果表明，DrSec 能够实现**高精度的无监督进程识别**；在告警分类任务中，其性能显著优于现有领先方法，有效缓解了告警疲劳问题（例如，精确率-召回率曲线下面积达到 **75.11%**，而对比方法仅为 **64.31%**）；同时，DrSec 还能准确学习由安全专家设计制定的规则，从而可灵活调优事件检测器，有效控制误报（false positives）和漏报（false negatives）。\n\n**关键词**：端点安全，EDR（端点检测与响应），语言模型，自监督学习，告警分类，进程识别"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：Efficient Design and Implementation of Polynomial Hash Functions over Prime Fields.pdf": {
        "title": "SoK：Efficient Design and Implementation of Polynomial Hash Functions over Prime Fields",
        "abstract": "Poly1305 是一种广泛部署的多项式哈希函数。其设计背后的原理由 Bernstein 在一系列论文中阐述，其中最后一篇发表于2005年。随着计算机体系结构的不断演进，该设计中某些特性逐渐变得不再那么关键；然而，实现者们却发现了利用这些特性来提升性能的新方法。但如果我们基于当今的计算机架构和应用场景从头开始设计，是否还会得出与 Poly1305 相同的设计方案呢？为回答这一问题，我们系统性地整理并归纳了有关多项式哈希函数设计与实现的知识，这些知识原本分散于研究论文、密码学库以及开发者博客之中。我们构建了一个自动化框架，用于验证和基准测试我们所收集到的各项设计思路。\n\n通过这一方法，我们提出了五个新的多项式哈希函数候选设计。利用该框架，我们为每个候选方案生成并评估了多种实现方式与优化策略。在安全性和性能方面，这些新设计相较于 Poly1305 均取得了显著提升。本文不仅阐述了我们新设计背后的设计逻辑，同时也为高效实现多项式哈希函数（包括 Poly1305 本身）提供了实用参考。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Multi-Stage Group Key Distribution and PAKEs：Securing Zoom Groups against Malicious Servers without New Security Elements.pdf": {
        "title": "Multi-Stage Group Key Distribution and PAKEs：Securing Zoom Groups against Malicious Servers without New Security Elements",
        "abstract": "——像Zoom这样的视频会议应用每天拥有数亿用户，使其成为监控和破坏的高价值目标。尽管这类应用声称实现了某种形式的端到端加密，但它们通常假设服务器是“不可被攻破的”，即服务器能够准确识别和认证会议中的所有参与者。具体而言，这意味着：例如，即使启用了“端到端加密”设置，恶意的Zoom服务器仍然可能窃听任意会议或冒充用户身份。\n\n在本研究中，我们提出了一种改进方法，通过改变这类协议使用密码（Zoom中称为“会议码”）的方式，并整合一种基于密码的认证密钥交换（PAKE）协议，从而提升对恶意服务器的安全性。\n\n为了严格证明我们的方法能够实现其安全目标，我们首先形式化了一类适用于该场景的密码学协议，并为其定义了一个基础安全概念：在该概念下，只要服务器被信任能正确授权群组成员，即可实现群组通信的安全性。我们证明，Zoom当前的机制确实满足这一基础安全概念。\n\n接着，我们提出了一个更强的安全概念，该概念即使在服务器恶意的情况下也能提供安全保障。我们进一步提出了一种协议转换方法，能够实现这一更强的安全目标。我们展示了如何将这种转换方法应用于Zoom，从而在不引入新的安全要素（如额外的信任假设或基础设施）的前提下，可证明地实现对恶意服务器的更强防护。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Digital Security - A Question of Perspective A Large-Scale Telephone Survey with Four At-Risk User Groups.pdf": {
        "title": "Digital Security - A Question of Perspective A Large-Scale Telephone Survey with Four At-Risk User Groups",
        "abstract": "本文研究了德国四类高风险用户群体的数字安全经历，包括老年人（70岁以上）、青少年（14-17岁）、有移民背景的人群以及低学历人群。通过计算机辅助电话访谈，我们对每组各抽取250名参与者，样本在地区、性别以及部分年龄分布上具有代表性。研究考察了这些群体的设备使用情况、安全担忧、过往负面经历、对潜在攻击者的认知以及信息获取渠道。本研究首次提供了针对德国这四类高风险群体数字安全经历的量化且全国代表性的实证分析。\n\n研究结果表明，有移民背景的参与者使用的设备最多，主动寻求安全信息的频率更高，遭遇网络犯罪事件的经历也显著多于其他群体。相比之下，老年人使用设备最少，受网络犯罪的影响也最小。所有群体在获取安全信息时，主要依赖亲友和在线新闻，而极少担忧自己社交圈中的人可能构成安全威胁。\n\n我们重点揭示了这四类高风险群体之间的细微差异，并在可能的情况下将其与德国整体人口情况进行对比。最后，我们提出了针对教育、政策制定和未来研究的建议，旨在更好地满足这些高风险用户群体的数字安全需求。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/PriDe CT：Towards Public Consensus, Private Transactions, and Forward Secrecy in Decentralized Payments.pdf": {
        "title": "PriDe CT：Towards Public Consensus, Private Transactions, and Forward Secrecy in Decentralized Payments",
        "abstract": "— **匿名 Zether** 由 Bünz 等人（FC, 2020）提出，并由 Diamond（IEEE S&P, 2021）后续改进，是一种基于账户的**保密支付机制**，其通过智能合约实现隐私保护（即交易的接收方身份和交易内容均被隐藏）。在本文中，我们致力于简化现有协议，同时实现对**多个接收方交易的批量处理**，并确保**共识性**与**前向保密性**（forward secrecy）。据我们所知，这是首个在区块链环境中**形式化研究前向保密性**的工作，借鉴了安全消息通信领域中一个非常流行且实用的思想。具体而言，我们提出了以下三项成果：\n\n- **FUL-Zether**：Zether（Bünz 等，FC, 2020）的**前向安全版本**；  \n- **PRIvate DEcentralized Confidential Transactions**（**PriDe CT**）：一个大幅简化的匿名 Zether 变体，不仅性能具有竞争力，还支持向多个接收方**批量发送交易**；  \n- **PRIvate DEcentralized Forward-secure Until Last update Confidential Transactions**（**PriDeFUL CT**）：PriDe CT 的**前向安全版本**。\n\n我们还提供了基于以太坊的**开源实现**。PriDe CT 与匿名 Zether 一样采用**线性同态加密**，但使用了更简单的**零知识证明**。PriDeFUL CT 则引入一种新的**基于 DDH 假设**（Decisional Diffie-Hellman）的标准模型下的可更新公钥加密方案，以实现前向保密性。\n\n在交易体积方面，Quisquis（Asiacrypt, 2019）是目前**唯一支持批量处理**的加密货币（尽管基于 UTXO 模型），但其所需的群元素数量是 PriDe CT 的 **15 倍**。此外，对于包含 $ N $ 个接收方的环结构，即使不考虑 PriDe CT 所具备的批量能力，匿名 Zether 仍需多出 $ 6 \\log N $ 个额外项。\n\n进一步地，我们的实现结果表明：当 $ N = 32 $，即使有 7 个目标接收方，**PriDe CT 在证明生成时间和 Gas 消耗上均优于匿名 Zether**。\n\n> 本文由摩根大通及其关联公司（“J.P. Morgan”）人工智能研究团队出于信息目的编写，并非 J.P. Morgan 研究部门的正式产品。J.P. Morgan 对本文信息的完整性、准确性或可靠性不作任何明示或暗示的陈述与保证，也不承担任何责任。本文不构成投资研究、投资建议、推荐，也不构成对任何证券、金融工具、金融产品或服务的购买或出售要约、招揽或建议，亦不可用于评估参与任何交易的可行性。在任何司法管辖区或向任何人士，若据此进行招揽行为属于违法，则本文不构成该类招揽行为。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Leaky Address Masking：Exploiting Unmasked Spectre Gadgets with Noncanonical Address Translation.pdf": {
        "title": "Leaky Address Masking：Exploiting Unmasked Spectre Gadgets with Noncanonical Address Translation",
        "abstract": "——线性地址掩码（Linear Address Masking, LAM）是英特尔近期推出的一项新功能，允许CPU在解引用64位指针前，屏蔽掉地址中的一些高位比特。LAM的核心思想（与AMD的类似技术“高位地址忽略”（Upper Address Ignore, UAI）类似）是让软件能够高效地利用64位线性地址中未被翻译的高位比特来存储元数据（metadata）。其基本前提是：在启用LAM（或UAI）功能的情况下，系统可以快速实现安全机制（例如内存安全性检查），从而最终提升生产环境系统的安全性。\n\n在本文中，我们挑战了这一假设，并指出LAM功能实际上可能**降低**生产环境的安全性——因为它显著扩大了**Spectre攻击面**。为支持这一观点，我们提出了一种基于**非规范地址翻译**（noncanonical address translation）的新型Spectre隐蔽信道（covert channel），并解决了在实际中实现该信道的关键挑战。例如，我们利用现代**转换后备缓冲器**（TLB）的特性来构建一个可靠的信号，并利用LAM功能**关键性地绕过规范地址检查**（canonicality checks）。\n\n更重要的是，我们指出，与传统的Spectre隐蔽信道不同，我们的攻击方式能够激活**通用型（或未掩码）Spectre gadget**——这些gadget可将高熵秘密（如密码哈希）编码为解引用的指针。相比之下，传统的（即已掩码的）gadget通常会因安全机制而失效，而我们揭示的这类gadget却能够**绕过现有的防御措施**，并且在如Linux内核等高价值目标中**广泛存在**。\n\n为展示这一新的攻击面，我们提出了一个端到端的Spectre攻击原型，称为**基于LAM的Spectre攻击**（Spectre based on LAM, SLAM），其目标为即将推出的英特尔CPU。我们特别聚焦于**BHI（Branch History Injection）这一Spectre变种**，并证明：尽管已有防御措施被认为已消除其攻击面，我们的攻击仍能利用最新版Linux内核中的多种gadget，在几分钟内从内核内存中泄露**root密码哈希**。\n\n最后，我们对可能的缓解措施进行了评估与探讨。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Poisoning Web-Scale Training Datasets is Practical.pdf": {
        "title": "Poisoning Web-Scale Training Datasets is Practical",
        "abstract": "深度学习模型通常是在从互联网爬取的大规模分布式数据集上进行训练的。在本文中，我们提出了两种新型的数据集投毒攻击，旨在故意向训练数据中注入恶意样本，从而破坏模型的性能。我们的攻击方法具有直接的现实可行性，目前即可对10个主流数据集实施投毒。第一种攻击称为“分视图投毒”（split-view poisoning），它利用了互联网内容的可变性，确保数据集标注者在初始查看数据时的内容与后续客户端下载到的内容存在差异。通过利用某些无效的信任假设，我们展示了仅花费60美元即可对LAION-400M或COYO-700M数据集中0.01%的数据实施投毒。第二种攻击称为“抢先投毒”（frontrunning poisoning），其目标是一类周期性抓取众包内容的网络级数据集（如维基百科），攻击者只需在短暂的时间窗口内注入恶意样本即可达成目的。鉴于这两种攻击的威胁，我们已通知所有受影响数据集的维护方，并提出了若干低开销的防御建议。\n\n（翻译说明：  \n1. 专业术语处理：\"split-view poisoning\"和\"frontrunning poisoning\"采用意译+保留英文原词的方式，确保技术准确性；\"mutable nature\"译为\"可变性\"符合计算机领域术语习惯。  \n2. 长句拆分：将原文中复合长句按中文表达习惯拆解为多个短句，如第二段首句的分布式数据集描述独立成句。  \n3. 被动转主动：\"we notify\"等被动结构转为中文主动表述\"我们已通知\"，增强可读性。  \n4. 数字与单位：严格保留\"$60 USD\"、\"0.01%\"等原始数据，符合学术论文翻译规范。  \n5. 逻辑显化：通过\"旨在\"\"鉴于\"等连接词明确原文隐含的因果关系，如攻击方法与防御建议的对应关系。）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Practical Attacks Against DNS Reputation Systems.pdf": {
        "title": "Practical Attacks Against DNS Reputation Systems",
        "abstract": "——DNS信誉系统是网络安全防御体系中的关键一环，它利用机器学习（ML）技术，基于与DNS相关的行为特征来识别潜在的恶意域名。尽管这类系统在防范垃圾邮件、恶意软件和社会工程攻击方面发挥着重要作用，但目前人们对于现实世界中DNS信誉系统面对攻击时的鲁棒性（即抗对抗性能力）知之甚少。本研究首次系统性地探讨了针对DNS信誉系统的通用攻击方法。\n\n为克服现有DNS信誉系统部署中存在的“黑箱”问题，我们首先构建了一个开源的参考型DNS信誉系统。该系统具有以下特点：1）避免了先前研究中在数据收集、预处理、模型训练和评估等环节中常见的缺陷；2）能够较好地复现先前研究中的DNS信誉系统；3）为未来可重复、可验证的相关研究提供了基础平台。\n\n我们发现，由于输入空间高度受限、特征之间存在复杂的相互依赖关系，以及从特征向量难以逆向还原为原始输入样本，传统的通用对抗性机器学习技术在DNS场景下并不实用。\n\n为此，我们提出了两类更实用的攻击方法：**模仿攻击**（mimicry）和**流行度操纵**（popularity manipulation）。实验表明，这两类攻击在我们的参考模型以及一个主流商用DNS信誉系统上均取得了很高的攻击成功率，充分说明这些攻击方法具有良好的现实可迁移性。\n\n最后，我们构建了约束模型，用于评估执行上述攻击所需的时间和资金成本。基于该模型的分析结果显示：一个仅需10美元成本的攻击者，在两周内即可实现对某领先安全厂商DNS信誉系统的100%规避成功率。\n\n这揭示了当前DNS信誉系统在实际部署中可能存在的严重安全漏洞，也凸显了提升其对抗鲁棒性的紧迫性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SINBAD：Saliency-informed detection of breakage caused by ad blocking.pdf": {
        "title": "SINBAD：Saliency-informed detection of breakage caused by ad blocking",
        "abstract": "——基于过滤列表规则的隐私增强型屏蔽工具往往会破坏网站的正常功能。过滤列表的维护者若能借助自动化的故障检测工具，便可在规则部署至数百万用户之前，主动发现并修复有问题的规则。我们推出了 SINBAD，这是一种自动化的故障检测器，其准确率比现有最先进技术高出 20%，并且首次实现了对动态故障以及由样式类过滤规则引发的故障的检测。\n\nSINBAD 的成功源于三项创新：(1) 利用用户在论坛中报告的故障问题，构建高质量的训练数据集，确保仅包含用户实际感知为“问题”的故障，从而提升模型的实用性；(2) 引入“网页显著性”（web saliency）技术，自动识别网页上用户最关注的区域，优先在这些区域执行自动化交互操作，以提高触发故障的效率；(3) 通过分析网页的子树结构，实现对问题过滤规则的细粒度定位，从而更精确地识别出导致故障的具体规则。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics.pdf": {
        "title": "Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics",
        "abstract": "深度学习中的后门攻击会在模型中植入一个隐藏的后门，当输入具有特定模式时，便会触发恶意行为。现有的检测方法通常假设存在一个度量空间（无论是针对原始输入还是其潜在表示），在该空间中正常样本与恶意样本是可分离的。我们通过提出一种新型的后门攻击——SSDT（特定源且动态触发器，Source-Specific and Dynamic Triggers）——揭示了该假设的严重局限性：这种攻击会掩盖正常样本与恶意样本之间的差异，使得传统方法难以识别。\n\n为克服这一局限，我们不再局限于寻找一种适用于不同深度学习模型的“理想”度量空间，而是转向更具鲁棒性的拓扑结构。我们提出了一种模型无关的鲁棒后门检测方法——TED（拓扑演化动力学，Topological Evolution Dynamics）。TED 的核心思想是将深度学习模型视为一个将输入逐步演化为输出的动态系统。在该系统中，良性输入遵循与其他良性输入相似的自然演化轨迹；而恶意样本虽然初始状态接近良性样本，但其演化轨迹却明显不同，最终会偏离正常路径，转向攻击者预设的目标样本邻域，从而激活后门。\n\n我们在多种网络架构上，针对图像和自然语言处理数据集进行了广泛的实验评估。结果表明，TED 不仅实现了较高的检测率，而且显著优于当前最先进的检测方法，尤其在应对复杂的 SSDT 攻击时表现突出。相关代码已开源发布在 GitHub 上，以支持实验结果的可复现性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/\"False negative - that one is going to kill you\"：Understanding Industry Perspectives of Static Analysis based Security Testing.pdf": {
        "title": "\"False negative - that one is going to kill you\"：Understanding Industry Perspectives of Static Analysis based Security Testing",
        "abstract": "——对自动化安全分析技术的需求，例如基于静态分析的安全测试（SAST）工具，正在持续增长。为了使开发人员能够有效利用SAST工具来发现安全漏洞，研究人员和工具设计者必须深入了解开发人员如何感知、选择并使用这些工具，他们对工具的期望是什么，是否了解工具的局限性，以及如何应对这些局限。本文介绍了一项定性研究，旨在探究使用SAST工具的开发人员所持有的假设、期望、信念以及面临的挑战。我们针对20名从业者进行了深入、半结构化的访谈，这些受访者具备多样化的软件开发专业背景，同时在安全、产品以及组织环境方面也拥有丰富的经验。研究总结出17项关键发现，揭示了开发人员对SAST工具的认知与期望，同时暴露了当前现状中的诸多不足——这些发现挑战了长期以来在SAST工具设计优先级方面所持有的固有观念。最后，我们基于对研究结果的分析，为研究人员和实践者提出了切实可行的未来发展方向。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Measuring the Effects of Stack Overflow Code Snippet Evolution on Open-Source Software Security.pdf": {
        "title": "Measuring the Effects of Stack Overflow Code Snippet Evolution on Open-Source Software Security",
        "abstract": "本文评估了Stack Overflow上代码片段的演变对开源项目安全性的影响。Stack Overflow的用户会积极修改已发布的代码片段，有时甚至会修复其中的错误和安全漏洞。因此，那些从Stack Overflow复用代码的开发者，应当像对待其他不断演化的代码依赖项一样，对其保持关注，并对更新保持警惕。但目前尚不清楚开发者是否真的这样做了，也不清楚GitHub项目中究竟存在多少来自Stack Overflow的过时代码片段，以及开发者是否遗漏了与被复用代码片段相关的安全更新。\n\n为回答这些问题，我们设计了一种方法，用于：  \n1）在11,479个流行的GitHub项目中，识别出源自Stack Overflow的150万个代码片段中的过时版本；  \n2）检测这些Stack Overflow代码片段所经历的安全相关更新，而这些更新并未在对应的GitHub项目中体现。\n\n研究结果表明，当Stack Overflow上的代码片段发生更新时，开发者并未同步更新其项目中依赖的对应代码。我们发现，有2,405个代码片段版本被2,109个GitHub项目复用，但这些版本已经过时。其中，有43个项目未同步Stack Overflow上已修复的漏洞和错误补丁。这43个包含过时且不安全代码片段的项目，平均被分叉（fork）了1,085次（最多达16,121次），这表明受影响的代码库数量可能远超我们当前发现的范围，我们的结果很可能只是受影响情况的下限。\n\n本研究的一个重要启示是：如果将Stack Overflow上的代码视为完全静态的代码，将阻碍针对“从Stack Overflow复制不安全代码”这一问题的整体性解决方案。相反，我们的结果表明，开发者需要一类新的工具——这些工具应能持续监控Stack Overflow，针对已复用的代码片段，实时发现安全警告和代码修复，而不仅仅在“复制-粘贴”时才发出提醒。唯有如此，才能有效应对代码复用带来的安全风险。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Eureka：A General Framework for Black-box Differential Privacy Estimators.pdf": {
        "title": "Eureka：A General Framework for Black-box Differential Privacy Estimators",
        "abstract": "——差分隐私（Differential Privacy, DP）是隐私保护数据分析中的关键工具。然而，对于非隐私专家而言，证明其算法满足差分隐私仍然极具挑战。我们提出了一种方法，使那些仅有有限数据隐私背景知识的领域专家，也能通过经验方式估算任意机制的隐私水平。我们的“顿悟时刻”在于发现并证明了差分隐私参数估计问题与机器学习中贝叶斯最优分类器问题之间存在一种全新联系——我们认为这一联系本身具有独立的研究价值。基于这一联系，我们提出的估计器具备两个理想特性：(1) 黑盒性（black-box），即无需了解机制内部结构；(2) 理论可证明的准确性，其精度取决于所使用的底层分类器，因此可灵活“即插即用”不同分类器。\n\n更具体地说，我们首先证明了在无限制输入域上完成上述任务是不可能的，受此启发，我们引入了一种自然且贴近实际应用的差分隐私松弛形式，称为**相对差分隐私（Relative DP）**。直观上，相对差分隐私将机制的隐私性定义相对于一个输入集合 *T* 来衡量，当 *T* 为有限集时，便避开了上述不可能性结果。更重要的是，它保留了差分隐私的核心直觉性隐私保障，同时具备一系列理想的差分隐私性质：可扩展性、可组合性以及对后处理过程的鲁棒性。\n\n基于此，我们设计了一种**黑盒多项式时间（ε, δ）-相对差分隐私估计器**，适用于任意多项式规模的集合 *T*。这是首个在输出空间较大的机制上仍能实现紧确（tight）精度界限的隐私估计器。作为一项具有独立意义的结果，我们进一步推广该理论，提出了首个**分布差分隐私（Distributional Differential Privacy, DDP）估计器**。\n\n我们通过一个概念验证性实现对我们的估计器进行了基准测试。首先，使用k近邻（kNN）作为分类器，我们展示了该方法：(1) 首次为低维拉普拉斯（Laplace）和高斯（Gaussian）机制生成了紧确且可解析计算的（ε, δ）-DP权衡曲线；(2) 准确估计了DDP机制的隐私谱；(3) 能够验证多种DP机制的具体实现，例如稀疏向量技术（Sparse Vector Technique）、带噪声直方图（Noisy Histogram）和带噪声最大值（Noisy Max）。我们的实现与实验展示了该框架的潜力，并突显了在估算差分隐私时存在的计算瓶颈，例如与δ的取值大小以及数据维度相关的问题。\n\n其次，我们基于神经网络的实例化方案迈出了关键一步，表明该方法可进一步扩展至具有**高维输出**的机制。这为未来处理更复杂、更现实的隐私机制提供了可能。\n\n---\n\n**注释补充（便于理解）：**  \n1. 本文的核心创新在于将“隐私估计”这一传统上依赖理论推导的任务，转化为一个可通过机器学习模型（分类器）来经验性解决的统计问题。  \n2. “黑盒”意味着无需访问机制的代码或数学形式，仅需通过输入-输出样本进行查询，极大降低了使用门槛。  \n3. “相对DP”通过限制输入域为有限集合 *T*，绕过了在无限域上无法一致估计隐私的障碍，同时仍保持实用性与理论严谨性。  \n4. 实验中使用kNN和神经网络分别验证了方法在低维与高维场景下的可行性，为后续研究提供了可扩展路径。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Casual Users and Rational Choices within Differential Privacy.pdf": {
        "title": "Casual Users and Rational Choices within Differential Privacy",
        "abstract": "——随着近年来隐私意识和数据所有权观念的不断增强，差分隐私（Differential Privacy, DP）已成为一种颇具前景的技术，并被多家知名数据控制机构所采用。这引发了一个关键问题：作为隐私威胁与风险最直接的承受者，普通用户如何理解并感知DP及其核心参数ε？因为DP所提供的保护程度正取决于ε的取值。现有研究表明，当通过清晰的文字说明和可视化辅助手段向普通用户传达DP的基本原理及其对隐私与数据效用之间权衡关系的影响时，他们完全有能力理解DP的基本机制，并据此对是否在差分隐私保护下分享自己的数据做出知情决策。\n\n然而，目前的相关尝试要么仅在沟通中隐含地提及ε的几个可能取值（如“低”“中”“高”），要么干脆完全忽略ε的明确传达。在本文中，我们开展了一项被试间用户研究（N = 426），旨在探讨九种交互式可视化工具在数据分享场景下（具体为发布新冠阳性检测结果）**显式地、在连续尺度上**传达ε值的有效性。这些交互式可视化工具使普通用户能够直观地看到不同ε值下DP对数据准确性以及/或隐私泄露程度的影响。\n\n研究发现，**包含隐私损失成分的可视化工具**在帮助用户选择更接近专家推荐值的ε方面具有显著效果。然而，**准确性损失成分对用户ε选择的影响则存在差异**：其影响程度取决于DP引入的噪声与原始数据之间的比例——相对误差越大，用户选择的ε值也越大（即隐私保护更弱），反之亦然。因此，在呈现数据准确性损失时必须格外谨慎。\n\n我们将研究结果置于现有文献中进行讨论，并总结出若干洞见与建议，旨在指导如何更有效地向普通用户传达差分隐私的概念，从而提升其在隐私保护实践中的参与度与决策质量。\n\n**关键词**：差分隐私，交互式ε可视化，普通用户感知，隐私-准确性权衡"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/One for All and All for One：GNN-based Control-Flow Attestation for Embedded Devices.pdf": {
        "title": "One for All and All for One：GNN-based Control-Flow Attestation for Embedded Devices",
        "abstract": "控制流认证（Control-Flow Attestation, CFA）是一种安全服务，允许某个实体（验证者）验证远程计算机系统（证明者）上代码执行的完整性。现有的CFA方案存在不切实际的前提假设，例如要求访问证明者的内部状态（如内存或代码）、完整的控制流图（Control-Flow Graph, CFG）、大量测量数据，或依赖定制化硬件。此外，当前的CFA方案由于计算开销大、资源消耗高，难以适用于嵌入式系统。\n\n在本文中，我们通过提出一种名为 **RAGE** 的新型轻量级CFA方法，克服了现有CFA方案在嵌入式设备上的局限性。RAGE具有极低的前提要求，能够检测代码复用攻击（Code Reuse Attacks, CRA），包括控制流攻击和非控制数据攻击。该方法只需从一次执行轨迹中高效提取特征，并利用无监督图神经网络（Graph Neural Networks, GNNs）来识别与正常（良性）执行之间的偏差。RAGE的核心思想在于利用执行轨迹、执行图和执行嵌入（execution embeddings）之间的对应关系，从而消除对“完整CFG”这一不切实际的前提依赖。\n\n我们在嵌入式基准测试平台上对RAGE进行了评估，结果表明：（i）RAGE能够检测出针对嵌入式软件的40种真实世界攻击；（ii）进一步地，我们在真实嵌入式软件基准测试集Embench上施加了合成的面向返回编程（Return-Oriented Programming, ROP）和面向数据编程（Data-Oriented Programming, DOP）攻击，RAGE的F1分数分别达到98.03%（ROP）和91.01%（DOP），同时将误报率（False Positive Rate, FPR）控制在较低水平（3.19%）；（iii）此外，我们还在被数以百万计设备广泛使用的OpenSSL上评估了RAGE，对ROP和DOP攻击检测的F1分数分别达到97.49%和84.42%，误报率为5.47%。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Distributed & Scalable Oblivious Sorting and Shuffling.pdf": {
        "title": "Distributed & Scalable Oblivious Sorting and Shuffling",
        "abstract": "现有的**不可区分性系统**（oblivious systems）通过隐藏内存访问模式来提供强大的安全性，但在**可扩展性**和**性能**方面面临重大挑战。近年来，为提升这类系统的实用性，研究者尝试将**不可区分计算**（如不可区分排序和洗牌）嵌入到**可信执行环境**（Trusted Execution Environments, TEEs）中。例如，不可区分排序已被广泛应用：在 Oblix（S&P’18）中，用于创建和访问不可区分索引；在 Snoopy 的高吞吐不可区分键值系统（SOSP’21）中，用于初始化阶段以及在对输入请求进行去重和准备分发时；在 Opaque（NSDI’17）中，被用于所有提出的不可区分 SQL 操作符；在最新的非外键不可区分连接方法（PVLDB’20）中也发挥了关键作用。此外，不可区分排序/洗牌还被应用于 Signal 的商业化联系人发现方案、Google 匿名密钥透明性（Key Transparency）、可搜索加密、软件监控，以及保护用户隐私的差分隐私联邦学习等场景中。\n\n在本工作中，我们针对**不可区分排序与洗牌的可扩展性瓶颈**，重新设计了相关算法，使其在**分布式多可信执行环境**（multi-enclave）场景下实现高效运行。首先，我们提出了一种**多线程化的双调排序**（bitonic sort），专为分布式环境优化，使其在少量可信执行环境（最多4个）下成为性能最优的不可区分排序算法。对于更大规模的多可信执行环境场景，我们提出了一种全新的**不可区分桶排序**（oblivious bucket sort），该算法显著提升了**数据局部性**并减少了**网络开销**，性能比我们优化后的分布式双调排序高出**5到6倍**。据我们所知，这是首个基于可信执行环境的**分布式不可区分排序解决方案**。作为参考，在我们的多可信执行环境测试中，能够在**1秒内完成2 GiB数据的排序**，在**53.4秒内完成128 GiB数据的排序**。\n\n我们不可区分桶排序的一个核心基础模块是一种新的**不可区分洗牌算法**，在分布式多可信执行环境设置下，其性能比此前最先进的成果（CCS’22）提升了**高达9.5倍**——有趣的是，即使在**单可信执行环境/多线程**设置下，其性能仍比现有方案高出**10%**。\n\n**关键词**：不可区分排序，洗牌，分布式，可扩展性"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Pudding：Private User Discovery in Anonymity Networks.pdf": {
        "title": "Pudding：Private User Discovery in Anonymity Networks",
        "abstract": "匿名网络能够实现具有元数据隐私保护的通信，其隐私性优于当前主流的加密消息应用。然而，目前在匿名网络中联系某个用户，必须知道其公钥或类似的高熵信息，因为这些系统缺乏一种能够保护隐私的机制，允许通过简短、易读的用户名来联系用户。已有研究表明，这一限制阻碍了匿名网络的广泛普及。\n\n在本文中，我们提出了Pudding——一种新颖的隐私保护用户发现协议，它允许仅通过用户的电子邮件地址，就在匿名网络中联系到该用户。我们的协议能够隐藏用户之间的联系关系，防止身份冒充，并掩盖哪些用户名已在网络中注册。Pudding具备拜占庭容错能力：只要不超过三分之一的服务器发生崩溃、不可用或恶意行为，系统仍能保持可用且安全。该协议无需修改底层匿名网络协议，即可部署在Loopix和Nym等匿名网络上，并且支持网络连接不稳定的移动设备。我们通过在Nym匿名网络上构建的原型系统，验证了Pudding的实用性。\n\n此外，我们还正式定义了该协议的安全性与隐私性目标，并进行了全面分析，以评估其对这些目标定义的符合程度。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/\"Watching over the shoulder of a professional\"：Why Hackers Make Mistakes and How They Fix Them.pdf": {
        "title": "\"Watching over the shoulder of a professional\"：Why Hackers Make Mistakes and How They Fix Them",
        "abstract": "——软件系统的复杂性和多样性要求采用细致的人工方法来发现漏洞，这一过程涉及深入分析、创造性问题解决以及专业的技术知识。与所有复杂任务一样，漏洞挖掘也容易因认知局限和行为因素导致的错误而影响最佳表现。尽管已有大量研究工作聚焦于漏洞发现本身，但鲜少有人关注挖掘过程中所犯错误的理解与剖析。深入理解这些错误，有助于设计更优质的教育课程和自动化工具，从而减少甚至预防潜在错误，提升漏洞研究的效率。\n\n在本文中，我们利用社交媒体平台（特别是YouTube），分析安全内容创作者在CTF（夺旗赛）风格挑战中进行漏洞利用时所犯的错误。通过对来自11名黑客的30个屏幕录制视频进行分析，我们识别出124个不同类型的具体问题，并进一步研究了这些问题的类别、根本原因以及所耗费的时间。此外，我们还深入探讨了与这些问题相关的认知与行为层面的因素。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/PassREfinder：Credential Stuffing Risk Prediction by Representing Password Reuse between Websites on a Graph.pdf": {
        "title": "PassREfinder：Credential Stuffing Risk Prediction by Representing Password Reuse between Websites on a Graph",
        "abstract": "——凭证填充（credential stuffing）的泛滥已对习惯在多个网站重复使用密码的在线用户造成了严重危害。为应对这一问题，研究人员致力于检测设置相同密码的用户或识别恶意登录行为。然而，现有的检测方法往往以牺牲密码的可用性为代价，例如限制密码创建或阻碍网站访问。此外，共享账户信息的复杂机制也阻碍了这些方法在实际中的部署。为此，在本研究中，我们提出了一种风险预测框架，旨在通过提前预防凭证填充攻击来保护用户，而非依赖攻击发生后的检测，从而避免对用户行为的干扰。\n\n为此，我们创新性地定义了用户极有可能重复使用密码的网站之间的关系，并利用图神经网络（Graph Neural Networks, GNN）将该关系表示为网站图中的一条边。随后，我们通过执行链路预测（link prediction）任务，识别网站之间发生凭证填充的风险。我们的框架能够适用于大量任意网站，仅需利用公开的网站信息，并将新观测到的网站节点链接至图中即可。\n\n在包含来自22,378个网站的3.6亿个泄露账户的真实数据集上的实验表明，我们的模型在不同图学习设置下分别实现了0.9559和0.9100的F1分数，成功预测了网站之间的凭证填充风险。此外，我们验证了各项设计策略的有效性，并证实预测结果可用于将密码重复使用的预期概率量化为风险评分。\n\n**关键词**——密码认证，凭证填充，图神经网络"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/TuDoor Attack：Systematically Exploring and Exploiting Logic Vulnerabilities in DNS Response Pre-processing with Malformed Packets.pdf": {
        "title": "TuDoor Attack：Systematically Exploring and Exploiting Logic Vulnerabilities in DNS Response Pre-processing with Malformed Packets",
        "abstract": "DNS 可被比作一场国际象棋：规则看似简单，但其蕴含的可能性却无穷无尽。尽管 DNS 的基本规则非常直观，DNS 的实际实现却可能极其复杂。在本研究中，我们旨在通过系统性地分析 DNS 的 RFC 标准文档及各类 DNS 软件实现，深入探究 DNS 响应预处理过程中的复杂性与潜在漏洞。我们发现了三类新型逻辑漏洞，并据此提出了三种全新的攻击方式，统称为 **TUDOOR 攻击**。这些攻击利用格式异常的 DNS 响应数据包，实施 DNS 缓存投毒、拒绝服务（DoS）以及资源耗尽攻击。\n\n通过全面的实验验证，我们证明了 TUDOOR 攻击的可行性及其在现实世界中的显著影响。共有 **24 款主流 DNS 软件** 受到 TUDOOR 影响，包括 BIND、PowerDNS 和 Microsoft DNS 等。攻击者仅需发送少量精心构造的数据包（在 1 秒内），即可对存在漏洞的解析器发动缓存投毒或拒绝服务攻击；或绕过查询频率限制，耗尽解析资源（如 CPU 算力）。\n\n为了评估野外环境中存在漏洞的解析器规模，我们收集并分析了 **16 款主流 Wi-Fi 路由器、6 种常见路由器操作系统、42 个公共 DNS 服务，以及约 180 万个开放 DNS 解析器**。测量结果表明，TUDOOR 攻击可成功利用 **7 款路由器（或操作系统）、18 个公共 DNS 服务，以及 424,652 个（占比 23.1%）开放 DNS 解析器**。\n\n遵循负责任的漏洞披露最佳实践，我们已向所有受影响的厂商报告了这些漏洞。其中，包括 BIND、Chrome、Cloudflare 和 Microsoft 在内的 **18 家厂商已确认我们的发现，并与我们讨论了相应的缓解方案**。此外，相关机构已为我们发现的漏洞分配了 **33 个 CVE 编号**。作为缓解措施之一，我们还开发并提供了一款在线检测工具。\n\n本研究突显出：**亟需对 DNS 响应预处理逻辑进行标准化**，以全面提升 DNS 系统的安全性。DNS 作为互联网的核心基础设施，其安全不容忽视。只有通过规范实现行为、消除逻辑歧义，才能从根本上防范此类新型逻辑攻击，保障全球网络服务的稳定与可信。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Attacking Byzantine Robust Aggregation in High Dimensions.pdf": {
        "title": "Attacking Byzantine Robust Aggregation in High Dimensions",
        "abstract": "——现代神经网络或模型的训练通常需要对高维向量样本进行平均。投毒攻击（poisoning attacks）会扭曲或偏置用于训练模型的平均向量，迫使模型学习特定模式，或无法学习任何有用的知识。拜占庭鲁棒聚合（Byzantine robust aggregation）是一种针对此类偏置攻击的、基于原理的算法防御机制。鲁棒聚合器能够限制中心性统计量（如均值）计算中的最大偏置，即使部分输入被任意篡改。然而，在高维空间中设计此类聚合器极具挑战性。尽管如此，近期已首次提出了在多项式时间内运行、且对偏置具有强理论界定的算法。这些算法的误差上界与维度数量无关，预示着在攻击与防御的持续军备竞赛中，投毒攻击的能力可能面临一个根本性的理论极限。\n\n本文中，我们提出了一种名为 H IDRA 的新型攻击，针对那些宣称具备“维度无关偏置”的强防御机制的实际实现进行攻击，从而颠覆其理论优势。H IDRA 揭示了一个此前在信息论分析中未被关注的全新计算瓶颈。我们的实验评估表明，该攻击几乎完全摧毁了模型性能，而现有具有相同攻击目标的方法却收效甚微。我们的发现表明，投毒攻击与可证明鲁棒性防御之间的军备竞赛，远未结束，仍处于开放状态。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Hyena：Balancing Packing, Reuse, and Rotations for Encrypted Inference.pdf": {
        "title": "Hyena：Balancing Packing, Reuse, and Rotations for Encrypted Inference",
        "abstract": "——深度神经网络已被广泛应用于各类商业服务中。其中许多服务部署在云端，用户需要将个人数据上传至云服务平台。这导致用户的隐私和敏感数据暴露于多个第三方。为解决这一问题，同态加密（Homomorphic Encryption, HE）应运而生：用户在将数据发送至云端前先行加密，云端在加密数据上执行计算操作，并将加密结果（密文）返回给用户，最终由用户自行解密。尽管这种方法能够有效保护用户数据的隐私，但其计算开销和数据传输量却呈数量级增长。因此，亟需设计硬件与软件协同优化技术，以降低在同态加密环境下执行人工智能服务所带来的额外开销。\n\n本文针对AI推理任务中的多种同态加密实现方案，深入分析了当前最先进框架中的关键瓶颈。我们首先提出，相较于纯全同态加密（Fully HE），一种混合使用同态加密与多方安全计算（Multi-Party Computation, MPC）的方案更具实用性。本文从多个层面引入创新技术：（i）提出新型数据打包（data packing）技术，显著降低数据移动开销；（ii）设计新的数据流（dataflow）策略，提升数据复用率，减少昂贵同态操作（如旋转、密钥切换、数论变换NTT转换）的频次；（iii）在一个平衡的流水线架构上评估所提出的Hyena框架，该架构能高效支持上述核心操作原语。\n\n最终提出的框架——Hyena（结合新型数据打包与数据流设计）——在性能和能效方面均显著优于多种现有打包基线方案。与广泛采用的通道打包（Channel-packing）方法相比，Hyena的推理速度提升达38倍，能耗降低至其1/162。在面积为163 mm²、功耗为16.75W的加速器上，ResNet20模型端到端推理延迟仅为11.4毫秒，展现出卓越的实际应用潜力。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Efficient Zero-Knowledge Arguments For Paillier Cryptosystem.pdf": {
        "title": "Efficient Zero-Knowledge Arguments For Paillier Cryptosystem",
        "abstract": "我们提出了一种专为Paillier密码系统定制的高效零知识知识论证（zero-knowledge argument of knowledge）系统。该系统具有**亚线性证明尺寸**、**低验证开销**和**可接受的证明生成成本**，同时支持**批量证明的生成与验证**。现有针对Paillier密码系统的方案通常具有线性增长的证明尺寸和验证时间。而若采用适用于通用陈述的现有亚线性论证系统（如zk-SNARK），则会因需将待证明的数学关系转化为一个极其庞大的布尔电路或素数域上的算术电路，导致证明生成成本过高，难以承受。我们的系统避免了这些缺陷。\n\n本论证系统的核心是一个定义在**合数模下的剩余类环**（ring of residue classes modulo a composite number）上的约束系统，并结合了为此设定量身设计的新技术，用于高效论证二进制值。随后，我们借鉴Bootle等人（EUROCRYPT 2016）的方法，将该约束系统编译成一个亚线性规模的论证系统。我们的约束系统具有通用性，能够表达Paillier密码系统中常见的多种典型关系，包括：明文范围证明（range proof）、加密正确性证明（correctness proof）、明文各位之间的比特关系、多个密文间明文之间的关联等。此外，该系统支持批量证明的生成与验证，当Paillier密文数量达到数百量级时，其**平均成本优于当前最先进的专用协议**。\n\n我们实现了一个端到端的原型系统，并在多种场景下进行了全面实验。  \n- **场景1：Paillier密文打包（packing）**。当我们将25.6K比特的数据打包进400个密文时，证明所有这些密文均被正确加密的证明大小仅为朴素实现（即使用25.6K个独立的OR证明且无打包）的**1/17**，验证速度则提升了**3倍**。更重要的是，我们还能以近乎零额外开销的方式证明附加陈述，例如：可证明某个子集见证比特之和小于给定阈值t。  \n- **场景2：范围证明（range proof）**。对于200个Paillier密文，要证明每个明文均为256比特长度，我们的证明尺寸比当前最优方案**缩小了10倍**。\n\n我们的分析表明，该系统在**渐近意义下优于现有协议**，尤其适用于涉及大量（超过100个）Paillier密文的场景——而这正是数据分析类应用中的常见情况。因此，本系统在实际应用中具有高度适用性。\n\n* 通讯作者"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Efficient Detection of Java Deserialization Gadget Chains via Bottom-up Gadget Search and Dataflow-aided Payload Construction.pdf": {
        "title": "Efficient Detection of Java Deserialization Gadget Chains via Bottom-up Gadget Search and Dataflow-aided Payload Construction",
        "abstract": "——Java对象注入（Java Object Injection, JOI）是一种严重的安全漏洞，影响Java反序列化过程。攻击者可利用该漏洞注入一个精心构造的序列化对象，从而触发一系列内部方法链（称为“gadget链”），最终实现诸如远程代码执行（Remote Code Execution, RCE）等攻击后果。此前的研究工作尝试通过**静态搜索潜在gadget链**和**基于模糊测试（fuzzing）动态构造攻击载荷**的方法，来解决JOI漏洞中gadget的检测与串联问题。然而，这些方法面临以下两个主要挑战：  \n（i）静态gadget搜索中的路径爆炸问题；（ii）在动态载荷构造过程中，缺乏对通过对象字段连接的**细粒度对象间关系**的建模。\n\n本文设计并实现了一种全新的Java反序列化gadget检测框架，名为 **JDD**。  \n一方面，JDD通过一种**自底向上**的方法解决静态路径爆炸问题：首先识别出gadget片段，然后从“汇聚点”（sinks）向“起点”（sources）逐步拼接这些片段。该方法将最大静态搜索时间复杂度从指数级降低至多项式级，即从 **O(e·Mⁿ)** 降至 **O(M²·n³ + e·n·M)**，其中：  \n- **n** 表示一个gadget链中动态函数调用的数量，  \n- **M** 表示每个步骤中动态函数调用候选的平均数量，  \n- **e** 表示程序入口点的数量。  \n\n另一方面，JDD构建了一种名为**注入对象构造图**（Injection Object Construction Diagram, IOCD）的模型，用于刻画注入对象字段之间的数据流依赖关系，从而支持更高效的动态模糊测试。\n\n我们对JDD在六个真实Java应用上进行了评估，共发现了**127条此前未知的、可利用的gadget链**，并已为其中6个漏洞分配了**通用漏洞披露编号**（CVE）。我们已负责任地向相关应用的开发者报告了这些漏洞，并获得了他们的确认与致谢。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/hinTS：Threshold Signatures with Silent Setup.pdf": {
        "title": "hinTS：Threshold Signatures with Silent Setup",
        "abstract": "我们提出了 hinTS——一种基于广泛使用的 BLS 签名构建的新型门限签名方案。该方案具备以下引人注目的特性：\n\n- **静默设置过程**：各参与方的联合公钥可通过其本地计算的公钥，按确定性函数直接计算得出，无需任何交互。\n- **支持动态选择门限值和签名者**：在完成静默设置后，可动态调整门限值并选择签名者，无需额外交互。\n- **支持通用访问策略**：特别地，方案原生支持带权重的门限策略，且在性能开销上与标准门限设置相比无额外负担。\n- **强大的安全保证**：包括主动安全性（proactive security）和前向安全性（forward security）。\n\n我们在代数群模型（Algebraic Group Model）中证明了 hinTS 的安全性，并提供了开源实现。在避免使用分布式密钥生成（DKG）的所有已有方案中，hinTS 在签名聚合时间、签名大小和验证时间（以及其他定性指标）方面均表现最优。例如，当有 1000 个签名者时，hinTS 的签名聚合时间低于 0.5 秒，而签名和验证均为常数时间算法，分别仅需 1 毫秒和 17.5 毫秒。\n\n本工作的关键技术贡献在于设计了一种专用的简洁证明（succinct proofs），用于高效验证聚合公钥的格式正确性。我们的解决方案利用签名者在其公钥中公开的一组“提示”（hint）信息（这也是“hinTS”名称的由来），从而实现高效、安全的聚合验证。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/More is Merrier：Relax the Non-Collusion Assumption in Multi-Server PIR.pdf": {
        "title": "More is Merrier：Relax the Non-Collusion Assumption in Multi-Server PIR",
        "abstract": "长期以来，关于安全计算的研究已证实：任何可计算的问题，都可以通过一组不串谋的参与方实现安全计算。事实上，这种“非串谋”假设使得许多原本难以解决的问题变得可行，同时降低了计算开销，并绕开了某些计算复杂性上的理论障碍。该假设在众多隐私增强技术中广泛存在。然而，它仍然极易受到计算参与方之间隐蔽、难以察觉的串谋行为的影响。\n\n本项研究源于一个观察：如果可供调用的计算参与方数量远远超过完成安全计算任务所需的最少参与方数量，那么隐私保护计算中的串谋行为就可能被有效遏制。\n\n我们将研究重点聚焦于一种重要的隐私保护计算任务——多服务器1-私有信息检索（PIR），该任务本质上假设任意两个服务器之间不会串谋。在许多PIR应用场景中（例如区块链轻客户端），可用的服务器数量通常非常庞大。在这种背景下，单个服务器的偏离行为（如泄露信息或偏离协议）对其自身带来的收益并不显著。因此，我们可以通过设置小额奖励与惩罚机制，使偏离行为变得无利可图，从而显著提高系统对串谋的抵抗能力。\n\n我们设计并实现了一种串谋缓解机制，该机制基于一个具备支付执行功能的公共公告板，仅考虑理性参与方和恶意参与方，而不假设存在任何诚实且非串谋的服务器。该机制在查询执行完成后的一段时间内，仍能持续提供隐私保护。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/eAudit：A Fast, Scalable and Deployable Audit Data Collection System.pdf": {
        "title": "eAudit：A Fast, Scalable and Deployable Audit Data Collection System",
        "abstract": "当今先进的网络攻击活动通常能够绕过现有的所有防护措施。应对此类攻击的主要防御手段是事后检测，随后通过取证分析来评估其影响。这种分析依赖于审计日志（也称溯源日志），这些日志需要忠实地记录每台主机上的所有活动及数据流动。尽管Linux审计守护进程（auditd）和sysdig是目前最流行的审计数据收集工具，但还有许多由研究人员和实际从业者开发的其他系统也可供使用。通过一项具有启发性的实验研究，我们发现这些系统存在严重问题：它们会带来极高的性能开销，使工作负载速度降低2到8倍；在持续高负载下会丢失大部分事件；并且容易受到日志篡改攻击——攻击者可在日志写入持久存储前删除其条目。\n\n我们提出了一种全新的解决方案，克服了上述挑战。该方法基于近年来Linux内核中集成的扩展伯克利数据包过滤器（eBPF）框架，无需修改内核代码，因此我们的数据收集器可在大多数Linux发行版上开箱即用。我们提出了一系列新的设计、调优与优化技术，使系统能够承受比现有系统导致严重数据丢失时高出整整一个数量级的工作负载强度。此外，我们的系统仅产生原有系统一小部分的性能开销，同时显著减少了数据量，并将日志篡改窗口缩短了约100倍。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Loki：Large-scale Data Reconstruction Attack against Federated Learning through Model Manipulation.pdf": {
        "title": "Loki：Large-scale Data Reconstruction Attack against Federated Learning through Model Manipulation",
        "abstract": "联邦学习（Federated Learning）的提出旨在支持在大型去中心化数据集上进行机器学习，同时通过避免数据共享来保障用户隐私。然而，已有研究表明，共享的梯度中往往包含敏感信息，攻击者可以通过恶意修改模型架构和参数，或利用优化方法从共享梯度中反推出用户数据，从而获取隐私信息。\n\n然而，此前的数据重构攻击在应用场景和规模上均存在局限：大多数研究仅针对FedSGD（联邦随机梯度下降）设置，且攻击目标局限于单个客户端的梯度。在更贴近实际场景的FedAVG（联邦平均）设置下，或当更新通过安全聚合（Secure Aggregation）技术进行合并时，许多此类攻击便会失效。由于数据重构难度显著增加，导致攻击规模受限，或重构质量大幅下降。当同时采用FedAVG与安全聚合时，目前尚无方法能够在联邦学习环境中同时对多个客户端发起有效攻击。\n\n在本文中，我们提出了名为**LOKI**的攻击方法，突破了上述诸多限制。LOKI不仅能够成功实施攻击，还打破了聚合过程的匿名性——被泄露的数据可被明确识别，并能直接追溯到其原始客户端来源。我们的设计向客户端发送定制化的卷积参数，使得不同客户端数据点对应的权重梯度即使在聚合过程中仍能保持分离。在包含100个客户端的FedAVG设置下，现有方法在MNIST、CIFAR-100和Tiny ImageNet数据集上仅能泄露不到1%的图像数据；而LOKI仅需一次训练轮次，即可泄露全部数据样本的76%至86%。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/ERASan：Efficient Rust Address Sanitizer.pdf": {
        "title": "ERASan：Efficient Rust Address Sanitizer",
        "abstract": "——Rust 是一种快速发展的系统级编程语言，其执行速度可与传统的 C/C++ 系统编程语言相媲美，同时还具备一项关键优势：**保障内存安全**。然而，Rust 严格的内存安全规则使得某些功能的实现与执行变得困难。为解决这一问题，Rust 引入了“不安全 Rust”（unsafe Rust），它在一定程度上放宽了这些严格的安全限制。然而，在这些“不安全 Rust”代码中，由于未完全应用 Rust 的严格安全规则，可能导致**时间性（temporal）和空间性（spatial）内存错误**，据研究统计，这类错误占 2016 至 2023 年间报告的 Rust 程序漏洞总数的 22%。\n\n在本文中，我们提出一种专为 Rust 定制的高效内存地址消毒剂（address sanitizer）设计，名为 **ERASAN**，旨在比现有方法更高效地检测 Rust 程序中的内存错误。基于我们对 Rust 语言安全/不安全代码规范，以及近年来真实世界中 Rust 程序中出现内存错误的深入分析，我们设计并实现了 ERASAN，使其**仅对 Rust 无法保证内存安全的代码区域（包括安全和不安全代码）中的内存访问进行插桩（instrumentation）**，从而避免对已由 Rust 安全机制保护的部分进行冗余检查。\n\n我们使用多个真实世界的应用程序对 ERASAN 进行了评估。结果显示，ERASAN 平均**减少了 90.03% 的 ASan（AddressSanitizer）内存访问检查操作**。得益于此，ERASAN 显著降低了 ASan 的性能开销，平均性能开销减少达 **239.05%**（即性能提升超过两倍），同时并未削弱其发现内存错误的能力。\n\n---\n\n**说明与理解补充：**\n\n- **“不安全 Rust”**：是 Rust 中用于处理底层操作（如裸指针、FFI、硬件访问等）的机制，允许程序员绕过编译器的部分安全检查，但需由开发者自行确保安全性。\n- **时空内存错误**：\n  - **空间错误**：如缓冲区溢出（数组越界访问）；\n  - **时间错误**：如使用已释放内存（use-after-free）、双重释放（double-free）等。\n- **ERASAN 的核心思想**：传统 ASan 对所有内存访问进行插桩，而 ERASAN 利用 Rust 的类型系统和安全规则，**只对“可能不安全”的访问进行插桩**，从而大幅提升效率。\n- **239.05% 的性能开销降低**：表示性能提升显著，例如原 ASan 导致程序运行慢 3 倍，而 ERASAN 仅慢约 1.3 倍，性能接近原生运行。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/DPI：Ensuring Strict Differential Privacy for Infinite Data Streaming.pdf": {
        "title": "DPI：Ensuring Strict Differential Privacy for Infinite Data Streaming",
        "abstract": "——流数据对于诸如众包分析、行为研究和实时监控等应用至关重要，但由于与个人相关的大量且多样化的数据，其面临着严重的隐私风险。特别是，近期尝试以严格的差分隐私（Differential Privacy, DP）标准发布数据流时，遇到了隐私泄露无界的问题。这一挑战使得相关方法仅能适用于有限的时间段（即“有限数据流”），或退而求其次，仅保护事件本身（即“事件级差分隐私”或“w-事件差分隐私”），而非保护用户的所有记录。一个长期存在的挑战在于：当用户贡献大量活动数据且数据分布随时间不断演变时，如何有效控制输出对输入的敏感性。\n\n在本文中，我们提出了一种新颖的技术，称为“无限披露下的差分隐私数据流处理”（Differentially Private data streaming over Infinite disclosure, DPI），该技术能够在无限数据流场景下，有效约束每个用户的总隐私泄露量，同时支持精确的数据收集与分析。此外，我们还通过一种创新的增强（boosting）机制，最大化DPI的输出准确性。最后，我们在多种流数据应用场景和真实数据集（如新冠疫情数据、网络流量数据和USDA农业生产数据）上进行了广泛实验，结果表明，DPI在不同设定下均能为无限数据流提供高实用性的隐私保护。DPI的代码已公开，访问地址为：https://github.com/ShuyaFeng/DP。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/FlowMur：A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge.pdf": {
        "title": "FlowMur：A Stealthy and Practical Audio Backdoor Attack with Limited Knowledge",
        "abstract": "——基于深度神经网络（DNN）的语音识别系统通过语音接口彻底改变了人机交互方式，极大地方便了我们的日常生活。然而，随着这些系统日益普及，其安全性问题也引发了特别关注，尤其是后门攻击（backdoor attacks）问题。后门攻击是指在模型训练过程中，向深度神经网络模型中植入一个或多个隐藏的后门，使得模型在正常输入下仍能保持良好性能，但当输入中包含特定触发信号（trigger）时，模型会强制输出攻击者预设的结果。尽管当前音频后门攻击已初步取得成效，但仍存在以下局限：  \n（i）大多数攻击需要攻击者掌握大量先验知识，限制了其广泛应用；  \n（ii）攻击不够隐蔽，容易被人类察觉；  \n（iii）多数攻击无法针对实时语音（live speech）实施，实用性较低。\n\n为应对上述挑战，本文提出了一种名为 **FlowMur** 的隐蔽性强、实用性高的音频后门攻击方法，该方法可在攻击者知识有限的情况下实施。FlowMur 通过构建辅助数据集和替代模型（surrogate model）来扩充攻击者知识。为实现动态性，它将触发信号的生成建模为一个优化问题，并在不同的输入位置进行优化搜索。为增强隐蔽性，我们提出一种基于信噪比（SNR）的自适应数据投毒方法。此外，在触发信号生成和数据投毒过程中引入环境噪声，使 FlowMur 对真实环境中的背景噪声具有鲁棒性，从而提升其实际可用性。\n\n在两个公开数据集上进行的广泛实验表明，FlowMur 在数字环境（digital settings）和物理环境（physical settings）中均能实现高攻击成功率，同时对当前最先进的防御机制具有较强的抵抗能力。特别地，一项人类感知实验证实，FlowMur 生成的触发信号不易被人类参与者察觉。FlowMur 的源代码已开源，公开于：https://github.com/cristinalan/FlowMur。\n\n---  \n**第1节**（引言）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Revisiting Automotive Attack Surfaces：a Practitioners' Perspective.pdf": {
        "title": "Revisiting Automotive Attack Surfaces：a Practitioners' Perspective",
        "abstract": "随着现代汽车在外部攻击面和内部车载网络（IVN）拓扑结构方面日益复杂，确保其网络安全仍是一项重大挑战。现有的标准与法规，如联合国世界车辆法规协调论坛第155号法规（WP.29 R155e）和ISO/SAE 21434，试图为汽车网络安全建立基本准则，但这些规范是否足以应对不断演变的威胁仍不明确。为填补这一空白，我们首先对15位汽车网络安全领域的专家进行了深入访谈，揭示了他们在安全实践中遇到的具体挑战以及当前法规的局限性。\n\n从访谈数据中，我们归纳出20项关键洞见，涵盖现有汽车安全产业所面临的挑战与空白，以及当前法规的不足与改进建议。值得注意的是，我们发现现有法规所提供的威胁案例质量普遍不高，且由于缺乏自动化工具，威胁分析与风险评估（TARA）过程往往效率极低。\n\n针对上述问题，我们首先利用收集到的访谈数据，构建了一个更完善的汽车系统威胁数据库，在数量和质量上均对现有数据库实现了显著提升。此外，我们还提出了CarVal——一种基于Datalog（逻辑编程语言）的方法，旨在推断IVN中的多阶段攻击路径并计算风险值，从而显著提升TARA在汽车系统中的执行效率。\n\n通过在五辆真实车辆上应用CarVal，我们基于生成的攻击路径开展了全面的安全分析，并在采用新型网关分段设计的IVN中成功复现了相应的攻击链。这一过程揭示了一系列此前研究中未被充分覆盖的新型汽车攻击面，包括车载浏览器、官方移动应用程序、后端服务器以及车载恶意软件等。\n\n这些发现不仅突显了传统安全框架的盲区，也为未来汽车网络安全标准的优化和自动化工具的落地提供了重要依据。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Poisoned ChatGPT Finds Work for Idle Hands：Exploring Developers' Coding Practices with Insecure Suggestions from Poisoned AI Models.pdf": {
        "title": "Poisoned ChatGPT Finds Work for Idle Hands：Exploring Developers' Coding Practices with Insecure Suggestions from Poisoned AI Models",
        "abstract": "——以人工智能驱动的代码辅助工具（如 ChatGPT、Copilot 和 IntelliCode）已彻底改变了软件工程生态系统。然而，已有研究表明，这些工具容易受到“投毒攻击”（poisoning attacks）的威胁。在投毒攻击中，攻击者会故意将恶意构造的不安全代码片段注入训练数据集中，从而操控这些工具的行为。被污染的工具可能会向开发者推荐存在安全漏洞的代码，导致其开发的产品中出现可被攻击者利用的漏洞。然而，目前尚不清楚此类针对代码辅助工具的投毒攻击在现实场景中是否具有实际可行性，以及开发者在软件开发过程中如何应对这类攻击。\n\n为了深入理解投毒攻击对依赖AI代码辅助工具的开发者所产生的现实影响，我们开展了两项用户研究：一项在线问卷调查，以及一项实验室环境下的对照实验。\n\n在线问卷调查共收集了238名参与者的反馈，其中包括软件工程师和计算机科学专业的学生。调查结果显示，这类工具在参与者中已被广泛采用，主要目的是提升编码速度、消除重复劳动以及快速获取模板代码（boilerplate code）。然而，调查也发现，开发者在一定程度上对这些工具过度信任，普遍忽视了投毒攻击所带来的潜在风险。\n\n实验室研究则邀请了30名专业软件开发人员参与。研究人员要求他们在 Visual Studio Code 环境中，使用一种典型的AI代码辅助工具（如 ChatGPT 或 IntelliCode）完成三项编程任务。研究结果显示，使用被“投毒”的类 ChatGPT 工具的开发者，比使用类 IntelliCode 工具或完全不使用辅助工具的开发者，更有可能在代码中引入不安全的内容。这表明，AI代码辅助工具对生成代码的安全性具有显著影响，其建议可能潜移默化地引导开发者编写出存在漏洞的代码。\n\n我们的研究结果凸显了当前亟需加强开发者教育与改进编码实践，以应对由AI驱动的代码辅助工具所带来的新型安全挑战。开发者不仅需要意识到这些工具的潜在风险，还应培养批判性思维和主动审查AI建议的能力，从而在享受效率提升的同时，保障软件的安全性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Cohere：Managing Differential Privacy in Large Scale Systems.pdf": {
        "title": "Cohere：Managing Differential Privacy in Large Scale Systems",
        "abstract": "——随着隐私保护分析和隐私合规新系统的出现，当今系统中对隐私管理层的需求逐渐显现。为此，许多独立的研究工作纷纷涌现，试图为系统提供隐私支持。近年来，系统中所采用的隐私解决方案范围已扩展至更复杂的技术，例如差分隐私（Differential Privacy, DP）。然而，在大规模系统中应用这些技术带来了新的挑战和需求。为确保在各类异构应用和数据系统中持续保持隐私保障，必须进行周密的规划和协调。这需要全新的解决方案，用于管理和分配稀缺且不可再生的隐私资源。在本文中，我们介绍了 Cohere——一个简化差分隐私在大规模系统中应用的新系统。Cohere 实现了一个统一接口，使异构应用能够基于对用户数据的统一视图进行操作。在本研究中，我们进一步解决了实际部署中出现的两个紧迫的系统性挑战：一是确保基于隐私的应用的连续性（即防止隐私预算耗尽），二是在复杂的偏好条件下，对稀缺的共享隐私资源（即隐私预算）进行高效分配。实验表明，在面对多种复杂工作负载时，Cohere 相比现有最先进技术，在效用（utility）上实现了 6.4 到 28 倍的提升。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Nebula：A Privacy-First Platform for Data Backhaul.pdf": {
        "title": "Nebula：A Privacy-First Platform for Data Backhaul",
        "abstract": "设想一下，能够将一种小型、电池供电的设备部署到地球上几乎任何人类频繁出没的地方，并且它无需配置网络——无需购买实体网关、无需设置Wi-Fi密码、也无需获取蜂窝SIM卡——就能将数据发送到云端。这种能力将解决在几乎任何场景下部署大量小型、嵌入式、低功耗物联网（IoT）设备所面临的最大瓶颈之一。然而，如何将设备的部署与传输（即“回传”）传感器数据到云端所需的网络配置解耦，仍然是一个棘手的挑战。幸运的是，Tile和AirTag的成功为我们带来了希望。它们已经证明，手机可以通过众包的方式，在全球范围内构建本地网络覆盖，从而帮助寻找丢失物品。然而，若要将这类系统扩展为通用的数据回传网络，就会引发网络参与者对隐私的担忧。\n\n在本项工作中，我们提出了Nebula——一种以隐私为核心、面向全球、间歇性、低速率数据回传的系统架构，旨在让“万物”最终都能连接到云端，同时满足以下三个目标：  \n（i）通过去中心化的数据流设计，保护移动网络参与者的隐私，防止平台提供商窥探其信息；  \n（ii）通过微支付机制激励用户参与网络协作；  \n（iii）防止系统被滥用。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Measure-Observe-Remeasure：An Interactive Paradigm for Differentially-Private Exploratory Analysis.pdf": {
        "title": "Measure-Observe-Remeasure：An Interactive Paradigm for Differentially-Private Exploratory Analysis",
        "abstract": "——差分隐私（Differential Privacy, DP）具有在敏感数据上进行隐私保护分析的潜力，但要求分析人员谨慎地在多个查询之间分配有限的“隐私损失预算”ϵ。然而，在进行探索性分析时，分析人员通常无法提前预知所有查询，且往往缺乏差分隐私的专业知识。因此，他们难以在分析开始前就为每项查询合理分配ϵ。为了帮助分析人员更高效地分配和使用ϵ，我们提出了一种新的交互式分析范式：**测量—观察—再测量**（MEASURE-OBSERVE-REMEASURE）。在该范式中，分析人员首先以有限的ϵ“测量”数据库，观察估计结果及其误差，然后根据需要，使用更多ϵ进行“再测量”。\n\n我们将这一范式实现为一个交互式可视化界面，使分析人员可以在总体预算限制下逐步增加ϵ的使用。为了解分析人员如何通过该界面与“测量—观察—再测量”范式进行交互，我们开展了一项用户研究。研究中，我们比较了实际参与者在敏感数据上做出的ϵ分配策略及其分析结果，与面对相同决策任务的理性智能体（rational agent）所预期的分配策略和结果之间的效用差异。研究发现，参与者能够相对成功地使用该工作流程，包括采用一些能实现超过一半潜在最大效用的ϵ分配策略。与理性智能体相比，参与者的性能损失主要源于他们**无法充分获取信息并将其有效报告**，而不仅仅是ϵ分配能力不足。\n\n（第1节）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/MetaFly：Wireless Backhaul Interception via Aerial Wavefront Manipulation.pdf": {
        "title": "MetaFly：Wireless Backhaul Interception via Aerial Wavefront Manipulation",
        "abstract": "——无线回程链路已无处不在，并随着5G及未来通信技术的发展持续扩展，被广泛应用于诸多关键领域，例如华尔街的金融交易。在本研究中，我们首次揭示了这类链路极易受到一类新型空中超表面攻击的威胁。具体而言，我们展示了攻击者“夏娃”（Eve）如何设计并部署名为“MetaFly”的装置，通过隐秘地操控电磁信号的波前，实现对高度定向的无线回程链路的远程窃听。\n\n为深入剖析该攻击的原理，我们展示了夏娃如何在空中超表面界面引入预设的相位分布，从而生成用于窃听的衍射波束。我们还提出了一种基于波前自适应飞行优化的导航策略，使夏娃能够利用无人机的机动性，动态地调控辐射方向图，实现波束的实时塑形。我们进一步构建了MetaFly原型系统，实现了轻量化、低成本、透射式且无需额外供电的空中超表面设备。\n\n我们实施了该项攻击，并在大型室内中庭以及大城市中的室外屋顶环境中开展了一系列真实环境下的无线实验。实验结果表明，装备MetaFly的夏娃能够在几乎为零比特误码率（near-zero BER）的条件下成功截获回程链路传输内容，同时对合法通信造成的影响极小，几乎难以被察觉。\n\n本研究首次证实了空中超表面攻击对现代无线回程网络的现实威胁，揭示了其在隐蔽窃听方面的巨大潜力，为未来无线安全防御提出了新的挑战与研究方向。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Flash：A Comprehensive Approach to Intrusion Detection via Provenance Graph Representation Learning.pdf": {
        "title": "Flash：A Comprehensive Approach to Intrusion Detection via Provenance Graph Representation Learning",
        "abstract": "近年来，基于溯源的入侵检测系统（IDS）因其在检测复杂的高级持续性威胁（APT）攻击方面的潜力而日益受到关注。这类IDS利用从系统日志构建的溯源图（provenance graph）来识别潜在恶意行为。尽管前景广阔，但它们在准确性、实用性和可扩展性方面仍面临挑战，尤其是在处理大规模溯源图时。为此，我们提出了 **FLASH**，一种可扩展的入侵检测系统，通过图神经网络（GNN）在数据溯源图上进行图表示学习，以克服上述局限性。\n\nFLASH 采用基于 Word2Vec 的语义编码器，用于捕捉溯源图中的关键语义属性（例如进程名称和文件路径），以及事件之间的时序顺序。此外，FLASH 引入了一种新颖的、基于 GNN 的上下文编码器变体，能够高效地将局部和全局图结构编码为具有丰富表达能力的节点嵌入（node embeddings）。为了学习正常节点的行为模式，我们设计了一个轻量级分类器，融合 GNN 与 Word2Vec 生成的嵌入向量。\n\n鉴于 GNN 计算开销大、处理速度慢（尤其在处理大规模溯源图时），我们开发了一种**嵌入复用数据库**，用于存储训练阶段生成的节点嵌入。在系统运行时，轻量级分类器直接调用这些预存储的嵌入，无需重新生成 GNN 嵌入，从而实现了对 APT 攻击的实时检测。\n\n在真实数据集上的广泛实验表明，FLASH 在检测准确率方面优于现有的基于溯源的 IDS。实验结果还验证了 FLASH 具有良好的可扩展性、对模仿攻击（mimicry attacks）的鲁棒性，以及加快告警验证流程的潜力。\n\n---\n\n**1.**  \n（注：原文中“1.”可能为章节编号，此处保留以对应原文结构。）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/INVISILINE：Invisible Plausibly-Deniable Storage.pdf": {
        "title": "INVISILINE：Invisible Plausibly-Deniable Storage",
        "abstract": "可否认（Plausibly-Deniable, PD）存储系统允许用户在受到胁迫时，能够安全地隐藏数据，并在被要求提供加密密钥或密码时，合理地否认这些数据的存。然而，现有的PD系统通常需要专用的软件，这使得它们在那些起疑心的攻击者面前变得可检测——攻击者只需怀疑系统本身是否使用了PD技术即可发现问题。为解决这一根本性难题，我们提出并形式化定义了“可否认不可见性”（plausible invisibility）的概念，其目标是防止攻击者判断出是否从一开始就使用了PD系统。\n\n我们开发了 **INVISILINE**，这是一种具有可否认不可见性的系统，能够抵御“多快照攻击者”（multi-snapshot adversaries）——即能够多次访问设备的攻击者。为了保持不可见性，INVISILINE 采用了一种与 Linux 的 dm-crypt 磁盘加密子系统完全兼容的数据布局与编码方式，并将隐藏数据存储在 dm-crypt 用于加密公开数据时所使用的“初始化向量”（initialization vectors, IVs）中。\n\nINVISILINE 确保：当攻击者多次获取磁盘快照时，由于隐藏数据的修改所引发的任何磁盘变化，都能被合理地解释为仅由对公开数据的常规 dm-crypt 使用所导致的变化。在面对攻击者的情况下，用户仅需使用标准的 dm-crypt 工具，即可访问全部且仅访问公开数据，而不会暴露隐藏数据的存在。\n\nINVISILINE 能够在 1TB 的磁盘上安全且完全不可见地隐藏 19GB 的数据，且对公开数据的输入/输出（I/O）性能无影响；同时，写入隐藏数据的平均吞吐速度可达 4.5MB/s。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Bulkor：Enabling Bulk Loading for Path ORAM.pdf": {
        "title": "Bulkor：Enabling Bulk Loading for Path ORAM",
        "abstract": "——不经意随机访问存储器（Oblivious RAM, ORAM）是一种重要的密码学原语，旨在防止数据访问模式的信息泄露。随着近年来ORAM协议在理论上的不断改进，以及基于硬件的可信执行环境（Trusted Execution Environments, TEEs）的引入，ORAM正逐渐成为一种更具实用性的设计，并开始被广泛应用于现实世界的安全系统中。本文研究的是ORAM的“批量加载”（bulk loading）问题，即如何高效地构建一个包含大量数据的ORAM结构。这一能力对于安全云系统中的许多场景具有重要意义，例如数据恢复、布局转换和查询处理。\n\n我们提出了BULKOR，一种对当前最先进的Path ORAM协议的扩展方案。BULKOR支持在不可信服务器上结合TEEs进行部署，并满足“双重不经意性”（doubly-oblivious）要求，从而缓解现代TEE中存在的侧信道攻击隐患。BULKOR在不牺牲安全性的前提下，将ORAM批量加载的理论复杂度从O(N log³N) 降低到 O(N log²N)，同时显著提升了实际性能。在各种将ORAM实现在硬盘或内存中的测试场景下，BULKOR的性能分别比基准方案Oblix和ZeroTrace高出8.7倍至54.6倍，以及5.8倍至533.1倍。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Shedding Light on CVSS Scoring Inconsistencies：A User-Centric Study on Evaluating Widespread Security Vulnerabilities.pdf": {
        "title": "Shedding Light on CVSS Scoring Inconsistencies：A User-Centric Study on Evaluating Widespread Security Vulnerabilities",
        "abstract": "——通用漏洞评分系统（CVSS）  \n是漏洞管理中评估漏洞严重性的一种常用方法。在评估过程中，系统会计算出一个介于0到10之间的数值分数，其中10分代表最严重（即“严重危急”）的漏洞。CVSS的目标是为不同评估者提供可比较的评分标准。然而，已有研究表明，CVSS可能并未真正实现这一目标：当多个分析人员对同一漏洞进行评估时，他们给出的分数常常存在差异。这引发了一系列关键问题：CVSS的评估结果是否一致？哪些因素影响了CVSS的评分判断？为系统性地探讨这些问题，我们开展了一项针对196名CVSS使用者的在线调查。\n\n研究结果显示，对于某些广泛存在的漏洞类型——包括“2022年CWE最危险的25个软件弱点”榜单中排名前三的漏洞——CVSS中的特定评分指标（metrics）被不一致地评估。在一项后续调查中，我们邀请了59名参与者，针对主研究中出现的相同漏洞进行评分，结果发现，**68%的参与者在同一漏洞上给出了不同的严重性等级**。\n\n我们的研究表明，大多数评估者虽然已经意识到CVSS存在一些问题和局限性，但仍然认为CVSS是漏洞评估中一个有用的工具。最后，我们深入分析了导致评分不一致的可能原因，并提出了若干改进建议，旨在提升CVSS评分的一致性与可靠性。\n\n（注：CWE 即 Common Weakness Enumeration，通用缺陷枚举，是软件安全领域中用于分类和描述软件安全弱点的标准列表。）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Injection Attacks Against End-to-End Encrypted Applications.pdf": {
        "title": "Injection Attacks Against End-to-End Encrypted Applications",
        "abstract": "我们探讨了一种针对端到端（E2E）加密应用的新兴威胁模型：攻击者向目标客户端发送精心选择的特定消息，从而将恶意内容“注入”应用状态中。这些状态随后会被加密，并同步到攻击者可见的云存储空间。通过观察云端存储的密文长度，攻击者可逆向推导出其中的机密信息。\n\n我们针对支持端到端加密备份的主流加密消息应用，研究了这种“注入”威胁模型。我们展示了概念验证攻击，在假设攻击者能够入侵目标用户的Google或Apple账户（从而获得其加密备份）的前提下，可恢复通过WhatsApp发送的端到端加密消息或附件的相关信息。此外，我们还揭示了Signal加密备份设计中的弱点：一旦攻击者以某种方式获取了用户的加密Signal备份，便可通过注入攻击推断出包括用户联系人数量、对话数量等在内的元数据。\n\n尽管我们认为当前这些研究结果尚不足以对用户构成直接威胁，但它们确实表明，要构建真正具备强大端到端安全保证的工具，仍需开展更多工作。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/BELT：Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting.pdf": {
        "title": "BELT：Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting",
        "abstract": "——深度神经网络（DNNs）容易受到后门攻击（backdoor attacks）的威胁：攻击者通过向模型中植入恶意功能，使其在特定触发条件下产生错误的分类结果。传统的后门攻击通常使用强触发特征（strong trigger features），这些特征容易被受害者模型学习并识别。尽管这类攻击对输入变化具有一定的鲁棒性，但这种鲁棒性反而增加了**非预期触发激活**的可能性——即，即使输入中仅包含与原始触发相似的特征，也可能意外激活后门。这为现有的防御机制留下了可追踪的“痕迹”。例如，一些防御方法（如逆向工程或样本叠加）能够通过寻找原始触发特征的近似替代方案，在不完全复制原始触发的情况下激活后门，从而识别出被感染模型。\n\n在本文中，我们提出并研究后门攻击的一种新特性，称为**后门排他性**（backdoor exclusivity），它衡量的是：当输入发生一定变化时，后门触发器仍能保持有效激活能力的程度。基于“后门排他性”这一概念，我们提出了一种新型技术——**后门排他性提升**（Backdoor Exclusivity LifTing, BELT）。BELT 的核心思想是通过抑制后门与“模糊触发器”（fuzzy triggers）之间的关联，来增强后门排他性，从而实现更有效的防御规避。\n\n我们在三个主流的后门攻击基准数据集上进行了广泛实验，结果表明：BELT 显著提升了四种传统后门攻击的**隐蔽性**。经过“后门排他性提升”处理后，这些攻击能够成功规避七种当前最先进的后门防御机制，且在攻击成功率和模型正常功能（normal utility）方面几乎未造成任何损失。例如，早期经典后门攻击方法 BadNet，在引入 BELT 技术后，成功规避了包括 ABS 和 MOTH 在内的多种先进防御手段——而这些防御方法原本能够有效识别出被 BadNet 攻击的模型。\n\n综上，BELT 为后门攻击提供了一种新的优化方向：通过增强触发机制的“排他性”，使后门更难被逆向工程或相似触发检测所发现，从而在保持高攻击成功率的同时，极大提升攻击的隐蔽性与生存能力。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Patchy Performance. Uncovering the Vulnerability Management Practices of IoT-Centric Vendors.pdf": {
        "title": "Patchy Performance. Uncovering the Vulnerability Management Practices of IoT-Centric Vendors",
        "abstract": "物联网（IoT）安全问题的长期存在，已促使研究人员和各国政府将关注点转向设备供应商所扮演的角色。安全领域早已对“供应商在安全和隐私方面表现失职”这一反复出现的论断耳熟能详，大量研究论文也揭示了IoT产品中的诸多漏洞。那么，专注于物联网的供应商是否比其他行业的供应商表现更差？要回答这个问题，我们不能仅仅统计各供应商公开披露的漏洞数量。在本研究中，我们分析了影响各供应商漏洞数量的多方面因素，例如企业规模、所在地以及是否具备漏洞披露政策。在此基础上，我们通过统计方法控制这些干扰因素，评估以物联网为核心的供应商是否会产生更多漏洞。结果表明，确实如此。\n\n我们还可以通过观察供应商的漏洞修补行为，更直接地评估其安全表现。为此，我们收集了涵盖104家领先供应商、共2,741个物联网与非物联网漏洞的补丁可用性与及时性的独特数据集，同时收集了一系列可能影响供应商补丁发布表现的因素数据。基于此，我们建立了一个统计模型，用以解释为何某些供应商的安全响应优于其他供应商。研究发现，以物联网为核心的供应商在漏洞补丁发布方面并不比其他供应商差；事实上，他们按时发布补丁的频率反而更高。\n\n本研究加深了我们对影响物联网安全关键因素的理解，并为旨在提升IoT供应商安全表现的政策干预措施提供了实证依据。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/AFGen：Whole-Function Fuzzing for Applications and Libraries.pdf": {
        "title": "AFGen：Whole-Function Fuzzing for Applications and Libraries",
        "abstract": "——模糊测试（Fuzzing）技术已被广泛用于发现软件漏洞，但现有的模糊测试方法仍难以全面覆盖和深入探索应用程序或库中的所有函数。目前已有一些工作致力于自动为库的API函数生成模糊测试驱动（fuzzing harness），从而直接测试目标函数。然而，将这些方法应用于项目中任意内部函数（例如库的内部函数）仍面临巨大挑战。具体而言，API函数的调用上下文通常对用户而言简单且清晰，而内部函数往往存在复杂的依赖关系，导致其运行上下文更加复杂，且对参数有诸多约束条件，这使得高效生成模糊测试驱动变得十分困难。\n\n在本文中，我们提出了一种“自底向上”的**全函数模糊测试**（whole-function fuzzing）方法，旨在通过覆盖所有函数来对应用程序和库进行模糊测试。我们认为，即使以一定的精确性为代价，若能实现全函数覆盖，并对这种代价通过精巧的设计加以缓解，仍将对漏洞发现大有裨益。为此，我们设计并实现了 **AFGEN** 框架，用于实现自动化的全函数模糊测试。给定一个目标函数，AFGEN 能够生成一个模糊测试驱动，该驱动可在适当的初始程序上下文中执行并到达目标函数；同时，AFGEN 还能根据已发现崩溃所揭示的约束条件，不断迭代优化测试驱动。\n\n具体来说，AFGEN 基于控制流和数据流依赖关系，对目标函数的调用语句进行切片（slicing）；根据切片中涉及的变量类型，为其分配初始值；并进一步搜索与崩溃相关的变量所对应的约束语句，以动态调整输入。通过这种方式，AFGEN 能够生成误报率较低的模糊测试驱动。\n\n为了验证 AFGEN 的有效性，我们从 11 个开源项目中收集了 102 个已知漏洞。实验表明，AFGEN 成功为所有存在漏洞的函数生成了模糊测试驱动，并从中识别出 66 个漏洞，性能显著优于所有对比工具，发现漏洞数量是排名第二的模糊测试工具（AFL++）的两倍。AFGEN 触发的崩溃具有 77.1% 的精确率（precision），是 FUDGE 工具精确率的 10 倍。此外，AFGEN 还发现了 24 个此前未知的漏洞，均已获得 CVE 编号确认。\n\n†共同第一作者。∗通讯作者。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/BounceAttack：A Query-Efficient Decision-based Adversarial Attack by Bouncing into the Wild.pdf": {
        "title": "BounceAttack：A Query-Efficient Decision-based Adversarial Attack by Bouncing into the Wild",
        "abstract": "——深度神经网络容易受到对抗性攻击。我们研究了在基于决策的黑盒攻击场景下的此类威胁，在这种设定中，攻击者仅能通过有限的查询次数获取受害者分类器的预测标签，并试图在不同的扰动约束下实施有针对性的（targeted）和无目标的（untargeted）对抗攻击。本文提出了一种查询高效的攻击方法——BounceAttack。我们提出了“反弹向量”（bounce vector）的概念，该向量能够引导迭代过程在有限的查询次数内，最大程度地探索对抗样本空间，从而更高效地逼近最优对抗样本，显著提升查询效率。我们在多个基准数据集和模型上进行了广泛的实验，结果表明，BounceAttack 在保持高查询效率的同时，还能生成扰动更小的对抗样本，整体性能优于现有攻击方法。例如，在相同数量的模型查询条件下，BounceAttack 所生成的对抗样本平均扰动比当前最先进的攻击方法小 48.1%。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Text-CRS：A Generalized Certified Robustness Framework against Textual Adversarial Attacks.pdf": {
        "title": "Text-CRS：A Generalized Certified Robustness Framework against Textual Adversarial Attacks",
        "abstract": "语言模型，尤其是基础的文本分类模型，已被证明容易受到文本对抗攻击的影响，例如同义词替换和词语插入等攻击。为防御此类攻击，越来越多的研究致力于提升模型的鲁棒性。然而，目前大多数工作仍聚焦于经验性鲁棒性（empirical robustness），而提供可证明的鲁棒性保障（provable robustness guarantees）这一方向仍远未充分探索。\n\n在本文中，我们提出了Text-CRS——一种基于随机平滑（randomized smoothing）的自然语言处理（NLP）可证明鲁棒性通用框架。据我们所知，现有针对NLP的可证明鲁棒性方案仅能针对同义词替换攻击中的ℓ₀扰动（即词语替换的数量）提供鲁棒性认证。为此，我们将每种词级别对抗操作（如同义词替换、词语重排序、插入和删除）统一表示为排列变换（permutation）与嵌入变换（embedding transformation）的组合，并提出了新颖的平滑定理，以在排列空间和嵌入空间中针对这些对抗操作推导出鲁棒性边界。\n\n为进一步提升可证明的准确率与鲁棒半径（certified accuracy and radius），我们考虑了离散词语之间的数值关系，并精心选择了适用于随机平滑的噪声分布。最后，我们在多种语言模型和数据集上进行了大量实验。实验结果表明，Text-CRS能够有效应对全部四种不同的词级别对抗操作，并显著提升了可证明准确率。此外，我们首次构建了涵盖四种词级别操作的可证明准确率与鲁棒半径的基准评估体系；在针对同义词替换攻击的认证性能上，Text-CRS也超越了当前最先进的可证明鲁棒性方法。¹\n\n---\n\n¹ 注：本工作首次系统性地解决了多种词级别对抗操作的可证明鲁棒性问题，并为后续研究提供了重要的基准与参考。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：Explainable Machine Learning in Adversarial Environments.pdf": {
        "title": "SoK：Explainable Machine Learning in Adversarial Environments",
        "abstract": "长期以来，现代深度学习方法因其决策过程缺乏可解释性而被视为“黑箱”。然而，近年来可解释机器学习（Explainable Machine Learning）的进展改变了这一局面。事后解释方法（post-hoc explanation methods）能够为深度神经网络等原本不透明的模型提供输入特征的相关性归因，实现精准解释。这一进展引发了人们的期待：这些技术或可揭示针对学习型系统的攻击手段，例如对抗样本（adversarial examples）或神经后门（neural backdoors）。但不幸的是，当前的事后解释方法本身并不具备对抗恶意操纵的鲁棒性。\n\n在本文中，我们旨在系统性地梳理针对事后解释方法的攻击方式，为构建更加鲁棒的可解释机器学习奠定基础。如果解释方法能够抵御攻击者的误导，它们便可成为抵御恶意攻击的有力工具，从而在对抗性机器学习领域实现一个关键转折点。我们提出了一个关于“解释感知的鲁棒性”（explanation-aware robustness）的分层概念框架，并将现有的防御方法与之对应。通过这一分析，我们揭示了不同方法之间的协同效应、研究空白以及未来发展方向，推动实现更可靠、更抗操纵的模型解释技术。\n\n关键词：可解释机器学习，XAI，攻击，防御，鲁棒性概念"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Targeted and Troublesome：Tracking and Advertising on Children's Websites.pdf": {
        "title": "Targeted and Troublesome：Tracking and Advertising on Children's Websites",
        "abstract": "在现代互联网中，追踪器和广告商常常在未经用户同意的情况下，构建并从中牟利用户的详细行为画像。尽管已有大量关于网页追踪机制和广告技术的研究，但此前尚无一项严谨研究专门针对面向儿童的网站。为填补这一空白，我们对面向儿童的网站上的追踪行为及（定向）广告进行了系统性测量分析。\n\n由于缺乏一份全面的、专门针对儿童的网站列表，我们首先基于网页标题和描述，构建了一个多语言分类器。将该分类器应用于来自“Common Crawl”数据集的超过两百万个网页后，我们筛选出两千个面向儿童的网站。随后，我们从五个不同的地理位置视角对这些网站进行爬取，测量其中追踪器、指纹识别脚本以及广告的普遍程度。我们的爬虫能够检测出显示在儿童网站上的广告，并通过抓取广告披露页面（如可用）来判断是否启用了广告定向投放功能。\n\n研究结果表明，约90%的面向儿童的网站嵌入了至少一个追踪器，约27%的网站包含定向广告——而此类行为依法应获得可验证的父母同意。\n\n接下来，我们通过开发一个可处理广告中图像和文本的机器学习（ML）流水线，识别出面向儿童网站上的不当广告。该流水线支持对任意关键词进行语义相似性检索，揭示了推广约会服务、减肥产品、心理健康服务、性玩具以及调情聊天服务等的广告。其中一些广告甚至包含令人反感、露骨且极不适宜的色情图像。\n\n综上所述，我们的发现表明，许多广告商和面向儿童的网站普遍存在违反隐私法规的趋势，且广告内容安全实践令人担忧。为确保儿童得到切实保护，并营造更安全的网络环境，监管机构及利益相关方必须采取并强制执行更严格的监管措施。\n\n关键词：在线追踪，广告，儿童，隐私"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Understanding Parents' Perceptions and Practices Toward Children's Security and Privacy in Virtual Reality.pdf": {
        "title": "Understanding Parents' Perceptions and Practices Toward Children's Security and Privacy in Virtual Reality",
        "abstract": "近年来，虚拟现实（VR）中的未成年人用户数量急剧增加，而随之而来的安全与隐私（S&P）风险，例如数据监控以及在社交互动中的自我暴露等问题也日益凸显。已有研究表明，儿童在技术使用过程中主要依赖父母来降低安全与隐私风险。因此，了解父母在安全与隐私方面的知识水平、认知态度和实践行为，对于识别父母、技术设计者和政策制定者在保护儿童安全与隐私方面存在的不足至关重要。尽管在其他消费类技术领域中，此类实证研究已较为丰富，但在虚拟现实（VR）这一特定场景下，相关认知仍十分有限。\n\n为填补这一研究空白，我们对20位家中有18岁以下儿童使用VR设备的父母进行了深入的半结构化访谈。研究发现，父母普遍缺乏对VR安全与隐私风险的意识，这主要源于他们认为VR技术仍处于“发展初期”的固有观念。目前，为了保护孩子在使用VR时的安全，父母主要依赖主动策略，例如通过口头教育向孩子灌输安全与隐私知识。而被动策略（如在VR系统中使用家长控制功能）在受访者中并不普遍，主要原因在于他们普遍认为这些技术手段存在操作复杂、功能有限等“技术性障碍”。\n\n此外，受访父母强调，必须建立一个多方参与的生态系统，才能为儿童在VR环境中的安全与隐私提供更有效的支持。基于上述发现，我们向关键利益相关方提出了切实可行的安全与隐私改进建议，涵盖父母、教育工作者、VR企业以及政府部门等多个主体。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Can we cast a ballot as intended and be receipt free.pdf": {
        "title": "Can we cast a ballot as intended and be receipt free",
        "abstract": "本文探讨了“无收据性”（receipt-freeness）与“按意图投票可验证性”（cast-as-intended verifiability）之间的相互作用，这一特性在以往的无收据投票协议中一直被忽视，或仅被假定为通过程序性手段即可实现。我们首先证明：在非交互式投票过程中，除非存在可信权威机构，否则无法构建同时具备无收据性和按意图投票可验证性的投票协议。我们还证明，如果存在一个可信的用户注册权威机构，则上述两个安全属性均可实现。\n\n进一步地，在将标准的无收据性安全定义扩展到交互式投票（及腐败攻击）场景后，我们证明：通过交互式投票过程，同样可以获得上述安全属性。\n\n最后，我们基于原型实现，对所提出协议的性能进行了分析与讨论。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SrcMarker：Dual-Channel Source Code Watermarking via Scalable Code Transformations.pdf": {
        "title": "SrcMarker：Dual-Channel Source Code Watermarking via Scalable Code Transformations",
        "abstract": "——开源社区的不断扩张以及大型语言模型的兴起，引发了人们对源代码分发所涉及的伦理与安全问题的高度关注，例如对受版权保护代码的违规使用、未遵循适当许可证的分发行为，以及将代码用于恶意目的等。因此，追踪源代码的所有权变得至关重要，而水印技术正是实现这一目标的主要手段。然而，与自然语言截然不同，源代码水印技术需要更加严格和复杂的规则，以确保代码的可读性与功能性不受影响。为此，我们提出了 SrcMarker，这是一种能够在源代码中隐式嵌入 ID 比特串的水印系统，且不会改变代码的实际用途和语义。\n\n为实现这一目标，SrcMarker 对基于抽象语法树（AST）的中间表示进行变换，从而支持跨多种编程语言的统一处理。该系统的核心采用基于学习的嵌入与提取模块，用于从一系列基于规则的变换中选择最合适的操作进行水印嵌入。此外，我们还设计了一种新颖的“特征近似”技术，以解决规则选择过程中固有的不可微问题，从而将基于规则的变换与基于学习的神经网络无缝融合，构建成一个可端到端训练的互连系统。\n\n大量实验表明，SrcMarker 在多种水印需求场景下，性能均优于现有方法，展现出显著的优势。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/The Inventory is Dark and Full of Misinformation：Understanding Ad Inventory Pooling in the Ad-Tech Supply Chain.pdf": {
        "title": "The Inventory is Dark and Full of Misinformation：Understanding Ad Inventory Pooling in the Ad-Tech Supply Chain",
        "abstract": "广告技术（Ad-tech）使发布商能够通过一个复杂的供应链，以程序化方式将其广告库存出售给数以百万计的需求方合作伙伴。然而，广告技术供应链的复杂性和不透明性，可能被低质量发布商（例如传播虚假信息的网站）利用，通过欺骗性手段将其广告库存变现。为应对此类欺诈行为，广告技术行业已制定了透明度标准，并推出了品牌安全产品。在本文中，我们指出，这些措施仍不足以有效防止欺骗性变现行为。\n\n具体而言，我们重点关注发布商如何通过将自身广告库存与不相关的网站聚合，来利用广告技术供应链、规避广告技术的透明度标准，并削弱品牌安全保护机制。这种欺骗行为被称为“暗池”（dark pooling）。我们的研究表明，虚假信息发布商在多个主流广告交易平台中普遍采用暗池策略，借此向知名品牌商进行欺骗性广告投放交易。\n\n我们的工作表明，亟需加强对广告交易平台供应链合作伙伴的资质审查，采用能够实现对广告技术供应链端到端验证的新型透明度标准，并广泛推行如本文所采用的独立审计机制，以有效遏制此类系统性漏洞。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/POMABuster：Detecting Price Oracle Manipulation Attacks in Decentralized Finance.pdf": {
        "title": "POMABuster：Detecting Price Oracle Manipulation Attacks in Decentralized Finance",
        "abstract": "——价格预言机操纵攻击（Price Oracle Manipulation Attacks, POMAs）在区块链系统中日益频繁，造成了巨大的经济损失。此前关于检测POMA的研究仅关注单笔交易攻击，即整个攻击行为被包含在单一交易中。我们系统性地研究了以太坊等区块链系统中的POMA，发现跨多笔交易的POMA攻击已变得远比单笔交易攻击更为常见。因此，亟需一个能够检测跨多笔交易POMA的通用框架。此外，我们不应再依赖过去攻击模式（如先前研究所做的那样），而应提出适用于检测POMA的通用规则。\n\n我们首先基于传统股票市场中的操纵攻击行为，推导出检测POMA的“第一性原理”规则。随后，我们提出POMABuster——一个利用这些规则来检测单笔和多笔交易POMA的系统。POMABuster通过识别POMA攻击者行为中的共性特征，对其检测机制进行优化。我们使用区块链中2.5年的交易数据，以及从Code4rena审计报告整理的数据集对POMABuster进行了评估。\n\n实验结果表明，POMABuster检测到的POMA数量是此前研究的近6.5倍。此外，POMABuster在最坏情况下的误报率仅为1%，且漏报率为零，这两项指标均显著优于现有方法。\n\n**关键词**——以太坊，去中心化金融，价格预言机操纵攻击"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：Safer Digital-Safety Research Involving At-Risk Users.pdf": {
        "title": "SoK：Safer Digital-Safety Research Involving At-Risk Users",
        "abstract": "——针对高风险用户的研究——即那些更可能遭受网络攻击，或在遭受攻击时受到更严重伤害的用户——可能对用户和研究人员自身都带来重大的安全挑战。然而，开展计算机安全与隐私（S&P）领域的研究，对于理解如何满足高风险用户的数字安全需求，并为所有人设计更安全的科技产品至关重要。为了规范并加强针对这类用户的更安全研究，我们对196项学术成果进行了分析，归纳出14种研究风险以及由日益壮大的研究群体所采用的36项安全实践。我们将这些报告中不一致的安全实践，与来自12位领域专家的深度访谈（口述历史）相结合，提出了一套结构清晰、整合统一的实用指导框架，帮助研究人员在规划、执行和分享涉及高风险用户的数字安全研究时，能够更安全地开展工作。最后，我们提出了未来在有关高风险用户研究的报告、研究设计以及资金支持等方面值得进一步探索的研究方向。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Do You Play It by the Books. A Study on Incident Response Playbooks and Influencing Factors.pdf": {
        "title": "Do You Play It by the Books. A Study on Incident Response Playbooks and Influencing Factors",
        "abstract": "——“事件响应‘剧本’（playbooks）”是组织为指导和规范人员或机器应对网络安全威胁而制定的一套结构化的操作流程。这些剧本通常结合了关于特定威胁的技术信息，以及与组织自身相关的内部背景因素。这两类信息对于剧本的部署、维护以及在组织之间的共享都至关重要，因为它们确保了响应措施的有效性以及信息的保密性。\n\n尽管安全从业者在实践中对剧本表现出极大兴趣，但从学术研究的角度，剧本本身的特性尚未得到系统深入的探讨。为此，我们通过分析“剧本里到底包含什么内容”来展开研究。我们的研究方法包括：对现有数据进行全面的实证分析（涵盖1217个剧本）、一项包含147名参与者的在线调查，以及对9名安全专业人士进行的深度访谈，以进一步整合并验证研究发现。\n\n我们特别发现，从业者和组织在定义“剧本”时存在内在的模糊性和不一致性。此外，现有的剧本并不能直接拿来即用，这种“通用性缺失”可能在当前阻碍了不同网络安全主体之间的广泛采用。因此，我们可以得出结论：虽然各组织确实是在“照章办事”（play it by the books），但它们各自对“剧本中应包含什么内容”以及“应覆盖事件响应的哪些环节”有着不同的理解和定义。换言之，每个组织都在根据自身需求，独立构建其专属的事件响应剧本。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/The Times They Are A-Changin'：Characterizing Post-Publication Changes to Online News.pdf": {
        "title": "The Times They Are A-Changin'：Characterizing Post-Publication Changes to Online News",
        "abstract": "无"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/UnTrustZone：Systematic Accelerated Aging to Expose On-chip Secrets.pdf": {
        "title": "UnTrustZone：Systematic Accelerated Aging to Expose On-chip Secrets",
        "abstract": "随着技术制程的持续微缩，社会正日益接近“智能尘埃”（smart dust）的愿景，但与此同时，系统设计师也必须应对物理攻击的威胁。为应对计算设备被物理接触的风险，防御者通常将敏感信息保留在芯片内部，使其难以被非国家级攻击者获取。现代系统引入了由硬件支持的安全隔离环境，即“可信执行环境”（Trusted Execution Environments, TEEs）。TEE 在“将密钥等秘密信息保留在芯片上”的基础上，进一步增加了硬件级保护机制，从而抵御来自特权软件以及软件非可信组件中潜在漏洞的攻击。尽管目前最优秀的 TEE 能够防范并发性或短期存在的物理攻击（例如冷启动攻击），但我们发现了一种对所有形式的片上加密都构成威胁的新问题：**长期数据残留**（long-term data remanence）。\n\n我们发现，最普遍的片上存储形式——静态随机存取存储器（SRAM）——在软件使用过程中，其模拟域（analog-domain）特性会随着所存储数据的模式发生与数据相关的物理变化。在正常情况下，这些变化是随着设备使用年限逐渐发生的。但我们证明，攻击者可以系统地加速 SRAM 模拟域中的这种“数据烙印”（data imprinting）过程，从而有效地将片上秘密信息“烧录”进硬件。随后，攻击者可通过测量 SRAM 上电初始状态（power-on state）来提取这些被烙印的信息。\n\n我们利用这一技术实现了三种攻击：  \n1. 提取受 TrustZone 保护的 AES 加密密钥；  \n2. 恢复受 TrustZone 保护的商业专有固件；  \n3. 获取缓存中存储的敏感秘密信息。\n\n总体而言，我们在来自 8 家厂商、跨越三十年制造的 13 款设备中，对多种基于 SRAM 的存储器成功实现了秘密信息的“烙印”与“提取”，准确率高达 98%。为应对这一新威胁，我们进一步为芯片制造商和程序员提供了在防御层面的权衡建议与指导方案。\n\n---\n\n**第1节（引言）核心要点总结：**  \n本研究揭示了一个被长期忽视的安全隐患：即使秘密信息被妥善保存在芯片内部并由 TEE 保护，SRAM 的物理特性仍可能导致数据以“模拟烙印”的形式长期残留。攻击者无需侵入软件或操作系统，只需在设备被物理接触后，通过分析 SRAM 上电时的初始状态，即可恢复出长期驻留的数据。这种攻击方式突破了传统硬件安全假设，对 TEE、加密密钥管理、固件保护等机制构成了根本性挑战。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Practical Obfuscation of BLE Physical-Layer Fingerprints on Mobile Devices.pdf": {
        "title": "Practical Obfuscation of BLE Physical-Layer Fingerprints on Mobile Devices",
        "abstract": "移动设备会持续广播蓝牙低功耗（BLE）广告数据包。这带来了攻击者通过嗅探其BLE信号来识别和追踪设备的威胁。为缓解这一威胁，大多数BLE发射器已在链路层部署了MAC地址随机化技术。然而，攻击者仍能利用由无线芯片制造过程中的微小缺陷所导致的底层物理层指纹，绕过MAC地址随机化进行设备识别。在本文中，我们提出了一种实用且有效的物理层硬件缺陷指纹混淆方法。通过理论分析、仿真实验和实际场景测试，我们设计并评估了该硬件缺陷混淆方案。基于对数千台BLE设备数据的分析，我们证明该混淆技术显著降低了识别目标设备的准确率。即使攻击者连续24小时对目标进行观测，此类攻击也难以成功。此外，我们通过在商用BLE芯片组上仅修改固件的方式实现了该防御方案，从而验证了其在实际部署中的可行性。\n\n（说明：译文在保持技术准确性的前提下，对部分措辞进行了优化，例如：\n1. \"beacon\"译为\"广播\"更符合通信领域术语\n2. \"manufacturing imperfections\"译为\"制造缺陷\"而非字面直译的\"不完美\"，突出工程语境\n3. \"obfuscating\"译为\"混淆\"准确传达其技术含义（通过干扰特征使识别失效）\n4. 将长句合理切分为符合中文表达习惯的短句\n5. \"commodity BLE chipsets\"译为\"商用BLE芯片组\"，强调其市场普及性而非简单翻译为\"商品\"）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Everything is Good for Something：Counterexample-Guided Directed Fuzzing via Likely Invariant Inference.pdf": {
        "title": "Everything is Good for Something：Counterexample-Guided Directed Fuzzing via Likely Invariant Inference",
        "abstract": "——定向模糊测试（directed fuzzing）展现出在复现缺陷报告、验证补丁以及调试漏洞方面的巨大潜力。当前最先进的定向模糊测试工具会对更可能触发目标漏洞的输入赋予更高优先级，或过滤掉与目标无关的输入。尽管如此，现有方法在复现特定漏洞时仍面临困难，因为大多数生成的输入都是无关的。例如，在Magma基准测试中，超过94%的生成输入未能命中目标漏洞。我们将这一挑战称为**间接输入生成问题**。\n\n我们提出通过约束输入生成过程，来提高能够到达目标位置的输入产出率。我们的核心思想是：从已执行的可达和不可达输入中，推断出可能的不变量（invariants），从而限制后续输入生成的搜索空间，生成更多可达的输入。此外，我们提出了两种选择策略：一是最小化用于不变量推断的不必要输入比例，以提高推断效率；二是降低不精确不变量的优先级，以提升输入生成的有效性。\n\nHalo是我们实现的原型系统，在复现目标漏洞方面，相比当前最先进的定向模糊测试工具，实现了15.3倍的加速，并生成了6.2倍更多的可达输入。在评估过程中，我们还发现了10个此前未知的缺陷，涉及7个在广泛测试过的目标程序最新版本中尚未完全修复的补丁问题。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Certifying Zero-Knowledge Circuits with Refinement Types.pdf": {
        "title": "Certifying Zero-Knowledge Circuits with Refinement Types",
        "abstract": "——零知识（ZK）证明系统已成为构建安全敏感型应用的一种极具前景的解决方案。然而，ZK应用中的程序错误极难被发现，攻击者可借此恶意利用系统，且不留下任何可察觉的痕迹。本文提出了C ODA，一种用于构建零知识应用的新型静态类型语言。关键的是，C ODA通过一个丰富的细化类型系统（refinement type system），使得对ZK应用的属性进行形式化规约和静态检查成为可能。\n\n形式化验证ZK应用面临的一个核心挑战在于：这类应用需要在大素数域上进行多项式方程的推理，其复杂性已超出自动化定理证明工具的处理能力。C ODA通过生成一系列可在交互式环境中、借助策略库（tactic library）进行证明的Coq引理，有效缓解了这一难题。\n\n我们使用C ODA重新实现了来自广泛使用的Circom库和应用的77个算术电路。评估结果表明，C ODA能够对这些电路的关键属性进行形式化规约，并验证其正确性。此外，评估过程中还发现了原始Circom项目中的6个此前未知的安全漏洞。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Pianist：Scalable zkRollups via Fully Distributed Zero-Knowledge Proofs.pdf": {
        "title": "Pianist：Scalable zkRollups via Fully Distributed Zero-Knowledge Proofs",
        "abstract": "在过去十年中，区块链技术涌现出众多金融与技术创新，加密货币的总市值一度突破1万亿美元。然而，**可扩展性**仍然是阻碍区块链在多种应用场景中广泛部署的关键问题之一。为了提高交易吞吐量，基于**零知识证明（ZKP）**这一密码学原语的**zkRollups**和**zkEVM**技术被提出，并已被许多公司广泛应用于二层（Layer-2）扩容解决方案中。然而，在这些技术中，**ZKP的证明生成过程成为主要瓶颈**，企业通常需要部署内存高达TB级的强大机器，才能将大量交易批量打包进一个ZKP中。\n\n在本文中，我们通过提出**全新的完全分布式零知识证明方案**，显著提升了这些技术的可扩展性。我们的方案利用多台机器协作生成ZKP，极大提升了效率与可扩展性，同时**机器之间的通信开销极低**。借助我们的方案，ZKP的生成过程可以被分发到多个参与者中，其协作模式类似于比特币中的“矿池”机制。\n\n我们的协议基于**Plonk**——一种具有通用可信设置的高效零知识证明系统。第一个协议适用于**数据并行电路**：对于一个包含M个子电路、每个子电路规模为T的计算任务，使用M台机器时，证明者的计算时间为O(T log T + M log M)，而原始Plonk在单台机器上的证明时间为O(MT log(MT))。我们的协议每台机器仅需O(1)的通信开销，且**证明大小和验证时间均为O(1)**，与原始Plonk完全一致。此外，我们进一步证明，仅需少量修改，第二个协议即可支持**具有任意连接结构的一般电路**，同时保持相同的证明时间、验证时间和通信复杂度。该技术在ZKP的其他应用场景中也可能具有独立的研究价值。\n\n我们实现了**Pianist**（Plonk via unlimited distribution，即“无限分布式Plonk”），一个基于我们协议构建的**完全分布式ZKP系统**。Pianist在64台机器上仅需313秒即可为8192笔交易生成证明，相比原始的Plonk方案，**可扩展性提升了64倍**。每台机器的通信量仅为**2.1KB**，且与机器数量和电路规模无关。证明大小为2.2KB，验证时间仅需3.5毫秒。\n\n我们进一步验证了Pianist对一般电路同样具有显著提升效果：在一个包含2^25个门电路的随机生成电路上，使用32台机器仅需**5秒**即可完成证明生成，比单台机器运行Plonk快了**24.2倍**。\n\n---\n\n**总结亮点：**\n\n- 提出**完全分布式ZKP方案**，突破单机资源限制；\n- 证明生成可像“矿池”一样并行化，**通信开销恒定、极低**；\n- 基于Plonk，保持其**简洁的验证复杂度**（证明大小和验证时间均为常数）；\n- 支持从数据并行电路到**任意结构通用电路**；\n- 实际系统Pianist实现**数十倍性能提升**，为大规模区块链应用提供可行路径。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/A Picture is Worth 500 Labels：A Case Study of Demographic Disparities in Local Machine Learning Models for Instagram and TikTok.pdf": {
        "title": "A Picture is Worth 500 Labels：A Case Study of Demographic Disparities in Local Machine Learning Models for Instagram and TikTok",
        "abstract": "——移动应用程序通过将数据处理转移到用户的智能手机上，加强了对用户隐私的保护。如今，先进的机器学习（ML）模型（如视觉模型）已能够在本地分析用户的图像，从中提取洞察，以驱动多种功能。基于这种在设备端本地分析用户图像的新型处理模式，我们选取了两款主流社交媒体应用——TikTok和Instagram，进行深入分析，旨在揭示：（1）这两款应用中的视觉模型从用户图像和视频数据中推断出了哪些关于用户的洞察；（2）这些模型在不同人口统计学群体（如年龄、性别、种族等）之间是否存在性能差异。\n\n由于视觉模型为年龄验证、人脸识别等敏感技术提供了关键信号，理解这些模型中可能存在的偏见至关重要，以确保所有用户都能获得公平且准确的服务。\n\n为此，我们开发了一种新颖的方法，用于捕获和评估移动应用中的机器学习任务，成功克服了代码混淆、原生代码执行以及可扩展性等挑战。该方法主要包括三个步骤：机器学习任务检测、机器学习流水线重建，以及机器学习性能评估，其中特别关注不同人口群体间的性能差异。我们将该方法应用于TikTok和Instagram，获得了重要发现。\n\n在TikTok中，我们发现其年龄和性别预测功能存在准确性问题，尤其体现在未成年人和黑人用户群体中。在Instagram中，我们的分析揭示了其图像中超过500种视觉概念的提取存在明显的人口统计学差异，并发现某些人口特征与特定视觉概念之间存在虚假相关性（即非因果的统计关联）。\n\n这些发现凸显了在移动端部署视觉模型时，必须系统性地检测和纠正模型偏见，以保障技术的公平性与可靠性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Understanding the Privacy Practices of Political Campaigns：A Perspective from the 2020 US Election Websites.pdf": {
        "title": "Understanding the Privacy Practices of Political Campaigns：A Perspective from the 2020 US Election Websites",
        "abstract": "——政治竞选活动以收集用户隐私数据而闻名，无论是为了建立选民画像、联络志愿者，还是为了募集捐款。然而，由于在美国（U.S.），这类竞选活动被归类为非营利性质，其隐私保护实践所受到的审查程度远低于营利性企业。本文提出了一种名为“Polityzer”的框架，用于评估政治竞选网站的隐私状况，并利用该框架分析了2020年11月美国大选期间活跃的2060个竞选网站。\n\n我们的分析得出了20项关键发现，揭示了政治竞选活动在隐私保护方面存在的诸多漏洞。例如，我们发现，许多竞选活动收集了大量超出联邦选举委员会（FEC）要求的私人数据，而绝大多数网站并未提供任何形式的隐私声明。即便提供了隐私声明，其内容往往也不完整。我们还发现，竞选活动可能通过共同的筹款平台，无意中与其他竞选团队共享了用户数据，且未向用户披露此类数据共享行为。\n\n此外，我们向相关竞选团队报告了隐私声明缺失的问题，这进一步揭示了其隐私安全策略背后的深层原因。最后，我们探讨了本研究结果如何推动未来研究、为新兴隐私法规提供参考，并在这一关键领域改变用户对数据隐私的认知与行为方式。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/AirTaint：Making Dynamic Taint Analysis Faster and Easier.pdf": {
        "title": "AirTaint：Making Dynamic Taint Analysis Faster and Easier",
        "abstract": "—动态污点分析（Dynamic Taint Analysis, DTA）是一种广泛应用的数据流追踪技术，在模糊测试（fuzzing）、漏洞分析等安全研究中发挥着重要作用。然而，其实际应用面临一个关键问题：显著的性能开销。根据我们的分析，在某些场景下，现有最先进的DTA工具甚至会使程序执行效率降低超过100倍。这种高开销主要源于：大多数现有方案在**指令级别**进行污点分析，并采用**即时插桩（just-in-time instrumentation）**技术，将追踪代码插入原始程序中，导致频繁的上下文切换和冗余操作。\n\n在本文中，我们提出了一种新颖的方法——**AirTaint**，该方法结合了**基本块级别的污点规则抽象**与**汇编代码级别的插桩机制**，实现了高效的高层动态污点分析。具体而言，AirTaint首先利用指令级模拟技术，识别每个基本块的输入和输出操作数（即寄存器和内存变量），然后基于现有的污点引擎，推导出适用于每个基本块的污点规则抽象。最后，AirTaint将这些污点规则抽象对应的汇编代码直接插入原始程序中。在程序运行时，这些插入的污点分析代码能够快速执行，从而大幅降低开销。\n\n在基于9个真实世界应用程序中14个CVE漏洞的测试评估中，AirTaint成功检测出了所有漏洞。在进一步的对比实验中，AirTaint在29个真实世界应用程序上的运行效率显著优于现有工具：相较于libdft、SelectiveTaint和TaintRabbit，其性能最大分别提升了**931.0倍**、**5.97倍**和**328.3倍**，充分展现了其在效率方面的巨大优势。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Need for Speed：Taming Backdoor Attacks with Speed and Precision.pdf": {
        "title": "Need for Speed：Taming Backdoor Attacks with Speed and Precision",
        "abstract": "现代深度神经网络模型（DNN）为了实现最佳性能，需要大量数据，这促使人们依赖多个实体来获取训练数据集。一个突出的安全威胁是后门攻击：攻击方通过污染训练数据集中的一小部分样本，向模型中植入后门，导致模型在运行过程中对特定触发样本产生错误分类。为缓解此类攻击，已有许多防御方法被提出，例如检测并清除被污染的样本，或修复受害DNN中被篡改的模型权重。然而，现有方法在处理大规模训练数据集时效率显著不足，导致这些防御手段在现实场景中难以实际应用。\n\n在本文中，我们提出了一种轻量级的后门识别与清除方案，名为 **REBACK**。该方案首先提取出一组可疑样本和良性样本的子集，随后采用一种基于“平均与差分”的方法来识别目标标签（即被攻击的类别）。接着，REBACK 利用识别结果，调用一种新颖的逆向工程方法，仅通过基本的算术运算单元，即可精准还原出触发器（trigger）。实验结果表明，对于包含750个类别的ImageNet数据集，REBACK 能够在约2小时内完成对后门攻击的防御，相比现有方法，速度提升了18.5倍至214倍。在后门清除方面，由于还原出的触发器与原始触发器之间的余弦相似度高达99%，攻击成功率可降低至0.05%。本研究的代码已开源，可在网上获取。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Transferable Multimodal Attack on Vision-Language Pre-training Models.pdf": {
        "title": "Transferable Multimodal Attack on Vision-Language Pre-training Models",
        "abstract": "视觉-语言预训练（VLP）模型在实际应用中取得了显著成功，但同时也极易受到对抗攻击的误导。尽管对抗攻击具有破坏性，但它有助于揭示VLP模型的盲区，并推动其鲁棒性的提升。然而，现有的对抗攻击研究对**不同模态相关特征的关键作用**关注不足，导致攻击的**可迁移性**表现不佳。  \n\n为应对这一问题，我们提出了**可迁移多模态（TMM）攻击框架**，该框架同时利用**模态一致性特征**和**模态差异性特征**。为提升攻击的可迁移性，我们设计了**注意力导向的特征扰动**，在关键注意力区域干扰模态一致性特征。考虑到广泛采用的交叉注意力机制能表征不同模型间的共性特征，针对这些特征的攻击更容易误导相似模型的感知，从而激发更强的可迁移性。为增强攻击能力，我们提出**正交引导的特征异质化**方法，引导对抗扰动在编码嵌入中融入更多模态差异性特征。由于VLP模型在决策时更依赖多模态对齐特征，增加模态差异性可有效混淆模型的学习表征，从而提升攻击效果。  \n\n在多种设置下的广泛实验表明，TMM攻击框架显著优于现有方法，平均可迁移攻击能力提升**20.47%**。此外，我们验证了TMM在大型模型（如MiniGPT-4、Otter等）上同样表现出卓越的攻击性能。  \n\n---\n\n### 关键术语解析（基于原文逻辑）：\n1. **模态一致性特征**：不同模态（如图像与文本）间对齐的、模型依赖的共性特征（如交叉注意力激活的区域）。  \n2. **模态差异性特征**：模态间不一致或冲突的特征，通过正交引导刻意放大这类特征以干扰模型。  \n3. **注意力导向扰动**：聚焦模型注意力权重高的关键区域施加扰动，针对性破坏模态一致性。  \n4. **正交引导**：通过正交约束确保扰动后的特征与原始模态差异性最大化，避免无效扰动。  \n\n（翻译时结合技术背景调整了部分措辞，如\"heterogenization\"译为\"异质化\"以体现特征分化意图，\"transferable attacking ability\"保留\"可迁移性\"这一机器学习术语，同时通过分段和加粗提升可读性。）"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Dropout Attacks.pdf": {
        "title": "Dropout Attacks",
        "abstract": "——Dropout 是深度学习中一种常见的操作，其目的是通过在训练过程中随机“关闭”（即丢弃）神经元来防止模型过拟合。本文提出了一类针对神经网络的新型投毒攻击，称为 **DROP OUT 攻击（DROPOUT ATTACK）**。\n\nDROPOUT ATTACK 攻击的核心在于操纵 Dropout 操作中神经元的丢弃选择机制——不再是均匀随机地选择要丢弃的神经元，而是恶意地控制哪些神经元被关闭。我们设计、实现并评估了四种 DROPOUT ATTACK 的变体，覆盖了多种实际应用场景。这些攻击能够造成以下危害：减缓甚至完全阻止模型训练、破坏目标类别的预测准确率，以及针对性地破坏某一目标类别的精确率（precision）或召回率（recall）。\n\n在针对 CIFAR-100 数据集上训练的 VGG-16 模型的实验中，我们的攻击成功将该模型在目标类别上的精确率降低了 **34.6%**（从原本的 **81.7% 降至 47.1%**），而模型的总体准确率却未出现任何下降。这表明攻击具有高度的隐蔽性和针对性，能够在不被察觉的情况下严重破坏模型在特定类别上的性能。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Guessing on Dominant Paths：Understanding the Limitation of Wireless Authentication Using Channel State Information.pdf": {
        "title": "Guessing on Dominant Paths：Understanding the Limitation of Wireless Authentication Using Channel State Information",
        "abstract": "—信道状态信息（CSI）在无线网络的认证机制中已被广泛研究。然而，目前对基于CSI的认证所面临的系统性攻击模型的研究却相对较少。现有研究通常采用两种攻击模型之一：一种是随机攻击模型，即现有认证方案能够抵御的攻击；另一种是特定知识模型，即假设攻击者掌握某些内部信息。本文提出了一种新的、更贴近现实的攻击模型，用于评估基于CSI的认证机制。在该模型中，攻击者Eve试图主动猜测用户Alice的CSI，并对自己的信号进行预编码，以伪装成Alice，欺骗使用CSI进行用户认证的验证者Bob。\n\n为了使CSI猜测既高效又低成本，我们通过理论分析和CSI数据集验证表明，攻击者无需猜测所有信号传播路径上的CSI值。具体而言，Eve可以采用一种称为“主导路径构造”（Dominant Path Construction, DomPathCon）的策略，仅聚焦于猜测信道响应幅度最高的前几条路径（称为主导路径）上的CSI值。全面的实验结果表明，DomPathCon策略在不同无线网络环境下均有效，攻击成功率最高可达61%，这揭示了基于CSI认证机制存在的新局限。\n\n此外，我们也提出了若干设计方案，以缓解DomPathCon攻击带来的负面影响。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/It's Simplex. Disaggregating Measures to Improve Certified Robustness.pdf": {
        "title": "It's Simplex. Disaggregating Measures to Improve Certified Robustness",
        "abstract": "——**认证鲁棒性**通过为模型预测提供类别不变性的保证，避免了对对抗性攻击防御的脆弱性，这种保证适用于攻击强度不超过某个计算值的情况。尽管这些认证具有一定的价值，但当前用于评估其性能的技术并未充分揭示其优势与局限，因为现有分析往往忽略了针对单个样本的性能表现，而仅依赖于整体聚合指标。本研究通过考察认证模型的潜在输出空间，提出了两种改进认证机制分析的新方法，分别支持**与数据集无关**和**与数据集相关**的认证性能度量。采用这一新视角，我们揭示了全新的认证方法，其有望将当前最先进方法所实现的认证半径**提升一倍以上**。实验验证表明，在噪声尺度σ=1时，我们的新方法可多认证9%的样本；且随着预测任务难度的增加，其相对性能提升更加显著。\n\n**关键词**：认证鲁棒性，对抗性机器学习，对抗性攻击，差分隐私\n\n---\n\n### 理解与翻译要点说明：\n1. **核心概念转化**：  \n   - \"Certified robustness\"译为“认证鲁棒性”，强调其数学可证明性。  \n   - \"Class invariance\"译为“类别不变性”，即模型预测在扰动下不改变类别标签。  \n   - \"Radius of certification\"译为“认证半径”，指可保证鲁棒性的扰动阈值。\n\n2. **批判性逻辑显化**：  \n   原文批评现有认证分析仅关注聚合指标（如平均认证半径），而本研究提出需同时关注样本级表现，因此补充“与数据集无关/相关”的对比，突出方法的全面性。\n\n3. **技术贡献强调**：  \n   - “Potential output space”译为“潜在输出空间”，指模型所有可能输出构成的集合。  \n   - “More than double the achievable radius”译为“提升一倍以上”，直接量化技术突破。\n\n4. **实验结论清晰化**：  \n   通过“9%”“相对性能提升”等数据，直观体现方法优势，并补充“任务难度增加时提升更显著”的潜在价值。\n\n5. **术语一致性**：  \n   保留“差分隐私”（Differential Privacy）等标准术语，确保学术严谨性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Sticky Tags：Efficient and Deterministic Spatial Memory Error Mitigation using Persistent Memory Tags.pdf": {
        "title": "Sticky Tags：Efficient and Deterministic Spatial Memory Error Mitigation using Persistent Memory Tags",
        "abstract": "——诸如缓冲区溢出等空间内存错误，仍然是C/C++程序中最常见的高危漏洞之一。尽管该领域已有大量研究，但（即使是部分）缓解措施所带来的性能开销依然过高，难以在实际中广泛应用。为降低开销，近年来的解决方案逐渐转向硬件辅助技术，例如Arm的内存标签扩展（Memory Tagging Extension, MTE）。然而，目前最先进的MTE方案由于频繁进行内存（重新）打标签操作，尤其是在栈上，仍会产生较高的性能开销。此外，这些方案依赖于随机内存标签的保密性，只能提供概率性的安全保障。\n\n在本文中，我们首先证明：随机打标签所提供的保护能力有限，因为攻击者可以通过推测性探测（speculative probing）手段推断出内存标签。随后，我们提出了**StickyTags**——一种高效的、确定性的MTE解决方案，用于缓解有界的空间内存错误。该方法通过将栈和堆的内存布局按对象大小分类组织为多个“大小类别区域”（per-size-class regions），并以预定义的固定模式为每个区域分配持久化的内存标签。因此，内存标签只需初始化一次，之后同一大小类别的对象可重复使用相同的标签。\n\n这一机制消除了昂贵的内存重打标签（retagging）需求，并支持采用固定、轮询（round-robin）的方式分配标签，从而为每个对象周围构建出较大的隐式空间隔离区（spatial guards）。尽管这类隔离区的大小受限于4位MTE的熵值（即最多16个标签），但其保护机制是**高效且确定性的**。\n\n实验结果表明，StickyTags在保持极低实际运行时开销（在SPEC CPU2006测试集上不超过4%）的前提下，显著优于现有方案，具备实用化部署的可行性。同时，在一个近期基于概率性MTE的评估中，StickyTags能够**完全缓解8个空间类CVE中的7个**，展现出更强的安全保障能力。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/A Security Analysis of Honey Vaults.pdf": {
        "title": "A Security Analysis of Honey Vaults",
        "abstract": "——基于“蜜罐加密”（Honey Encryption, HE）保护的密码库（称为“蜜罐密码库”，即 honey vaults）是一种极具前景的技术工具，允许用户存储多个密码（统称为一个密码库），并使用主密码通过 HE 技术对其进行加密。一旦密码库意外泄露，攻击者试图发起离线密码猜测攻击时，蜜罐密码库在面对错误猜测时能够生成“诱饵密码库”（decoy password vaults）。这使得离线猜测攻击者无法仅凭本地解密判断密码是否正确，而必须与认证服务器进行交互，以验证解密出的密码是否有效。因此，蜜罐密码库成功地将**离线猜测攻击者**转变为**在线猜测攻击者**，即“蜜罐区分攻击者”（honey vault distinguishing attacker）。\n\n在在线猜测场景中，攻击者可以针对多个密码库实施多种攻击策略，进行多次密码尝试。然而，现有的关于 HE 的理论性消息恢复（Message Recovery, MR）安全性分析，仅关注对单个密码库进行**一次猜测**的攻击优势，无法准确刻画现实中的攻击行为，因而难以为用户密码库的安全设计提供实际指导。\n\n为解决这一问题，我们提出了一种**理论支撑的最优攻击策略**，用于建模区分攻击者，并由此推导出了针对消息恢复安全性（MR）的**更紧致的优势上界**。特别地，我们为与 HE 相关的多种密码学安全游戏提供了更紧致的**优势上界和下界**，包括：分布变换编码器（DTE）的安全性、已知明文攻击（known message attack）以及已知侧信息攻击（known side information attack）。这有助于更深入地理解蜜罐加密在实际应用中的真实安全水平。\n\n为了更全面地评估蜜罐密码库系统的安全性，我们将所提出的最优策略具体化为三种实用攻击方法，并提出了一种新的**编码攻击**（encoding attack）。针对两类主流的蜜罐密码库系统开展的广泛实验表明，我们的四种攻击方法相比现有同类攻击，可将攻击成功率提升 **1.15 至 4.35 倍**。\n\n此外，针对 Cheng 等人在 USENIX SEC’21 提出的**增量更新机制**（incremental update mechanism），我们提出了专门的**特征攻击**（feature attack）用于实施交集攻击（intersection attack）。实验结果显示，我们的攻击能够以 **87%–93% 的优势**成功突破该机制，显著削弱其设计的安全保障。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Cerberus：Enabling Efficient and Effective In-Network Monitoring on Programmable Switches.pdf": {
        "title": "Cerberus：Enabling Efficient and Effective In-Network Monitoring on Programmable Switches",
        "abstract": "——随着网络流量的持续增长以及新型攻击手段的不断涌现，传统的网络监控技术在保障网络安全与性能方面正面临严峻挑战。基于可编程交换机（如基于P4的）的**网络内监控**（In-Network Monitoring, INM）系统，因其具备高性能和实时性优势，已成为一种更具前景的解决方案。然而，现有的基于P4的INM系统在处理多样化、高并发的INM任务（如多向量DDoS防御）时，仍受限于硬件资源。更严重的是，攻击者可能动态变换攻击向量，针对缺乏适应性的监控系统进行干扰，甚至发起针对INM系统本身的拒绝服务（DoS）攻击。\n\n为应对上述挑战，我们提出了**Cerberus**——一个高效且有效的网络内安全监控系统。为支持多样化的INM任务，我们将这些任务抽象为**关键特征-功能**（Key-Feature, K-F）对，并设计了一种新颖的**内存切片机制**，使多个K-F对之间能够共享内存资源，从而提升资源利用率。为应对高流量负载，我们提出了一种新的**协同监控机制**，通过数据平面与控制平面的互补协作，显著提升了Cerberus的监控效率。为适应动态变化的网络环境，我们设计了一种全新的**资源管理器**，能够动态地为各类INM任务重新分配资源，并在不中断现有服务的前提下，灵活调整数据平面与控制平面的负载。\n\n我们设计了一系列INM功能模块（包括DDoS防御），并开发了Cerberus的原型系统。通过大量实验评估，结果表明：Cerberus可将可编程交换机的并发处理能力与监控容量提升一个数量级。此外，Cerberus在应对各类INM任务时展现出更强的**适应性与灵活性**，能够动态响应攻击变化，保障网络的高效、安全运行。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection.pdf": {
        "title": "Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection",
        "abstract": "——恶意域名检测（Malicious Domain Detection, MDD）是一项重要的开放性安全挑战，旨在判断一个互联网域名是否与网络攻击活动相关。为解决这一问题，已有多种技术被提出和应用，其中图神经网络（Graph Neural Networks, GNNs）被认为是最为有效的方法之一。基于GNN的恶意域名检测利用域名系统（DNS）日志，将互联网域名表示为图中的节点，构建一种被称为“域名恶意性图”（Domain Maliciousness Graph, DMG）的结构，并通过训练GNN模型，借助已知恶意或良性域名的标签，推断其他域名的恶意性。\n\n然而，这种方法高度依赖“公开”可获取的DNS日志来构建DMG，这为攻击者提供了可乘之机——他们可以操纵图中自身域名节点所对应的特征或与其他节点的连接关系（即边）。当前的研究主要集中在针对单个攻击者节点进行操纵的威胁模型上。但现实中，攻击者通常会创建大量域名以实现其攻击目标，以降低成本并规避检测。因此，他们的核心目标是让尽可能多的域名不被检测到。\n\n在本文中，我们将**同时在DMG中操纵多个节点**的攻击行为称为**多实例规避攻击**（multi-instance evasion attack）。据我们所知，此类攻击在现有文献中尚未被系统研究。我们通过理论分析与实验验证表明：现有的针对GNN型MDD系统的单实例规避攻击技术，无法有效应对多实例场景下的攻击需求。\n\n为此，我们提出了一种在**推理阶段**实施的、面向GNN型恶意域名检测系统的多实例对抗攻击方法，命名为**MintA**。MintA通过优化对节点特征及其邻居结构的扰动，提升目标节点及其邻域整体在检测系统中的隐蔽性。值得注意的是，MintA仅需对目标模型具备**黑盒访问权限**即可成功发动攻击，也就是说，它不需要了解MDD模型的内部参数、网络架构，也无需掌握非攻击节点的任何信息。\n\n我们将MintA的攻击目标形式化为一个优化问题，并设计了一种高效的近似求解算法。通过在真实世界数据上对一种先进的GNN型MDD技术进行实验评估，结果表明MintA的攻击成功率超过80%。\n\n本研究的结果为网络安全领域的研究人员和实践者敲响了警钟：GNN-based恶意域名检测系统在实际部署中可能面临严重的多实例规避攻击威胁，此类攻击会显著削弱该技术的有效性与优势。\n\n**关键词**：对抗攻击，恶意域名检测，DNS日志，推理阶段攻击。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Formal Model-Driven Analysis of Resilience of GossipSub to Attacks from Misbehaving Peers.pdf": {
        "title": "Formal Model-Driven Analysis of Resilience of GossipSub to Attacks from Misbehaving Peers",
        "abstract": "—GossipSub 是一种新型的对等（peer-to-peer）通信协议，旨在通过控制信息的发送内容与对象，抵御来自行为不当节点的攻击。其核心机制是每个节点通过一个“评分函数”来评估其邻居节点的行为，该函数综合衡量了邻居的正向与负向行为。该评分函数依赖于若干可配置参数（如权重、上限、阈值），这些参数可由使用 GossipSub 的应用程序进行自定义设置。GossipSub 的协议规范以英文撰写，其对抗恶意节点的韧性（resilience）目前主要通过基于 Go 语言实现的模拟测试进行经验性验证。\n\n在本研究中，我们采用一种基础性的方法来深入理解 GossipSub 对恶意节点攻击的抵御能力。我们使用 ACL2s 定理证明器，首次构建了 GossipSub 的形式化模型。该模型已获得 GossipSub 开发团队的正式认可。该模型能够模拟任意规模、任意拓扑结构的 GossipSub 网络，支持节点任意配置，并可用于对该协议进行定理的证明与证伪。\n\n我们将若干基本安全属性形式化，包括：评分函数应具有公平性，能够惩罚恶意行为，并奖励良性行为。我们证明，该评分函数在本质上始终是公平的，但其具体配置方式可能导致对良性行为的误惩罚，或对恶意行为的忽视。\n\n利用该模型，我们以两个主流真实应用场景的配置——FileCoin 和 Eth2.0 区块链——运行了 GossipSub 协议。结果表明，FileCoin 的所有配置均满足上述安全属性。然而，对于任意规模、任意拓扑结构的 Eth2.0 网络，即使存在任意数量的潜在恶意节点，我们都能构造出一种攻击策略：这些节点可以持续地不转发任何主题消息（即持续恶意行为），却仍能保持正分，从而不会被 GossipSub 从网络中被剔除。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Understanding and Bridging the Gap Between Unsupervised Network Representation Learning and Security Analytics.pdf": {
        "title": "Understanding and Bridging the Gap Between Unsupervised Network Representation Learning and Security Analytics",
        "abstract": "——网络攻击正变得越来越复杂，这也推动了安全分析技术的发展，这些技术通过挖掘组织日志（如网络日志和身份认证日志）来生成防御对策。图安全分析（Graph Security Analytics, GSA）能够对用户、主机和进程之间的复杂通信模式进行建模，近年来得到了广泛研究和部署。在支撑GSA的各项技术中，无监督网络表示学习（Unsupervised Network Representation Learning, UNRL）正逐渐受到关注。UNRL通过学习一种潜在的图表示（即节点嵌入），并根据不同的下游任务进行定制化优化。基于UNRL的GSA已展现出显著优势：它以无监督方式训练检测模型，使模型开发人员无需进行繁琐的特征工程。\n\n在本文中，我们重新审视了此前基于UNRL的GSA的设计，以探究它们在真实场景中的实际表现。我们发现，这类方法在大规模、噪声较多的日志数据集（如LANL身份认证数据集）上性能堪忧，其主要原因在于它们遵循标准的UNRL框架，以一种“攻击无关”（attack-agnostic）的方式训练通用模型。我们主张，应当考虑通用攻击行为的特征，并据此提出了ARGUS——一种采用新型编码器和解码器设计的、基于UNRL的图安全分析系统。ARGUS还被设计用于处理离散时间图（Discrete Temporal Graph, DTG），以充分利用图结构的时序动态特性。我们在两个大规模数据集（LANL和OpTC）上的评估表明，ARGUS在性能上显著超越了当前最先进的方法。\n\n**关键词**：图神经网络，安全分析，离散时间图"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/PolySphinx：Extending the Sphinx Mix Format With Better Multicast Support.pdf": {
        "title": "PolySphinx：Extending the Sphinx Mix Format With Better Multicast Support",
        "abstract": "——混合网络（Mix networks）是一种隐藏通信元数据的成熟技术，但在群组通信场景下会产生较高的开销，这阻碍了其在现实世界中的广泛应用，因为群组通信在现代通信模式中占据了重要地位。本文提出了一种名为“PolySphinx”的新型混合网络格式，它朝着高效匿名多播迈出了关键一步，允许混合节点将消息负载复制并发送给多个接收者。我们证明，PolySphinx在显著降低群组消息延迟的同时，并未牺牲用户所享有的匿名性：在一个包含25名成员的群组中，使用当前最先进的Rollercoaster方法平均延迟为6.1秒，而采用PolySphinx后延迟降至4.1秒。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：Privacy-Preserving Data Synthesis.pdf": {
        "title": "SoK：Privacy-Preserving Data Synthesis",
        "abstract": "随着数据分析的广泛应用，保障数据隐私已成为一项至关重要的任务。因此，旨在实现隐私保护数据分析的技术机制迅速兴起。然而，现有方法大多针对特定任务设计，为新的应用场景开发算法往往过程繁琐、效率低下。作为一种替代方案，生成（理想情况下）不包含私人信息的合成数据，成为极具前景的方向。本文聚焦于隐私保护数据合成（Privacy-Preserving Data Synthesis, PPDS）这一领域，对其进行了全面的综述、分析与探讨。\n\n具体而言，我们提出了一个“主配方”（master recipe），将PPDS领域中两大主流研究方向——统计方法与基于深度学习（DL）的方法——统一在一个框架之下。在该主配方的指导下，我们进一步将统计方法细分为建模方式与数据表示形式的选择，并从不同的生成建模原理出发，对基于深度学习的方法进行系统性剖析。\n\n为整合研究成果，我们提供了详尽的参考表格，提炼出关键结论，并指出了现有文献中尚未解决的重要问题。通过上述工作，我们旨在回答以下核心问题：  \n- 不同PPDS方法背后的设计原则是什么？  \n- 我们应如何对这些方法进行分类？每一类方法各自的优缺点是什么？  \n- 如何为不同的实际应用场景提供方法选择指南？\n\n在此基础上，我们对几种主流的基于深度学习的方法在“隐私保护图像合成”任务上进行了基准测试，结果表明，**DP-MERF** 是一种具有广泛适用性的通用方法。最后，通过对过去十年研究的系统化梳理，我们明确了该领域未来的发展方向，并向研究者提出了进一步探索的行动倡议。\n\n**第1章引言（隐含）**  \n本文致力于构建一个结构清晰、逻辑连贯的理论框架，推动PPDS从碎片化研究走向系统化发展，为学术界与工业界提供实用的参考与指导。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Leveraging Prefix Structure to Detect Volumetric DDoS Attack Signatures with Programmable Switches.pdf": {
        "title": "Leveraging Prefix Structure to Detect Volumetric DDoS Attack Signatures with Programmable Switches",
        "abstract": "随着日益复杂且动态的流量型DDoS（分布式拒绝服务）攻击持续对边缘网络造成严重破坏，近期出现的两个技术进展为边缘网络的DDoS防御带来了新的希望。首先，可编程交换机作为实现可扩展、低成本攻击特征检测的有力工具崭露头角。然而，其在边缘网络中的实际部署仍是一个极具挑战性的开放性问题。其次，基于机器学习（ML）的解决方案已展现出基于每流流量特征准确识别攻击特征的潜力，但其难以有效扩展到实际生产环境中边缘网络所面临的巨大流量规模和海量并发流，因而大多仍停留在理论层面，难以投入实际应用。\n\n在本文中，我们提出了ZAPDOS——一种新颖的方法，可在源前缀（source prefix）级别上准确、快速且可扩展地检测流量型DDoS攻击特征。ZAPDOS首次利用了在实测攻击源与正常源前缀结构中观察到的关键特性（即明显的“簇中簇”结构特性），并将其有效应用于现代攻击的实战防御中。ZAPDOS通过在交换机硬件中监控聚合的源前缀级流量特征，结合学习模型识别出可能包含攻击源的源前缀，并采用多种创新算法高效地精确定位攻击源。\n\n我们构建了ZAPDOS的硬件原型和基于数据包级别仿真的软件模拟器，二者均实现了相当的检测准确率。由于现有数据集在训练和评估源前缀级模型方面存在不足，我们提出了一种新的数据融合方法，专门用于ZAPDOS的训练与评估。通过原型和模拟器，我们验证了在相同监控资源开销下，ZAPDOS针对多种不同攻击场景，其误报率和漏报率均比现有最先进方案低数个数量级。\n\n**关键词**：网络安全与测量、可编程交换机硬件、DDoS防御"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Piano：Extremely Simple, Single-Server PIR with Sublinear Server Computation.pdf": {
        "title": "Piano：Extremely Simple, Single-Server PIR with Sublinear Server Computation",
        "abstract": "我们构建了一种**亚线性时间的单服务器预处理型私有信息检索（PIR）方案**，在客户端存储与服务器计算之间实现了**最优权衡**（至多相差多项式对数因子）。该方案每次查询的**服务器和客户端平均计算开销为 Õ(√n)**，**在线通信量为 O(√n)**，并仅需 **eO_λ(√n)** 的客户端存储空间。与以往依赖同态加密等复杂密码学工具的单服务器 PIR 方案不同，我们的方案仅依赖于**伪随机函数（PRF）**，显著降低了实现复杂度。\n\n据我们所知，**PIANO 是首个实用的单服务器亚线性时间 PIR 方案**，其性能相较当前最先进的单服务器 PIR 方案提升了 **10 倍至 300 倍**。与最优的双服务器 PIR 方案相比，PIANO 在性能上具备可比性，但其构造方式**更为简洁高效**。\n\n实验结果表明：对于一个 **100GB 的数据库**，在 **60ms 往返延迟**的网络环境下，PIANO 仅需 **93ms** 即可返回查询结果；而此前最优的 PIR 方案则需要 **11 秒或更长时间**，性能差距显著。这一突破使得 PIR 技术在大规模现实场景中的实用化迈出了关键一步。\n\n---\n\n### 核心亮点翻译解析：\n1. **\"sublinear-time\" → 亚线性时间**：强调算法复杂度低于线性（n），体现高效性。\n2. **\"optimal tradeoff...poly-logarithmic factors\" → 最优权衡（至多相差多项式对数因子）**：数学上严谨表达\"渐进最优\"。\n3. **\"amortized Õ(√n)\" → 平均 Õ(√n)**：强调多次查询后的摊销开销，体现实际性能。\n4. **\"eO_λ(√n)\"**：保留原符号，表示依赖安全参数 λ 的拟线性存储（常见于密码学文献）。\n5. **\"10×−300×\" → 10倍至300倍**：明确性能提升幅度。\n6. **\"comparable performance but simpler\" → 性能可比但构造更简洁**：突出单服务器架构的简洁性优势。\n7. **实验数据对比**：通过具体数值（93ms vs 11s）直观体现技术突破，增强说服力。\n\n该方案标志着 PIR 技术从理论迈向实用的重要进展，尤其适用于隐私敏感的大数据检索场景。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Sweep-UC：Swapping Coins Privately.pdf": {
        "title": "Sweep-UC：Swapping Coins Privately",
        "abstract": "——公平交换（也称原子交换）是任何加密货币中的一项基本操作，允许用户以原子方式交换代币。尽管已有大量研究致力于解决该问题，但大多数方案缺乏链上隐私保护。因此，代币仍会保留公开的交易历史，而这会损害货币的可互换性（fungibility）。正是这一问题催生了关于具备隐私保障的公平交换的蓬勃发展的新研究方向。现有的协议要么依赖复杂的脚本机制（这同样会损害可互换性并导致高昂的交易费用），要么无法支持在多种加密货币之间进行原子交换，要么缺乏完整的安全证明。\n\n为克服这些局限性，我们提出了 **Sweep-UC**，这是首个在效率、脚本最小化以及广泛货币兼容性（超越现有技术水平）三方面同时优化的公平交换协议。我们基于模块化的子协议构建 Sweep-UC，并在通用可组合性（UC）框架下给出了严格的安全性分析。我们的许多工具和安全定义均可独立使用，可作为未来公平交换协议设计中的实用组件。\n\n**关键词**：原子交换；不可关联交换；代币混币；盲签名；"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/SoK：Unintended Interactions among Machine Learning Defenses and Risks.pdf": {
        "title": "SoK：Unintended Interactions among Machine Learning Defenses and Risks",
        "abstract": "——机器学习（ML）模型不能忽视对安全性、隐私性和公平性所带来的风险。已有多种防御方法被提出，以缓解这些风险。然而，当某一种防御措施在有效降低某一类风险的同时，可能会导致模型对其它风险变得更加敏感或更具抵抗力。现有研究缺乏一个有效的框架，来识别并解释这些非预期的交互作用。我们提出了一个这样的框架，其核心假设是：过拟合与记忆化（memorization）是导致这些非预期交互的根本原因。我们梳理了关于非预期交互的现有文献，并将其纳入我们的框架中进行统一分析。基于该框架，我们进一步推测出两种此前未被探索的交互作用，并通过实验进行了实证验证。\n\n1."
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Scalable Mixed-Mode MPC.pdf": {
        "title": "Scalable Mixed-Mode MPC",
        "abstract": "近年来，支持**混合模式计算**的安全多方计算（MPC）协议因其在函数表示上的灵活性，已被广泛应用于多个领域。然而，现有的混合模式MPC协议仅适用于参与方数量较少的情形：它们要么专门针对两方或三方场景设计，要么在参与方数量较大时性能急剧下降，难以扩展。\n\n在本文中，我们设计并实现了一个新的系统，用于实现**高效且可扩展的混合模式MPC**，能够容忍任意数量的半诚实（semi-honest）恶意方。我们的协议允许秘密数据以**加密（Encrypted）、布尔（Boolean）、算术（Arithmetic）或姚氏（Yao）**形式表示，并支持这些表示形式之间的高效转换。\n\n具体贡献如下：\n\n1) 我们设计了一种**多方查表协议**，其中查表的下标（index）和表内容（table）均可保持私密。该协议具有良好的可扩展性，即使面对数百个参与方也能高效运行。\n\n2) 基于上述查表协议，我们为大量参与方设计了**加法算术秘密共享与布尔秘密共享之间的高效转换协议**。对于32个参与方，我们的转换协议相比当前最先进的MPC框架MOTION和MP-SPDZ，通信开销减少了**1184倍至8141倍**；在1 Gbps网络环境下，运行时间最多可提升**1275倍**。当参与方数量进一步增加时，性能提升幅度更为显著。\n\n3) 我们还利用新设计的协议，提出了一种高效的**多方分布式电路混淆（garbling）协议**。该协议在通信开销方面具有**每参与方渐近恒定通信量**的特性，显著优于传统方案。\n\n我们的实现代码将全部开源。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Please Tell Me More：Privacy Impact of Explainability through the Lens of Membership Inference Attack.pdf": {
        "title": "Please Tell Me More：Privacy Impact of Explainability through the Lens of Membership Inference Attack",
        "abstract": "——可解释性正日益被视为推动机器学习（ML）更广泛应用的一项关键技术，尤其是在安全攸关的应用场景中。这催生了“可解释机器学习”（explainable ML）这一研究领域，其目标是通过引入解释器（explanators）来增强神经网络的可解释性。然而，对更好可解释性的追求，却无意中带来了更高的安全与隐私风险。尽管目前已有大量研究关注可解释机器学习的安全风险，但其潜在的隐私风险仍未得到充分探索。\n\n为弥补这一空白，我们从**成员推断**（membership inference）的角度，系统性地研究了可解释机器学习中的隐私风险。我们观察到：除了模型的预测准确率之外，模型在面对扰动时的**鲁棒性**，在训练集的成员样本（member samples）与非成员样本（non-member samples）之间也表现出可观测的差异。基于这一发现，我们提出了一种新的成员推断攻击方法。该攻击利用解释器生成的归因图（attribution maps）所强调的重要特征，在不同强度的扰动下观察模型置信度的变化，并从中提取额外的成员特征。\n\n直观上，当对重要特征施加扰动时，成员样本的模型置信度通常会显著下降。我们结合模型性能（如准确率）和鲁棒性（对扰动的响应）在成员与非成员样本之间的差异，训练一个攻击模型，以区分样本是否属于训练集。我们在多个基准模型和不同数据集上，使用七种主流的解释器对我们的方法进行了评估。\n\n结果表明，当前的可解释机器学习方法存在不可忽视的隐私泄露问题。更重要的是，即使攻击者不了解训练数据集的具体内容，甚至不知道目标模型的结构，这种隐私泄露依然可能发生。最后，我们还发现，现有的基于模型或输出层面的防御机制，无法有效缓解这种新型攻击。\n\n---\n\n**总结要点：**  \n本研究揭示了可解释性技术本身可能成为隐私攻击的“后门”——解释器在揭示模型决策依据的同时，也无意暴露了训练数据的成员信息。这为未来可解释AI的设计提出了新的挑战：如何在提升透明度的同时，防范由此引发的隐私风险。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Private Analytics via Streaming, Sketching, and Silently Verifiable Proofs.pdf": {
        "title": "Private Analytics via Streaming, Sketching, and Silently Verifiable Proofs",
        "abstract": "我们推出了 Whisper，一个用于在保护隐私的前提下收集聚合统计数据的系统。与以往的系统类似，Whisper 的部署包含一组数量较少的、互不串通的服务器；这些服务器能够基于大量用户的数据计算聚合统计结果，同时不会获知任何单个用户的原始数据。Whisper 的主要创新在于：其服务器之间的通信开销以及服务器端的存储开销，与用户总数呈**次线性增长**关系。\n\n具体而言，以往的方案要求服务器为验证每个客户端提交数据的格式正确性（well-formedness）而交换若干比特的信息。相比之下，Whisper 引入了一种名为“静默可验证证明”（silently verifiable proofs）的新型证明机制，该机制作用于秘密共享的数据之上，使得服务器仅需交换一个 128 位的字符串，即可验证任意大规模批次的证明。这种改进显著降低了服务器间通信成本。虽然这会带来客户端到服务器通信量的增加，但在云计算环境中，客户端上传数据的成本通常远低于服务器之间数据出口（egress）的成本，甚至可能是免费的。\n\n为了进一步降低服务器存储开销，Whisper 使用**小空间草图数据结构**（small-space sketching data structures）来近似计算某些统计量。然而，在存在恶意客户端的对抗性环境中应用随机化草图技术，需要进行一项细致且新颖的安全性分析。\n\n在一个包含两台服务器和 10 万客户端的部署场景中，假设其中 1% 的客户端为恶意节点，Whisper 能够在仅使每个客户端通信量增加 10% 的前提下，将向量求和（vector sum）操作中的服务器间通信开销降低**三个数量级**。这一性能提升显著优于传统方案。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Preserving Node-level Privacy in Graph Neural Networks.pdf": {
        "title": "Preserving Node-level Privacy in Graph Neural Networks",
        "abstract": "——差分隐私（Differential Privacy, DP）在表格数据、图像数据和序列数据的学习中已有广泛应用，尤其是在关注**个体实例级隐私**（instance-level privacy）的场景下。然而，在图数据学习领域，针对**节点级隐私**（node-level privacy）的研究却极为稀少。其主要挑战在于，现有的差分隐私协议难以直接应用于图神经网络（GNN）中的**消息传递机制**（message-passing mechanism）。\n\n在本研究中，我们提出了一种专门解决节点级隐私问题的方案。我们的协议包含两个核心组件：  \n1）一种名为 **HeterPoisson** 的采样策略，采用专门的节点采样方法，并结合一系列定制化操作，生成具有理想性质的一组子图；  \n2）一种随机化机制，使用**对称多元拉普拉斯噪声**（Symmetric Multivariate Laplace, SML）而非传统的高斯噪声。我们的隐私核算表明，这种特定组合能够提供**非平凡的隐私保障**（non-trivial privacy guarantee）。此外，实验在五个真实世界数据集上验证了我们的协议在保持良好GNN学习性能方面的有效性；与现有基线方法相比，我们的方法展现出显著优势，尤其是在**高隐私保护强度**（high privacy regime）下表现尤为突出。我们还通过实验：  \n1）对我们的协议实施了成员推理攻击（membership inference attacks），  \n2）应用隐私审计技术（privacy audit techniques）来验证协议的隐私完整性，进一步确认了其鲁棒性。\n\n随后，我们深入探讨了一种看似颇具吸引力的方法[33]（USENIX’23），该方法试图通过**差分隐私的节点/实例嵌入**（differentially private node/instance embeddings）来实现节点级隐私保护。然而，通过一项详尽的案例研究，我们发现该方法存在**根本性的隐私缺陷**。更重要的是，我们证明了一个**不可能性结果**：即无法通过**私有实例嵌入**（private instance embedding）同时实现**（强）隐私性**和**（可接受的）实用性**。这意味着，当强制施加差分隐私时，此类方法在本质上存在**实用性障碍**。\n\n**关键词**——节点级隐私；差分隐私；图神经网络"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Where Are the Red Lines. Towards Ethical Server-Side Scans in Security and Privacy Research.pdf": {
        "title": "Where Are the Red Lines. Towards Ethical Server-Side Scans in Security and Privacy Research",
        "abstract": "——全面且具有代表性的测量对于理解网络上的安全与隐私风险至关重要。然而，长期以来，研究人员一直不愿大规模调查服务器端漏洞，因为这可能对服务器造成损害、中断服务并引发经济损失。这种行为可能引发运营方的强烈反对，并在同行评审中引发争议，因为法律、伦理以及运营方对安全研究的立场之间的界限在很大程度上尚不明确。\n\n本文旨在弥补这一研究空白，探讨网络环境中服务器端扫描（Server-Side Scanning, 3S）的边界问题。为此，我们设计了五种典型的3S应用场景，以获取具体的实践指导。我们通过23次深度访谈，收集了来自法律专家（以德国法律为案例研究对象）、研究伦理委员会成员，以及网站和服务器运营方的定性数据，旨在了解哪些类型的3S被视为可接受，哪些行为会触碰“红线”。为进一步验证研究发现，我们还对119名运营方开展了一项在线调查。\n\n综合分析这些不同视角，我们发现：尽管在访谈和调查过程中，有略占多数（57%）的运营方对学术性的3S研究持积极态度，但由于缺乏司法判例和明确的伦理指导，研究人员在应对3S相关风险时仍面临巨大挑战。作为缓解这些挑战的第一步，我们提出了未来3S研究的最佳实践建议，并引入预注册（pre-registration）机制，为基于3S的研究提供一个可靠且透明的框架，从而降低研究人员和运营方双方所面临的不确定性。"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/The Role of User-Agent Interactions on Mobile Money Practices in Kenya and Tanzania.pdf": {
        "title": "The Role of User-Agent Interactions on Mobile Money Practices in Kenya and Tanzania",
        "abstract": "——数字金融服务在非洲极大地推动了金融包容性的发展。这类服务通常以被称为“移动货币”（Mobile Money，简称MoMo）的移动钱包形式落地实施，为大量长期以来被排除在传统银行体系之外的民众带来了巨大便利。尽管移动货币服务所带来的益处已有大量文献记录，但在服务使用过程中，特别是各相关方（尤其是用户与代理之间）互动中产生的挑战，却仍相对缺乏深入研究。本研究聚焦于移动货币用户在与移动货币代理互动过程中的实际行为，在肯尼亚和坦桑尼亚共开展了72次结构化访谈（每个国家36人）。研究结果表明，用户和代理服务提供者会通过设计“变通做法”（workarounds）来应对移动货币生态系统中存在的限制和困难。这些变通方式包括：代理向用户预支现金或提供小额借贷；在缺乏法定身份证件时，依赖用户与代理之间建立的信任关系完成交易；以及调整系统预设的交易流程，以提升操作的便捷性。总体而言，这些变通做法改变了我们视为移动货币核心组成部分中的一个或多个要素：即用户、代理以及交易本身。然而，此类变通做法也为用户和整个生态系统带来了新的风险与挑战。研究结果凸显出，有必要重新思考该生态系统中各环节的隐私与安全问题，同时调整相关政策和监管机制，在保障移动货币服务可用性的前提下，加强对用户与代理之间互动行为的保护。\n\n**关键词**——移动货币，用户-代理互动，数字金融系统，可用隐私与安全性，技术变通做法"
    },
    "/Users/xuyi/Downloads/PaperWorkflowAutomation/2024(45th)/Surveilling the Masses with Wi-Fi-Based Positioning Systems.pdf": {
        "title": "Surveilling the Masses with Wi-Fi-Based Positioning Systems",
        "abstract": "基于 Wi-Fi 的定位系统（WPS）被现代移动设备用于通过附近 Wi-Fi 接入点作为地标来获取自身位置。本研究中，我们揭示了苹果的 WPS 可能被滥用于制造全球范围的隐私威胁。我们提出一种攻击方法，允许非特权攻击者仅用数天时间就能获取全球 Wi-Fi BSSID 地理定位数据的快照。该攻击基于极少的假设条件，仅利用了已分配 MAC 地址空间中密集区域相对较少这一事实。通过为期一年的技术应用，我们成功获取了全球超过 20 亿个 BSSID 的精确位置。当这类海量数据集进行纵向关联分析时，其隐私影响更为严峻——攻击者可以借此追踪设备的移动轨迹。虽然大多数 Wi-Fi 接入点长期处于固定状态，但众多设备（如便携式旅行路由器）本身就是为移动场景设计的。我们通过多个案例研究展示了苹果 WPS 引发的隐私侵害类型：通过远程对无线接入点进行地理定位，我们追踪了进出战乱地区（特别是乌克兰和加沙）的设备移动、自然灾害（特别是茂宜岛火灾）的影响，以及通过代理实现针对特定个体的追踪可能性。我们为 WPS 运营商和 Wi-Fi 接入点制造商提出系列建议，以增强全球数亿用户的隐私保护。最后，我们详细说明了负责任地披露该隐私漏洞的努力，并阐述了苹果及 Wi-Fi 设备制造商独立实施及因本研究推动的部分修复措施。"
    }
}